{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "8d4fddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas \n",
    "pandas.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# This is required to catch warnings when the multiprocessing module is used\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "# import pertpy as pt\n",
    "import scanpy as sc\n",
    "\n",
    "import pertpy as pt\n",
    "adata = pt.dt.kang_2018()\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "ce738036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata)\n",
    "\n",
    "#hv_genes = filtered_keys = df[df['column_name'] == True].index.tolist()\n",
    "\n",
    "#normal_genes = filtered_keys = df[df['column_name'] == False].index.tolist()\n",
    "\n",
    "#print(hv_genes, normal_genes)\n",
    "hv_genes = (list(adata.var[adata.var['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "hv_columns = [i for i,val in enumerate(normal_genes) if val in hv_genes]\n",
    "#hv_genes\n",
    "len(hv_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "5024bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "#batchcontrol\n",
    "#clustering\n",
    "#cell type annotation\n",
    "#embedding\n",
    "#reverse transcriptome\n",
    "#differential expression\n",
    "\n",
    "#rna velocity -> predicts the future state \n",
    "#predict the probability of unseen perturbations\n",
    "#test: first data set => output list of perturbations \n",
    "# take a 2nd dataset and get list of perturbations + their probability \n",
    "\n",
    "\n",
    "#representation learning (in particular, self-supervised, multi-view, and transfer learning\n",
    "#https://registry.opendata.aws/tabula-muris/#usageexamples\n",
    "\n",
    "#see what preprocessing is needed to get better accuracy\n",
    "\n",
    "##load data\n",
    "\n",
    "##import premade model => output list of predicted unseen perturbation\n",
    "sc.pp.calculate_qc_metrics(adata)\n",
    "\n",
    "#write custom model. get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "619d5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_expressed = [\"string1\", \"string2\", \"string3\"]\n",
    "\n",
    "    \n",
    "# strings = np.array(gene_expressed)\n",
    "# #adata.obs['genes_expressed'] = strings\n",
    "# coordinates = []\n",
    "cx = adata.X\n",
    "cx = cx.tocoo()\n",
    "\n",
    "# #delete non highly variable genes from matrix\n",
    "\n",
    "\n",
    "# for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "#     if i in hv_columns: coordinates += [[i,j,v]]\n",
    "# for coord in coordinates:\n",
    "#     coord[1] = adata.var_names[coord[1]]\n",
    "\n",
    "#batch removal - one patient at at time\n",
    "#one cell_type at a time \n",
    "#index cell type\n",
    "#index ctrl/stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "e04c40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rowGeneExpression2 = defaultdict(dict)\n",
    "\n",
    "\n",
    "import math\n",
    "math.floor\n",
    "df = adata.obs\n",
    "end = 50 if True else -1\n",
    "for column in hv_columns:\n",
    "    for row_id in range(math.floor(float(df.shape[0])))[:end]:\n",
    "        rowGeneExpression[row_id] += adata.X[row_id, column]\n",
    "        #rowGeneExpression2[row_id][column] = adata.X[row_id, column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "37853254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs\n",
    "dependent_variables =  [rowGeneExpression[row] for row in range(df.shape[0])]\n",
    "df['geneExpressionCount'] = dependent_variables\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "dependent_variables = [x for x in dependent_variables]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "9aa9e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "01957362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.9469, 33.1962,  7.2055, 35.4831, 26.7429, 11.3642, 24.9079,  ...,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dep = tensor(dependent_variables) # pertrubations\n",
    "t_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "17156f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3017.0000,    877.0000,    -27.6404,     14.9666,      9.0000,   1704.0000,    711.0000,     35.9469],\n",
       "        [  2481.0000,    713.0000,    -27.4936,     28.9249,      9.0000,   1614.0000,    662.0000,     33.1962],\n",
       "        [   703.0000,    337.0000,    -10.4682,     -5.9844,      3.0000,    908.0000,    337.0000,      7.2055],\n",
       "        [  3420.0000,    850.0000,    -24.3680,     20.4293,      9.0000,   1738.0000,    653.0000,     35.4831],\n",
       "        [  3158.0000,   1111.0000,     27.9522,     24.1597,      4.0000,   1857.0000,    928.0000,     26.7429],\n",
       "        [  1869.0000,    635.0000,     -0.4702,    -25.3987,      5.0000,   1525.0000,    634.0000,     11.3642],\n",
       "        [  1142.0000,    436.0000,    -15.9062,     20.0853,      9.0000,   1157.0000,    436.0000,     24.9079],\n",
       "        ...,\n",
       "        [   635.0000,    424.0000,     -6.6479,     -5.5475,      3.0000,    882.0000,    423.0000,      0.0000],\n",
       "        [  1340.0000,    480.0000,      7.7202,     33.3402,      8.0000,   1324.0000,    480.0000,      0.0000],\n",
       "        [  1033.0000,    468.0000,     18.2683,      1.0582,      6.0000,   1128.0000,    468.0000,      0.0000],\n",
       "        [  2116.0000,    819.0000,    -11.5631,      2.5741,      4.0000,   1669.0000,    799.0000,      0.0000],\n",
       "        [  1522.0000,    523.0000,     25.1424,      6.6038,      6.0000,   1422.0000,    523.0000,      0.0000],\n",
       "        [  1143.0000,    503.0000,     14.3597,     10.9656,      6.0000,   1185.0000,    503.0000,      0.0000],\n",
       "        [  1031.0000,    421.0000,     14.5721,     -4.7139,      5.0000,   1144.0000,    419.0000,      0.0000]])"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep = tensor(numerical_values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "955bcb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "2926f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.1443,  0.1673,  0.1378, -0.4768, -0.0260, -0.2365, -0.2289],\n",
       "        [-0.0058,  0.1173,  0.1664,  0.2664, -0.4768, -0.0246, -0.2202, -0.2114],\n",
       "        [-0.0016,  0.0555,  0.0634, -0.0551, -0.1589, -0.0139, -0.1121, -0.0459],\n",
       "        [-0.0079,  0.1399,  0.1475,  0.1882, -0.4768, -0.0265, -0.2172, -0.2260],\n",
       "        [-0.0073,  0.1828, -0.1692,  0.2225, -0.2119, -0.0284, -0.3087, -0.1703],\n",
       "        [-0.0043,  0.1045,  0.0028, -0.2339, -0.2649, -0.0233, -0.2109, -0.0724],\n",
       "        [-0.0026,  0.0717,  0.0963,  0.1850, -0.4768, -0.0177, -0.1450, -0.1586],\n",
       "        ...,\n",
       "        [-0.0015,  0.0698,  0.0402, -0.0511, -0.1589, -0.0135, -0.1407, -0.0000],\n",
       "        [-0.0031,  0.0790, -0.0467,  0.3071, -0.4238, -0.0202, -0.1597, -0.0000],\n",
       "        [-0.0024,  0.0770, -0.1106,  0.0097, -0.3178, -0.0172, -0.1557, -0.0000],\n",
       "        [-0.0049,  0.1348,  0.0700,  0.0237, -0.2119, -0.0255, -0.2658, -0.0000],\n",
       "        [-0.0035,  0.0861, -0.1522,  0.0608, -0.3178, -0.0217, -0.1740, -0.0000],\n",
       "        [-0.0027,  0.0828, -0.0869,  0.1010, -0.3178, -0.0181, -0.1673, -0.0000],\n",
       "        [-0.0024,  0.0693, -0.0882, -0.0434, -0.2649, -0.0175, -0.1394, -0.0000]])"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "8fc0dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "7f25fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = pd.DataFrame(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "id": "f6d67306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(independent_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "42738fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "#len(trn_indep),len(val_indep)\n",
    "#dropout, svd, latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "e0499927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6772, 0.0615, 0.2613],\n",
      "        [0.1261, 0.7126, 0.1613]]) tensor([[ 0.3935, -2.0054, -0.5590],\n",
      "        [-0.4589,  1.2726, -0.2133]])\n",
      "0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; 0.532; {'nCount_RNA': tensor(0.3870), 'nFeature_RNA': tensor(0.1283), 'tsne1': tensor(-0.0261), 'tsne2': tensor(-0.0653), 'cluster': tensor(-0.0117), 'nCount_SCT': tensor(0.1363), 'nFeature_SCT': tensor(-0.3976), 'geneExpressionCount': tensor(-0.2811)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5686"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def init_coeffs(): \n",
    "#     hiddens = [10, 10] # <-- set this to the size of each hidden layer you want_ \n",
    "#     sizes = [n_coeff] + hiddens + [1] \n",
    "#     n = len(sizes) \n",
    "#     layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]  for i in range(n-1)] \n",
    "#     consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)] \n",
    "#     for l in layers+consts:\n",
    "#         l.requires_grad_() \n",
    "#     return layers,consts\n",
    "\n",
    "# import torch.nn.functional as F \n",
    "# def calc_preds(coeffs, indeps): \n",
    "#     layers,consts = coeffs \n",
    "#     n = len(layers) \n",
    "#     res = indeps \n",
    "#     for i,l in enumerate(layers): \n",
    "#         res = res@l + consts[i] \n",
    "#         if i!=n-1: res = F.relu(res) \n",
    "#     return torch.sigmoid(res)\n",
    "\n",
    "# def update_coeffs(coeffs, lr): \n",
    "#     layers, consts = coeffs \n",
    "#     for layer in layers+consts: \n",
    "#         layer.sub_(layer.grad * lr) \n",
    "#         layer.grad.zero_()\n",
    "torch.manual_seed(443)\n",
    "\n",
    "def calc_preds(coeffs, indeps): return (coeffs * indeps).sum(axis=1)\n",
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))\n",
    "#def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "#def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)\n",
    "\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()\n",
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()\n",
    "def update_coeffs(coeffs, lr): \n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()\n",
    "\n",
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n",
    "    \n",
    "m = torch.nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "one = m(input)\n",
    "print(one, input)\n",
    "\n",
    "\n",
    "def train_model(epochs=30, lr=4):\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): \n",
    "        one_epoch(coeffs, lr=lr)\n",
    "        #coeffs = m(coeffs)\n",
    "    return coeffs\n",
    "\n",
    "coeffs = train_model(33, lr=.02)\n",
    "\n",
    "indep_cols = ['nCount_RNA' ,                \n",
    "'nFeature_RNA'    ,             \n",
    "'tsne1'     ,                 \n",
    "'tsne2'  ,                   \n",
    "'cluster'    ,                  \n",
    "'nCount_SCT'   ,              \n",
    "'nFeature_SCT',\n",
    "'geneExpressionCount'\n",
    "]    \n",
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "print(show_coeffs())\n",
    "len([prob for prob in calc_preds(coeffs, t_indep) if prob > .5]) # should be 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "14ce99b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4981188178062439,\n",
       " 0.4981151521205902,\n",
       " 0.49967727065086365,\n",
       " 0.49808281660079956,\n",
       " 0.49838531017303467,\n",
       " 0.4995662271976471,\n",
       " 0.4985203444957733,\n",
       " 0.499601811170578,\n",
       " 0.498313307762146,\n",
       " 0.4994831681251526,\n",
       " 0.49935537576675415,\n",
       " 0.4992859959602356,\n",
       " 0.4995814561843872,\n",
       " 0.4998539388179779,\n",
       " 0.49923038482666016,\n",
       " 0.49964678287506104,\n",
       " 0.4981745481491089,\n",
       " 0.4991650879383087,\n",
       " 0.49953895807266235,\n",
       " 0.49980297684669495,\n",
       " 0.4985271096229553,\n",
       " 0.49931347370147705,\n",
       " 0.49963441491127014,\n",
       " 0.4993177354335785,\n",
       " 0.49966442584991455,\n",
       " 0.4991382956504822,\n",
       " 0.49952074885368347,\n",
       " 0.4988451600074768,\n",
       " 0.499502569437027,\n",
       " 0.49961167573928833,\n",
       " 0.499094158411026,\n",
       " 0.4996446371078491,\n",
       " 0.49794450402259827,\n",
       " 0.4994189441204071,\n",
       " 0.4995386004447937,\n",
       " 0.49950268864631653,\n",
       " 0.499509334564209,\n",
       " 0.4995979964733124,\n",
       " 0.49924957752227783,\n",
       " 0.49954235553741455,\n",
       " 0.49798861145973206,\n",
       " 0.4985899329185486,\n",
       " 0.49895358085632324,\n",
       " 0.4993210732936859,\n",
       " 0.49934306740760803,\n",
       " 0.4991726279258728,\n",
       " 0.4994920790195465,\n",
       " 0.4978584349155426,\n",
       " 0.4996151924133301,\n",
       " 0.4978962540626526,\n",
       " 0.49999308586120605,\n",
       " 0.49957239627838135,\n",
       " 0.5001180171966553,\n",
       " 0.5000397562980652,\n",
       " 0.4996179938316345,\n",
       " 0.5001397132873535,\n",
       " 0.5000994801521301,\n",
       " 0.5001149773597717,\n",
       " 0.5001676082611084,\n",
       " 0.49957239627838135,\n",
       " 0.5000923871994019,\n",
       " 0.49980825185775757,\n",
       " 0.4998493194580078,\n",
       " 0.5001364946365356,\n",
       " 0.49999427795410156,\n",
       " 0.5001842379570007,\n",
       " 0.4999889135360718,\n",
       " 0.5000842213630676,\n",
       " 0.5000959634780884,\n",
       " 0.4995768070220947,\n",
       " 0.5000354051589966,\n",
       " 0.4996356666088104,\n",
       " 0.5000607967376709,\n",
       " 0.49998027086257935,\n",
       " 0.4999576210975647,\n",
       " 0.4997776448726654,\n",
       " 0.4999871253967285,\n",
       " 0.4996241629123688,\n",
       " 0.5001911520957947,\n",
       " 0.5001166462898254,\n",
       " 0.5001220107078552,\n",
       " 0.4995558559894562,\n",
       " 0.500079870223999,\n",
       " 0.4999591112136841,\n",
       " 0.4997367560863495,\n",
       " 0.500165581703186,\n",
       " 0.49967214465141296,\n",
       " 0.4998093247413635,\n",
       " 0.5001504421234131,\n",
       " 0.5000369548797607,\n",
       " 0.5001425743103027,\n",
       " 0.5000466108322144,\n",
       " 0.49959734082221985,\n",
       " 0.4998183250427246,\n",
       " 0.49997252225875854,\n",
       " 0.5000834465026855,\n",
       " 0.500022828578949,\n",
       " 0.49985530972480774,\n",
       " 0.4997095465660095,\n",
       " 0.49988046288490295,\n",
       " 0.5000755190849304,\n",
       " 0.5001153945922852,\n",
       " 0.5000390410423279,\n",
       " 0.4998202919960022,\n",
       " 0.49995726346969604,\n",
       " 0.49954408407211304,\n",
       " 0.5001708269119263,\n",
       " 0.4996057152748108,\n",
       " 0.5000733137130737,\n",
       " 0.4995904862880707,\n",
       " 0.5000227093696594,\n",
       " 0.4998179078102112,\n",
       " 0.49981123208999634,\n",
       " 0.5000400543212891,\n",
       " 0.5000224113464355,\n",
       " 0.5001181960105896,\n",
       " 0.5001165270805359,\n",
       " 0.5000112056732178,\n",
       " 0.4997384250164032,\n",
       " 0.500201404094696,\n",
       " 0.49964115023612976,\n",
       " 0.4996829926967621,\n",
       " 0.49977555871009827,\n",
       " 0.5000747442245483,\n",
       " 0.4998607337474823,\n",
       " 0.5000854134559631,\n",
       " 0.5000451803207397,\n",
       " 0.5001177787780762,\n",
       " 0.49997150897979736,\n",
       " 0.4997153580188751,\n",
       " 0.5000094771385193,\n",
       " 0.5001087784767151,\n",
       " 0.499977171421051,\n",
       " 0.50008225440979,\n",
       " 0.5000947117805481,\n",
       " 0.49959322810173035,\n",
       " 0.5001929998397827,\n",
       " 0.5001837015151978,\n",
       " 0.49972882866859436,\n",
       " 0.4995896518230438,\n",
       " 0.49989715218544006,\n",
       " 0.5000671148300171,\n",
       " 0.5000191926956177,\n",
       " 0.4997154772281647,\n",
       " 0.4999765157699585,\n",
       " 0.5000724196434021,\n",
       " 0.49955812096595764,\n",
       " 0.5000221133232117,\n",
       " 0.4995615780353546,\n",
       " 0.4999520778656006,\n",
       " 0.49947839975357056,\n",
       " 0.4995826482772827,\n",
       " 0.5001212954521179,\n",
       " 0.5001009106636047,\n",
       " 0.5000366568565369,\n",
       " 0.5000107884407043,\n",
       " 0.49968215823173523,\n",
       " 0.4996340572834015,\n",
       " 0.5001904368400574,\n",
       " 0.5001690983772278,\n",
       " 0.4995863139629364,\n",
       " 0.5000861883163452,\n",
       " 0.4996534585952759,\n",
       " 0.5001588463783264,\n",
       " 0.5000211000442505,\n",
       " 0.49964720010757446,\n",
       " 0.4998229146003723,\n",
       " 0.4999871850013733,\n",
       " 0.49990925192832947,\n",
       " 0.5000309348106384,\n",
       " 0.5000934600830078,\n",
       " 0.5001516342163086,\n",
       " 0.49980542063713074,\n",
       " 0.49978575110435486,\n",
       " 0.5001020431518555,\n",
       " 0.4996100664138794,\n",
       " 0.5001389980316162,\n",
       " 0.5001924633979797,\n",
       " 0.49983710050582886,\n",
       " 0.4997667074203491,\n",
       " 0.5000532269477844,\n",
       " 0.5001146197319031,\n",
       " 0.4998254179954529,\n",
       " 0.5000113844871521,\n",
       " 0.5000135898590088,\n",
       " 0.5000536441802979,\n",
       " 0.5001083612442017,\n",
       " 0.49954754114151,\n",
       " 0.49999672174453735,\n",
       " 0.4996027648448944,\n",
       " 0.5000476837158203,\n",
       " 0.4997389614582062,\n",
       " 0.4999764561653137,\n",
       " 0.499616801738739,\n",
       " 0.499816358089447,\n",
       " 0.49998939037323,\n",
       " 0.49973413348197937,\n",
       " 0.5001931190490723,\n",
       " 0.5001081824302673,\n",
       " 0.4998408555984497,\n",
       " 0.4996285140514374,\n",
       " 0.4998127818107605,\n",
       " 0.5001505017280579,\n",
       " 0.4995788335800171,\n",
       " 0.5000736117362976,\n",
       " 0.5000981688499451,\n",
       " 0.49955907464027405,\n",
       " 0.4999760389328003,\n",
       " 0.4998272657394409,\n",
       " 0.49981898069381714,\n",
       " 0.5001183152198792,\n",
       " 0.49962347745895386,\n",
       " 0.49972012639045715,\n",
       " 0.4996127486228943,\n",
       " 0.4999629259109497,\n",
       " 0.49969780445098877,\n",
       " 0.4995855689048767,\n",
       " 0.4999518394470215,\n",
       " 0.5001100897789001,\n",
       " 0.4994654357433319,\n",
       " 0.5000543594360352,\n",
       " 0.5001027584075928,\n",
       " 0.5000300407409668,\n",
       " 0.5000659227371216,\n",
       " 0.5000927448272705,\n",
       " 0.49953585863113403,\n",
       " 0.5001425743103027,\n",
       " 0.49964797496795654,\n",
       " 0.4999566078186035,\n",
       " 0.4996383488178253,\n",
       " 0.49979010224342346,\n",
       " 0.5000808238983154,\n",
       " 0.5000863075256348,\n",
       " 0.5000189542770386,\n",
       " 0.5001206398010254,\n",
       " 0.49975723028182983,\n",
       " 0.5000855922698975,\n",
       " 0.499555379152298,\n",
       " 0.4999825358390808,\n",
       " 0.49982529878616333,\n",
       " 0.4999985694885254,\n",
       " 0.4998032748699188,\n",
       " 0.5000298619270325,\n",
       " 0.5001242160797119,\n",
       " 0.4995718002319336,\n",
       " 0.49981510639190674,\n",
       " 0.5000113248825073,\n",
       " 0.49961382150650024,\n",
       " 0.4996682107448578,\n",
       " 0.49956682324409485,\n",
       " 0.49991685152053833,\n",
       " 0.49962323904037476,\n",
       " 0.5001271963119507,\n",
       " 0.5000649690628052,\n",
       " 0.5000887513160706,\n",
       " 0.49979522824287415,\n",
       " 0.5000020861625671,\n",
       " 0.5000507831573486,\n",
       " 0.5000324845314026,\n",
       " 0.5001688599586487,\n",
       " 0.49961209297180176,\n",
       " 0.4996163249015808,\n",
       " 0.4996477961540222,\n",
       " 0.5000647902488708,\n",
       " 0.5001147389411926,\n",
       " 0.49966466426849365,\n",
       " 0.5000211000442505,\n",
       " 0.49965792894363403,\n",
       " 0.5000307559967041,\n",
       " 0.4996282756328583,\n",
       " 0.5001229643821716,\n",
       " 0.49981147050857544,\n",
       " 0.49957138299942017,\n",
       " 0.49955782294273376,\n",
       " 0.49957895278930664,\n",
       " 0.4995950162410736,\n",
       " 0.5000327229499817,\n",
       " 0.5000320076942444,\n",
       " 0.49995362758636475,\n",
       " 0.5000633001327515,\n",
       " 0.49959513545036316,\n",
       " 0.5001032948493958,\n",
       " 0.5001123547554016,\n",
       " 0.5000435709953308,\n",
       " 0.49984341859817505,\n",
       " 0.4999680519104004,\n",
       " 0.49987128376960754,\n",
       " 0.5000903606414795,\n",
       " 0.5001028180122375,\n",
       " 0.5000725984573364,\n",
       " 0.4999502897262573,\n",
       " 0.4997279942035675,\n",
       " 0.5000185966491699,\n",
       " 0.5001428723335266,\n",
       " 0.49957191944122314,\n",
       " 0.5000333786010742,\n",
       " 0.500106692314148,\n",
       " 0.49964240193367004,\n",
       " 0.4998171925544739,\n",
       " 0.5000922083854675,\n",
       " 0.4999774098396301,\n",
       " 0.4994640052318573,\n",
       " 0.49963101744651794,\n",
       " 0.4995756149291992,\n",
       " 0.5000936985015869,\n",
       " 0.4995441436767578,\n",
       " 0.49994993209838867,\n",
       " 0.4995957314968109,\n",
       " 0.4999402165412903,\n",
       " 0.49960288405418396,\n",
       " 0.5000312924385071,\n",
       " 0.5000793933868408,\n",
       " 0.500130295753479,\n",
       " 0.5001406669616699,\n",
       " 0.5001490116119385,\n",
       " 0.4999786615371704,\n",
       " 0.5000855922698975,\n",
       " 0.5000623464584351,\n",
       " 0.4998117685317993,\n",
       " 0.49956265091896057,\n",
       " 0.5000096559524536,\n",
       " 0.500049889087677,\n",
       " 0.4996013343334198,\n",
       " 0.4995778799057007,\n",
       " 0.5000855326652527,\n",
       " 0.49981534481048584,\n",
       " 0.4999881982803345,\n",
       " 0.5000148415565491,\n",
       " 0.5000491142272949,\n",
       " 0.5000898838043213,\n",
       " 0.5001165866851807,\n",
       " 0.4998236894607544,\n",
       " 0.4999602437019348,\n",
       " 0.5000465512275696,\n",
       " 0.4995848536491394,\n",
       " 0.500000536441803,\n",
       " 0.4999157190322876,\n",
       " 0.4996170401573181,\n",
       " 0.4998357892036438,\n",
       " 0.5000157356262207,\n",
       " 0.5000813603401184,\n",
       " 0.4999757409095764,\n",
       " 0.5000076293945312,\n",
       " 0.4998176097869873,\n",
       " 0.4996955394744873,\n",
       " 0.5001665353775024,\n",
       " 0.5000274777412415,\n",
       " 0.5001639723777771,\n",
       " 0.5000228881835938,\n",
       " 0.4996740520000458,\n",
       " 0.4998188018798828,\n",
       " 0.4995669424533844,\n",
       " 0.4995414614677429,\n",
       " 0.5000530481338501,\n",
       " 0.4996863901615143,\n",
       " 0.5000141859054565,\n",
       " 0.5002105832099915,\n",
       " 0.5000812411308289,\n",
       " 0.49983519315719604,\n",
       " 0.500140905380249,\n",
       " 0.49981242418289185,\n",
       " 0.49995875358581543,\n",
       " 0.49998342990875244,\n",
       " 0.4995689392089844,\n",
       " 0.5000655055046082,\n",
       " 0.5000956654548645,\n",
       " 0.4996071457862854,\n",
       " 0.4998404383659363,\n",
       " 0.49979063868522644,\n",
       " 0.49994587898254395,\n",
       " 0.500005841255188,\n",
       " 0.49993711709976196,\n",
       " 0.4997280538082123,\n",
       " 0.4995897114276886,\n",
       " 0.5001806616783142,\n",
       " 0.4994601011276245,\n",
       " 0.4994620382785797,\n",
       " 0.5001397132873535,\n",
       " 0.4996160864830017,\n",
       " 0.500084638595581,\n",
       " 0.5000786781311035,\n",
       " 0.5000603795051575,\n",
       " 0.4996074438095093,\n",
       " 0.5000418424606323,\n",
       " 0.5000709295272827,\n",
       " 0.4996193051338196,\n",
       " 0.4996461868286133,\n",
       " 0.5000503063201904,\n",
       " 0.4996551275253296,\n",
       " 0.499604195356369,\n",
       " 0.5000919103622437,\n",
       " 0.49959537386894226,\n",
       " 0.4999654293060303,\n",
       " 0.5000107288360596,\n",
       " 0.5000810027122498,\n",
       " 0.500050961971283,\n",
       " 0.49982959032058716,\n",
       " 0.49946513772010803,\n",
       " 0.5000877976417542,\n",
       " 0.5000386238098145,\n",
       " 0.5000083446502686,\n",
       " 0.4999690055847168,\n",
       " 0.500019371509552,\n",
       " 0.500151515007019,\n",
       " 0.4997401535511017,\n",
       " 0.49965232610702515,\n",
       " 0.4999699592590332,\n",
       " 0.49982964992523193,\n",
       " 0.49958187341690063,\n",
       " 0.500045895576477,\n",
       " 0.500005304813385,\n",
       " 0.4998548924922943,\n",
       " 0.5000718832015991,\n",
       " 0.4998026192188263,\n",
       " 0.49999845027923584,\n",
       " 0.5000296235084534,\n",
       " 0.5000348091125488,\n",
       " 0.49965357780456543,\n",
       " 0.5000613927841187,\n",
       " 0.49957698583602905,\n",
       " 0.4995886981487274,\n",
       " 0.500112771987915,\n",
       " 0.5000764727592468,\n",
       " 0.5000824332237244,\n",
       " 0.500087559223175,\n",
       " 0.5000962018966675,\n",
       " 0.5000236630439758,\n",
       " 0.49994802474975586,\n",
       " 0.49983125925064087,\n",
       " 0.5001561641693115,\n",
       " 0.5000746846199036,\n",
       " 0.5000370740890503,\n",
       " 0.4999988079071045,\n",
       " 0.4999579191207886,\n",
       " 0.4996449947357178,\n",
       " 0.49980849027633667,\n",
       " 0.49996763467788696,\n",
       " 0.5000864267349243,\n",
       " 0.49970757961273193,\n",
       " 0.49960431456565857,\n",
       " 0.49999988079071045,\n",
       " 0.4996006190776825,\n",
       " 0.499616801738739,\n",
       " 0.5000870227813721,\n",
       " 0.50009685754776,\n",
       " 0.4995897114276886,\n",
       " 0.4998311400413513,\n",
       " 0.5000946521759033,\n",
       " 0.5000481605529785,\n",
       " 0.4998064935207367,\n",
       " 0.5000303387641907,\n",
       " 0.49992620944976807,\n",
       " 0.4998096823692322,\n",
       " 0.49958762526512146,\n",
       " 0.5000693202018738,\n",
       " 0.5001060366630554,\n",
       " 0.49948328733444214,\n",
       " 0.5001504421234131,\n",
       " 0.49956169724464417,\n",
       " 0.49998658895492554,\n",
       " 0.4996195435523987,\n",
       " 0.4999958276748657,\n",
       " 0.49959930777549744,\n",
       " 0.4997865855693817,\n",
       " 0.5001241564750671,\n",
       " 0.4998745024204254,\n",
       " 0.49981093406677246,\n",
       " 0.4995644986629486,\n",
       " 0.5000186562538147,\n",
       " 0.5000492930412292,\n",
       " 0.5000094771385193,\n",
       " 0.4999358654022217,\n",
       " 0.4995342195034027,\n",
       " 0.4999556541442871,\n",
       " 0.49995774030685425,\n",
       " 0.5001172423362732,\n",
       " 0.5000783205032349,\n",
       " 0.5001183152198792,\n",
       " 0.5001128315925598,\n",
       " 0.49960145354270935,\n",
       " 0.5000971555709839,\n",
       " 0.499986469745636,\n",
       " 0.5000922083854675,\n",
       " 0.4999936819076538,\n",
       " 0.5000583529472351,\n",
       " 0.49973753094673157,\n",
       " 0.49990180134773254,\n",
       " 0.49999749660491943,\n",
       " 0.499946653842926,\n",
       " 0.4995882213115692,\n",
       " 0.5000341534614563,\n",
       " 0.5000181198120117,\n",
       " 0.5000023245811462,\n",
       " 0.49959126114845276,\n",
       " 0.4999975562095642,\n",
       " 0.5000430941581726,\n",
       " 0.4999600648880005,\n",
       " 0.5000942945480347,\n",
       " 0.5001624822616577,\n",
       " 0.5000372529029846,\n",
       " 0.5000381469726562,\n",
       " 0.49966952204704285,\n",
       " 0.49958622455596924,\n",
       " 0.4998261332511902,\n",
       " 0.4995425343513489,\n",
       " 0.5000099539756775,\n",
       " 0.49961692094802856,\n",
       " 0.49998635053634644,\n",
       " 0.5000292062759399,\n",
       " 0.500049352645874,\n",
       " 0.5000346302986145,\n",
       " 0.4998120665550232,\n",
       " 0.4995577037334442,\n",
       " 0.49984508752822876,\n",
       " 0.50007164478302,\n",
       " 0.49958109855651855,\n",
       " 0.5001083612442017,\n",
       " 0.4995710849761963,\n",
       " 0.499969482421875,\n",
       " 0.5000344514846802,\n",
       " 0.4996317923069,\n",
       " 0.49962857365608215,\n",
       " 0.5001140236854553,\n",
       " 0.4999673366546631,\n",
       " 0.5001019239425659,\n",
       " 0.5000773668289185,\n",
       " 0.4998723566532135,\n",
       " 0.4995521605014801,\n",
       " 0.4998214840888977,\n",
       " 0.500145435333252,\n",
       " 0.5000415444374084,\n",
       " 0.5000177025794983,\n",
       " 0.5001932978630066,\n",
       " 0.5000210404396057,\n",
       " 0.5000578761100769,\n",
       " 0.5000340342521667,\n",
       " 0.49965769052505493,\n",
       " 0.4999798536300659,\n",
       " 0.49956759810447693,\n",
       " 0.49965012073516846,\n",
       " 0.50006103515625,\n",
       " 0.4998173117637634,\n",
       " 0.5000690817832947,\n",
       " 0.5000686645507812,\n",
       " 0.5001189112663269,\n",
       " 0.500097930431366,\n",
       " 0.5000882744789124,\n",
       " 0.5001857280731201,\n",
       " 0.5000691413879395,\n",
       " 0.5000318884849548,\n",
       " 0.49957334995269775,\n",
       " 0.5000874996185303,\n",
       " 0.5000117421150208,\n",
       " 0.5000560283660889,\n",
       " 0.5000960826873779,\n",
       " 0.4998251795768738,\n",
       " 0.5001322031021118,\n",
       " 0.5000930428504944,\n",
       " 0.4999450445175171,\n",
       " 0.5000898838043213,\n",
       " 0.49982792139053345,\n",
       " 0.500092625617981,\n",
       " 0.49958449602127075,\n",
       " 0.5000210404396057,\n",
       " 0.4996069073677063,\n",
       " 0.4999616742134094,\n",
       " 0.49996650218963623,\n",
       " 0.5000500679016113,\n",
       " 0.499950110912323,\n",
       " 0.49965929985046387,\n",
       " 0.5000956654548645,\n",
       " 0.4996781051158905,\n",
       " 0.5000945925712585,\n",
       " 0.49965107440948486,\n",
       " 0.5000574588775635,\n",
       " 0.5000981092453003,\n",
       " 0.4995759129524231,\n",
       " 0.4999668598175049,\n",
       " 0.5001004338264465,\n",
       " 0.5001087784767151,\n",
       " 0.5000668168067932,\n",
       " 0.49957072734832764,\n",
       " 0.4999740719795227,\n",
       " 0.5000886917114258,\n",
       " 0.49953794479370117,\n",
       " 0.4998334050178528,\n",
       " 0.4999673366546631,\n",
       " 0.49959656596183777,\n",
       " 0.5000601410865784,\n",
       " 0.49998581409454346,\n",
       " 0.5000998973846436,\n",
       " 0.5000416040420532,\n",
       " 0.4999352693557739,\n",
       " 0.49999380111694336,\n",
       " 0.49993640184402466,\n",
       " 0.5000340938568115,\n",
       " 0.5001341104507446,\n",
       " 0.499991774559021,\n",
       " 0.5001140832901001,\n",
       " 0.4998341202735901,\n",
       " 0.5001364946365356,\n",
       " 0.5000608563423157,\n",
       " 0.49957942962646484,\n",
       " 0.4994677007198334,\n",
       " 0.5000630021095276,\n",
       " 0.5001046657562256,\n",
       " 0.5000901818275452,\n",
       " 0.5001382827758789,\n",
       " 0.4995613992214203,\n",
       " 0.4996245205402374,\n",
       " 0.49955740571022034,\n",
       " 0.499936580657959,\n",
       " 0.49982625246047974,\n",
       " 0.500078558921814,\n",
       " 0.5000643134117126,\n",
       " 0.500017523765564,\n",
       " 0.49954158067703247,\n",
       " 0.4995487928390503,\n",
       " 0.4996471405029297,\n",
       " 0.4995484948158264,\n",
       " 0.4997192919254303,\n",
       " 0.4995425343513489,\n",
       " 0.5000554919242859,\n",
       " 0.4997502565383911,\n",
       " 0.4999955892562866,\n",
       " 0.5000545382499695,\n",
       " 0.5001585483551025,\n",
       " 0.4994731843471527,\n",
       " 0.5001894235610962,\n",
       " 0.500024139881134,\n",
       " 0.4996122717857361,\n",
       " 0.499575138092041,\n",
       " 0.49974068999290466,\n",
       " 0.5001417398452759,\n",
       " 0.5001003742218018,\n",
       " 0.5000108480453491,\n",
       " 0.4996241629123688,\n",
       " 0.49985137581825256,\n",
       " 0.5000765919685364,\n",
       " 0.4995763897895813,\n",
       " 0.49982351064682007,\n",
       " 0.5000300407409668,\n",
       " 0.4999943971633911,\n",
       " 0.5000185966491699,\n",
       " 0.500137448310852,\n",
       " 0.50015789270401,\n",
       " 0.5000894069671631,\n",
       " 0.5000951290130615,\n",
       " 0.5000688433647156,\n",
       " 0.4995584189891815,\n",
       " 0.49955883622169495,\n",
       " 0.5001322031021118,\n",
       " 0.5000410676002502,\n",
       " 0.5000507235527039,\n",
       " 0.5000056624412537,\n",
       " 0.5000932812690735,\n",
       " 0.49947163462638855,\n",
       " 0.4999394416809082,\n",
       " 0.5000186562538147,\n",
       " 0.5000037550926208,\n",
       " 0.4994681775569916,\n",
       " 0.5000351667404175,\n",
       " 0.5000924468040466,\n",
       " 0.4996010959148407,\n",
       " 0.4998212456703186,\n",
       " 0.49993884563446045,\n",
       " 0.4996069073677063,\n",
       " 0.5000068545341492,\n",
       " 0.5000774264335632,\n",
       " 0.4995868504047394,\n",
       " 0.5001402497291565,\n",
       " 0.49984270334243774,\n",
       " 0.4995975196361542,\n",
       " 0.49959227442741394,\n",
       " 0.5000149607658386,\n",
       " 0.5000465512275696,\n",
       " 0.4995723366737366,\n",
       " 0.4996455907821655,\n",
       " 0.500111997127533,\n",
       " 0.5000411868095398,\n",
       " 0.49961036443710327,\n",
       " 0.49976909160614014,\n",
       " 0.4999725818634033,\n",
       " 0.49995243549346924,\n",
       " 0.4996134042739868,\n",
       " 0.4994681775569916,\n",
       " 0.5001057982444763,\n",
       " 0.499539852142334,\n",
       " 0.4998053014278412,\n",
       " 0.5000178217887878,\n",
       " 0.49958324432373047,\n",
       " 0.4998168349266052,\n",
       " 0.49994927644729614,\n",
       " 0.49968788027763367,\n",
       " 0.4995923340320587,\n",
       " 0.5001276731491089,\n",
       " 0.4995554983615875,\n",
       " 0.49982601404190063,\n",
       " 0.5001258254051208,\n",
       " 0.5001655220985413,\n",
       " 0.499637633562088,\n",
       " 0.5000517964363098,\n",
       " 0.5001861453056335,\n",
       " 0.5000318884849548,\n",
       " 0.5000433921813965,\n",
       " 0.49971193075180054,\n",
       " 0.4996342957019806,\n",
       " 0.5000315308570862,\n",
       " 0.49992889165878296,\n",
       " 0.4996335208415985,\n",
       " 0.5000556707382202,\n",
       " 0.5001128911972046,\n",
       " 0.49963346123695374,\n",
       " 0.5001205205917358,\n",
       " 0.49958479404449463,\n",
       " 0.4994766116142273,\n",
       " 0.4996776282787323,\n",
       " 0.49959680438041687,\n",
       " 0.5000346302986145,\n",
       " 0.5001319646835327,\n",
       " 0.5000898838043213,\n",
       " 0.5000519752502441,\n",
       " 0.49997663497924805,\n",
       " 0.5000525712966919,\n",
       " 0.5000450015068054,\n",
       " 0.4997403919696808,\n",
       " 0.5000008940696716,\n",
       " 0.5001384615898132,\n",
       " 0.5000056028366089,\n",
       " 0.5000112652778625,\n",
       " 0.5001695156097412,\n",
       " 0.49965953826904297,\n",
       " 0.5000149607658386,\n",
       " 0.5000432729721069,\n",
       " 0.5000933408737183,\n",
       " 0.5001246929168701,\n",
       " 0.49963340163230896,\n",
       " 0.5000903010368347,\n",
       " 0.49996984004974365,\n",
       " 0.4995996654033661,\n",
       " 0.5001224279403687,\n",
       " 0.49957960844039917,\n",
       " 0.4999736547470093,\n",
       " 0.5001585483551025,\n",
       " 0.4999966025352478,\n",
       " 0.500166118144989,\n",
       " 0.5000799894332886,\n",
       " 0.4999908208847046,\n",
       " 0.5000587701797485,\n",
       " 0.5001856684684753,\n",
       " 0.500017523765564,\n",
       " 0.5001952648162842,\n",
       " 0.49997711181640625,\n",
       " 0.5000378489494324,\n",
       " 0.49989786744117737,\n",
       " 0.4995638430118561,\n",
       " 0.4999959468841553,\n",
       " 0.5001128315925598,\n",
       " 0.5000283718109131,\n",
       " 0.5001718997955322,\n",
       " 0.5000929832458496,\n",
       " 0.499983549118042,\n",
       " 0.4999886155128479,\n",
       " 0.49977871775627136,\n",
       " 0.4999666213989258,\n",
       " 0.5000349283218384,\n",
       " 0.4998388886451721,\n",
       " 0.500126838684082,\n",
       " 0.49983447790145874,\n",
       " 0.4998299479484558,\n",
       " 0.49983400106430054,\n",
       " 0.5000989437103271,\n",
       " 0.49974387884140015,\n",
       " 0.4999336004257202,\n",
       " 0.4999634027481079,\n",
       " 0.49957430362701416,\n",
       " 0.5000602602958679,\n",
       " 0.5000914931297302,\n",
       " 0.4999741315841675,\n",
       " 0.49998366832733154,\n",
       " 0.4998284578323364,\n",
       " 0.5000879168510437,\n",
       " 0.5000327229499817,\n",
       " 0.49955639243125916,\n",
       " 0.5001013875007629,\n",
       " 0.4998394846916199,\n",
       " 0.4996372163295746,\n",
       " 0.49975281953811646,\n",
       " 0.5001150369644165,\n",
       " 0.49973180890083313,\n",
       " 0.5000637173652649,\n",
       " 0.5001077055931091,\n",
       " 0.5000981092453003,\n",
       " 0.4995788335800171,\n",
       " 0.5000683069229126,\n",
       " 0.4998820126056671,\n",
       " 0.5000208616256714,\n",
       " 0.49963369965553284,\n",
       " 0.500184178352356,\n",
       " 0.49960359930992126,\n",
       " 0.5001113414764404,\n",
       " 0.49991536140441895,\n",
       " 0.4999537467956543,\n",
       " 0.49989357590675354,\n",
       " 0.4999338388442993,\n",
       " 0.49981653690338135,\n",
       " 0.49996423721313477,\n",
       " 0.4999745488166809,\n",
       " 0.5000945329666138,\n",
       " 0.4995698928833008,\n",
       " 0.49993646144866943,\n",
       " 0.4995894134044647,\n",
       " 0.49980196356773376,\n",
       " 0.4995495676994324,\n",
       " 0.49969178438186646,\n",
       " 0.5001533627510071,\n",
       " 0.49995219707489014,\n",
       " 0.49957048892974854,\n",
       " 0.499575138092041,\n",
       " 0.50011146068573,\n",
       " 0.49953991174697876,\n",
       " 0.5001038908958435,\n",
       " 0.5000405311584473,\n",
       " 0.5001190900802612,\n",
       " 0.4995632469654083,\n",
       " 0.50008225440979,\n",
       " 0.5001519322395325,\n",
       " 0.49961942434310913,\n",
       " 0.4999656677246094,\n",
       " 0.5000087022781372,\n",
       " 0.49960044026374817,\n",
       " 0.5000316500663757,\n",
       " 0.5000065565109253,\n",
       " 0.49963489174842834,\n",
       " 0.5000819563865662,\n",
       " 0.49956294894218445,\n",
       " 0.49960821866989136,\n",
       " 0.500145435333252,\n",
       " 0.4998033940792084,\n",
       " 0.5001026391983032,\n",
       " 0.5001638531684875,\n",
       " 0.4995771646499634,\n",
       " 0.499715119600296,\n",
       " 0.5001488924026489,\n",
       " 0.49959614872932434,\n",
       " 0.5000030994415283,\n",
       " 0.5000790953636169,\n",
       " 0.4995916187763214,\n",
       " 0.5000688433647156,\n",
       " 0.4997095465660095,\n",
       " 0.5000704526901245,\n",
       " 0.49975502490997314,\n",
       " 0.5001003742218018,\n",
       " 0.49958905577659607,\n",
       " 0.4995507597923279,\n",
       " 0.49984294176101685,\n",
       " 0.5000795125961304,\n",
       " 0.4995453953742981,\n",
       " 0.5000225305557251,\n",
       " 0.499471515417099,\n",
       " 0.49995338916778564,\n",
       " 0.500085175037384,\n",
       " 0.49953967332839966,\n",
       " 0.5001745223999023,\n",
       " 0.49997782707214355,\n",
       " 0.49981778860092163,\n",
       " 0.49955347180366516,\n",
       " 0.49955040216445923,\n",
       " 0.5000264644622803,\n",
       " 0.5000131726264954,\n",
       " 0.4996342957019806,\n",
       " 0.5001219511032104,\n",
       " 0.5001760721206665,\n",
       " 0.5000084638595581,\n",
       " 0.499914288520813,\n",
       " 0.49960798025131226,\n",
       " 0.4995638430118561,\n",
       " 0.49997007846832275,\n",
       " 0.49983835220336914,\n",
       " 0.5001890063285828,\n",
       " 0.49984210729599,\n",
       " 0.49982553720474243,\n",
       " 0.5000892877578735,\n",
       " 0.49981945753097534,\n",
       " 0.5001775026321411,\n",
       " 0.5001469254493713,\n",
       " 0.499652624130249,\n",
       " 0.5001247525215149,\n",
       " 0.4996500015258789,\n",
       " 0.5000423192977905,\n",
       " 0.49995189905166626,\n",
       " 0.5001712441444397,\n",
       " 0.4999156594276428,\n",
       " 0.5001276731491089,\n",
       " 0.4995545446872711,\n",
       " 0.499549925327301,\n",
       " 0.49997425079345703,\n",
       " 0.5001888275146484,\n",
       " 0.5000393986701965,\n",
       " 0.49957460165023804,\n",
       " 0.5000276565551758,\n",
       " 0.5001050233840942,\n",
       " 0.49970418214797974,\n",
       " 0.5000522136688232,\n",
       " 0.49975085258483887,\n",
       " 0.5000921487808228,\n",
       " 0.4998489022254944,\n",
       " 0.5000651478767395,\n",
       " 0.49958696961402893,\n",
       " 0.5000644326210022,\n",
       " 0.5000022649765015,\n",
       " 0.4996490478515625,\n",
       " 0.499542772769928,\n",
       " 0.4998077154159546,\n",
       " 0.5001530647277832,\n",
       " 0.5000751614570618,\n",
       " 0.4995921552181244,\n",
       " 0.5000084042549133,\n",
       " 0.49946901202201843,\n",
       " 0.5001049637794495,\n",
       " 0.5001544952392578,\n",
       " 0.49946263432502747,\n",
       " 0.49981552362442017,\n",
       " 0.49958181381225586,\n",
       " 0.5000036358833313,\n",
       " 0.4996216297149658,\n",
       " 0.5001526474952698,\n",
       " 0.5001436471939087,\n",
       " 0.49981242418289185,\n",
       " 0.49953481554985046,\n",
       " 0.5001444220542908,\n",
       " 0.5001596212387085,\n",
       " 0.5000244379043579,\n",
       " 0.500192403793335,\n",
       " 0.49997198581695557,\n",
       " 0.4998246431350708,\n",
       " 0.4999685287475586,\n",
       " 0.4999989867210388,\n",
       " 0.5000254511833191,\n",
       " 0.4997987449169159,\n",
       " 0.4996092915534973,\n",
       " 0.499994158744812,\n",
       " 0.5001001954078674,\n",
       " 0.500068724155426,\n",
       " 0.4994756579399109,\n",
       " 0.5000849962234497,\n",
       " 0.4999345541000366,\n",
       " 0.49999183416366577,\n",
       " 0.5001259446144104,\n",
       " 0.5000137090682983,\n",
       " 0.49962690472602844,\n",
       " 0.4995826482772827,\n",
       " 0.5000960826873779,\n",
       " 0.49982529878616333,\n",
       " 0.49982720613479614,\n",
       " 0.4997997581958771,\n",
       " 0.49971845746040344,\n",
       " 0.4998188614845276,\n",
       " 0.50018709897995,\n",
       " 0.4995677173137665,\n",
       " 0.5000516176223755,\n",
       " 0.5001050233840942,\n",
       " 0.5000669360160828,\n",
       " 0.49961334466934204,\n",
       " 0.49960726499557495,\n",
       " 0.499997615814209,\n",
       " 0.5001427531242371,\n",
       " 0.49995338916778564,\n",
       " 0.5000032782554626,\n",
       " 0.4999839663505554,\n",
       " 0.49983370304107666,\n",
       " 0.4995671808719635,\n",
       " 0.49974584579467773,\n",
       " 0.500100314617157,\n",
       " 0.5000952482223511,\n",
       " 0.49996697902679443,\n",
       " 0.49995148181915283,\n",
       " 0.4995696544647217,\n",
       " 0.5001232028007507,\n",
       " 0.49992144107818604,\n",
       " 0.5000287890434265,\n",
       " 0.4994698464870453,\n",
       " 0.5001218914985657,\n",
       " 0.5001196265220642,\n",
       " 0.4999730587005615,\n",
       " 0.5000647902488708,\n",
       " 0.5000969171524048,\n",
       " 0.49995696544647217,\n",
       " 0.4999632239341736,\n",
       " 0.4994677007198334,\n",
       " 0.500093400478363,\n",
       " 0.500097393989563,\n",
       " 0.49957823753356934,\n",
       " 0.5000861883163452,\n",
       " 0.5000728964805603,\n",
       " 0.5001603364944458,\n",
       " 0.5000492334365845,\n",
       " 0.49959704279899597,\n",
       " 0.5000023245811462,\n",
       " 0.4999351501464844,\n",
       " ...]"
      ]
     },
     "execution_count": 1141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prob.item() for prob in calc_preds(coeffs, t_indep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "e22a96b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0020)"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.1)).float().mean()\n",
    "\n",
    "acc(coeffs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "66dfff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install --quiet hyperopt\n",
    "# !pip install --quiet \"ray[tune]\"\n",
    "# !pip install --quiet scvi-colab\n",
    "# from scvi_colab import install\n",
    "\n",
    "# install()\n",
    "\n",
    "\n",
    "# import ray\n",
    "# import scanpy as sc\n",
    "# import scvi\n",
    "# from ray import tune\n",
    "# from scvi import autotune\n",
    "# model_cls = scvi.model.SCVI\n",
    "# model_cls.setup_anndata(adata)\n",
    "# scvi_tuner = autotune.ModelTuner(model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "385450cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarkResults():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "7a58542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scgen\n",
    "adata.obs.rename({\"label\": \"condition\"}, axis=1, inplace=True)\n",
    "adata.obs[\"condition\"].replace({\"ctrl\": \"control\", \"stim\": \"stimulated\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02605-1\n",
    "\n",
    "# adata_t = adata[\n",
    "#     ~(\n",
    "#         (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "#         & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "#     )\n",
    "# ].copy()\n",
    "\n",
    "# cd4t_stim = adata[\n",
    "#     (\n",
    "#         (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "#         & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "#     )\n",
    "# ].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scgen.SCGEN.setup_anndata(adata_t, batch_key=\"condition\", labels_key=\"cell_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "05b5f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = scgen.SCGEN(adata_t, n_hidden=800, n_latent=100, n_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "214e901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(\n",
    "#     max_epochs=1, batch_size=32, early_stopping=True, early_stopping_patience=25\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "4f6f2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata_t.obsm[\"scgen\"] = model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "84889a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.neighbors(adata_t, use_rep=\"scgen\")\n",
    "# sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "5ec93614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "6a4a815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred, delta = model.predict(\n",
    "#     ctrl_key=\"control\", stim_key=\"stimulated\", celltype_to_predict=\"CD4 T cells\"\n",
    "# )\n",
    "\n",
    "# # we annotate the predicted cells to distinguish them later from ground truth cells.\n",
    "# pred.obs[\"condition\"] = \"prediction\"\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c5ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "8d6ca81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "b7007635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train = adata\n",
    "# ctrl_adata = adata[\n",
    "#     ((adata.obs[\"cell_type\"] == \"CD4 T cells\") & (adata.obs[\"condition\"] == \"control\"))\n",
    "# ]\n",
    "# stim_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'stimulated'))]\n",
    "\n",
    "# # concatenate pred, control and real CD4 T cells in to one object\n",
    "# eval_adata = ctrl_adata.concatenate(cd4t_stim, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "c1bc85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.pca(eval_adata)\n",
    "# sc.pl.pca(eval_adata, color=\"condition\", frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "66b16e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd4t_adata = adata[adata.obs[\"cell_type\"] == \"CD4 T cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "3508e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.rank_genes_groups(cd4t_adata, groupby=\"condition\", method=\"wilcoxon\")\n",
    "# diff_genes = cd4t_adata.uns[\"rank_genes_groups\"][\"names\"][\"stimulated\"]\n",
    "# diff_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_value = model.reg_mean_plot(\n",
    "#     eval_adata,\n",
    "#     axis_keys={\"x\": \"predicted stimulated\", \"y\": \"stimulated\"},\n",
    "#     gene_list=diff_genes[:10],\n",
    "#     top_100_genes=diff_genes,\n",
    "#     labels={\"x\": \"predicted\", \"y\": \"ground truth\"},\n",
    "#     show=True,\n",
    "#     legend=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.violin(eval_adata, keys=\"ISG15\", groupby=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pertpy as pt\n",
    "# import muon as mu\n",
    "# import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata = pt.dt.papalexi_2021()\n",
    "# for col in mdata.obs: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a027076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.normalize_total(mdata[\"rna\"])\n",
    "# sc.pp.log1p(mdata[\"rna\"])\n",
    "# sc.pp.highly_variable_genes(mdata[\"rna\"], subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.prot.pp.clr(mdata[\"adt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe04851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.pca(mdata[\"rna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5308a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate neighbors with the cosine distance similarly to the original Seurat implementation\n",
    "# sc.pp.neighbors(mdata[\"rna\"], metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0721f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.umap(mdata[\"rna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40747691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.umap(mdata[\"rna\"], color=[\"replicate\", \"Phase\", \"perturbation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f25d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms = pt.tl.Mixscape()\n",
    "\n",
    "# ms.perturbation_signature(\n",
    "#     mdata[\"rna\"],\n",
    "#     pert_key=\"perturbation\",\n",
    "#     control=\"NT\",\n",
    "#     split_by=\"replicate\",\n",
    "#     n_neighbors=20,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy of the object to recalculate the PCA.\n",
    "# Alternatively we could replace the X of the RNA part of our MuData object with the `X_pert` layer.\n",
    "# adata_pert = mdata[\"rna\"].copy()\n",
    "# adata_pert.X = adata_pert.layers[\"X_pert\"]\n",
    "# sc.pp.pca(adata_pert)\n",
    "# sc.pp.neighbors(adata_pert, metric=\"cosine\")\n",
    "# sc.tl.umap(adata_pert)\n",
    "# sc.pl.umap(adata_pert, color=[\"replicate\", \"Phase\", \"perturbation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3197d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms.mixscape(adata=mdata[\"rna\"], control=\"NT\", labels=\"gene_target\", layer=\"X_pert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ffa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata[\"rna\"].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.perturbscore(\n",
    "#     adata=mdata[\"rna\"], labels=\"gene_target\", target_gene=\"IFNGR2\", color=\"orange\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.settings.set_figure_params(figsize=(10, 10))\n",
    "# pt.pl.ms.violin(\n",
    "#     adata=mdata[\"rna\"],\n",
    "#     target_gene_idents=[\"NT\", \"IFNGR2 NP\", \"IFNGR2 KO\"],\n",
    "#     groupby=\"mixscape_class\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee147bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.heatmap(\n",
    "#     adata=mdata[\"rna\"],\n",
    "#     labels=\"gene_target\",\n",
    "#     target_gene=\"IFNGR2\",\n",
    "#     layer=\"X_pert\",\n",
    "#     control=\"NT\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d44870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata[\"adt\"].obs[\"mixscape_class_global\"] = mdata[\"rna\"].obs[\"mixscape_class_global\"]\n",
    "# pt.pl.ms.violin(\n",
    "#     adata=mdata[\"adt\"],\n",
    "#     target_gene_idents=[\"NT\", \"JAK2\", \"STAT1\", \"IFNGR1\", \"IFNGR2\", \"IRF1\"],\n",
    "#     keys=\"PDL1\",\n",
    "#     groupby=\"gene_target\",\n",
    "#     hue=\"mixscape_class_global\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms.lda(adata=mdata[\"rna\"], labels=\"gene_target\", layer=\"X_pert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.lda(adata=mdata[\"rna\"])\n",
    "#https://zenodo.org/record/7058382\n",
    "# folders = '/home/awahab/llm-testing/data_sets/'\n",
    "# fp1 = 'SC3_v3_NextGem_DI_CRISPR_A549_5K_Multiplex_count_raw_feature_bc_matrix.h5'\n",
    "# fp2 = 'SC3_v3_NextGem_DI_CRISPR_A549_5K_Multiplex_count_raw_molecule_info.h5'\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# import anndata\n",
    "\n",
    "# # Read the .h5 File\n",
    "# def explore_h5py_group(group, indent=0):\n",
    "#     \"\"\"Recursively print the contents of an h5py group/dataset.\"\"\"\n",
    "#     print(group.data.name)\n",
    "#     items = sorted(group.items())\n",
    "#     for name, item in items:\n",
    "#         if isinstance(item, h5py.Dataset):  # Check if item is a dataset\n",
    "#             print(\"  \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "#         elif isinstance(item, h5py.Group):  # Check if item is a group\n",
    "#             print(\"  \" * indent + f\"Group: {name}\")\n",
    "#             explore_h5py_group(item, indent + 1)  # Recursive call to explore subgroups\n",
    "\n",
    "# # Open your HDF5 file\n",
    "# with h5py.File(folders + fp1, 'r') as f:\n",
    "#     explore_h5py_group(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
