{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25361d3e",
   "metadata": {},
   "source": [
    "#! ls ./data_sets/* -lh\n",
    "#https://github.com/chriswi93/Neural-Networks-and-Logistic-Regression-Backpropagation-in-depth\n",
    "\n",
    "![Alt text](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-021-22197-x/MediaObjects/41467_2021_22197_Fig3_HTML.png?as=webp)\n",
    "\n",
    "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bib/22/4/10.1093_bib_bbaa268/1/m_bbaa268f1.jpeg?Expires=1695201196&Signature=1KEY92u4ZstK959i3C6haCKHZ7-6ghmNkBQwGELax4hVBn6N0o7lasyTNgnHk6sQ6eP2yiV~E51~X8JdkQkF9D5PfM7pk0N-z1rOF1HJpYaNBZ7IrUSqzdj-lQHw-TTBMjlW8rFKnSWg8~Y0y2y7q7a1hGweo3LHFNk7pSxu0kgYUaN54HwRrCWvpuMe0Eq~PL4oIh857EOSI9YaYyZ4U3ilKNy9bzbEHrLUiGOdfBBvJV09gq5g1Xp3rl49KqxwnpaFVs1qEj0z94TBYtJMDnUXEoV8ZXGJ2ESWxaXQRGziXBHA-b5l2Ac40c2eSVvTgqGFK2ClL0yGFZM5J458dg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3818fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cancer sample matrix was normalized by the Z-score method, \n",
    "#which scaled the mean of each row (corresponding to feature edge) to zero and variance to one. \n",
    "#First, the rows of the matrix were clustered using hierarchical clustering based on the complete linkage method with the cluster number set to 100, \n",
    "#and clusters containing more than 30 edges were retained.\n",
    "#We then computed the mean values of perturbation for each edge in each subtype through Z-scores.\n",
    "#For each subtype, we counted the percentage of edges whose absolute value of the average perturbation was greater than 0.5 in each retained cluster. \n",
    "#A cluster with a percentage greater than 70% was regarded as a perturbed cluster for this subtype. \n",
    "#All edges in all of the perturbed clusters for each subtype constituted the subtype-specific networks.\n",
    "#All genes involved in each subtype-specific network were used for pathway enrichment analysis by Metascape (http://metascape.org). \n",
    "#The KEGG and Reactome pathways with a P-value less than 0.01 were retained. \n",
    "#Finally, the subtype-specific pathways were identified.\n",
    "\n",
    "#grouping based on shared genes\n",
    "\n",
    "\n",
    "#network = nodes = cell\n",
    "#edges = shared gene expression above mean -> only retain those above 30 \n",
    "#graeter than > .5 of the zscore\n",
    "#a cluster with a percentage greater than ??? (look at ribosomes)\n",
    "# https://metascape.org/blog/\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3609c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncounts       ctrl =    7085.9976    pert =  7251.1616\n",
      "ngenes       ctrl =    1460.5028512358208    pert =  1472.5600646518021\n",
      "percent_mito       ctrl =    2.642741    pert =  2.799472\n",
      "percent_ribo       ctrl =    3.813907    pert =  3.8422022\n"
     ]
    }
   ],
   "source": [
    "#more datasets\n",
    "from scipy.sparse import csr_matrix, find\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas \n",
    "pandas.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# This is required to catch warnings when the multiprocessing module is used\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "import scanpy as sc\n",
    "\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "rowGeneExpression2 = defaultdict(dict)\n",
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "#one ='DatlingerBock2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "folders = '/home/awahab/llm-testing/data_sets/'\n",
    "#one = 'AdamsonWeissman2016_GSM2406675_10X001.h5ad' #sigmoid returns nan in 0th frame\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "one = 'SrivatsanTrapnell2020_sciplex2.h5ad'\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "\n",
    "\n",
    "adata = sc.read_h5ad(folders + one)\n",
    "#2. Non-negative matrix factorization (NMF)\n",
    "#3. Linear discriminant analysis (LDA)\n",
    "#adata.obs\n",
    "\n",
    "sc.pp.log1p(adata)\n",
    "#sc.pp.highly_variable_genes(adata)\n",
    "sc.pp.highly_variable_genes(adata, \n",
    "                                layer=None, \n",
    "                                n_top_genes=200, \n",
    "                                min_disp=0.5, \n",
    "                                max_disp=1, \n",
    "                                min_mean=0.0125, \n",
    "                                max_mean=3, \n",
    "                                span=0.3, \n",
    "                                n_bins=20, \n",
    "                                flavor='seurat_v3', \n",
    "                                subset=False, \n",
    "                                inplace=True, \n",
    "                                batch_key=None, \n",
    "                                check_values=True)\n",
    "\n",
    "sc.pp.pca(adata)\n",
    "#M = adata.X[:5000, ]\n",
    "found = find(adata.X)\n",
    "torch.manual_seed(440)\n",
    "\n",
    "#adata.obs.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "#adata.obs = adata.iloc[:5000]\n",
    "#adata.obs= adata.obs[adata.obs.iloc[:5000]]\n",
    "#adata.obs.iloc[:5000]\n",
    "#adata.var_names\n",
    "var_df = adata.var\n",
    "df = adata.obs#.iloc[:5000]\n",
    "df = df.drop(columns=['nperts'])\n",
    "df['percent_mito'] = 1\n",
    "def getMode(l): \n",
    "    return max(set(l), key=l.count)\n",
    "\n",
    "#sc.pp.filter_cells(adata, min_counts=None, min_genes=None, max_counts=None, max_genes=10, inplace=True, copy=False)\n",
    "#sc.pp.filter_genes(adata, min_counts=None, min_cells=None, max_counts=None, max_cells=None, inplace=True, copy=False)\n",
    "#sc.pp.highly_variable_genes(adata, layer=None, n_top_genes=None, min_disp=0.5, max_disp=inf, min_mean=0.0125, max_mean=3, span=0.3, n_bins=20, flavor='seurat', subset=False, inplace=True, batch_key=None, check_values=True)\n",
    "#sc.pp.regress_out(adata, keys, n_jobs=None, copy=False)\n",
    "\n",
    "#cell perturbation is defined as molecular response or gene expression that is different to what is \"normal\"\n",
    "\n",
    "from IPython.display import IFrame\n",
    "# check for expression values that are equal from crispr\n",
    "#join with gene ontology\n",
    "#this is a program\n",
    "#input an adata file\n",
    "#outputs a list of cell-IDs and the genes perturbed \n",
    "#and then what that gene does \n",
    "#and what interactions may occur with those perturbations \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical column\n",
    "df['perturbation_2'] = label_encoder1.fit_transform(df['perturbation_2'])\n",
    "\n",
    "# = df.perturbation_2.map(stimulated=1,unstimulated=2)\n",
    "#df\n",
    "df['target_2'] = label_encoder2.fit_transform(df['target'])\n",
    "\n",
    "# df\n",
    "#scipy.stats.zscore(adata.X[1,].data, axis=0, ddof=0, nan_policy='propagate')\n",
    "#talk to every lab in the nation and get/buy/ make a website with an \"offical sounding company name\" all their data\n",
    "#singlecelldata.com or find \n",
    "#scrape a list of all bio-labs doing single cell and get them to upload them to NYC open data or whatever - zenodo??\n",
    "#IFrame('https://www.shadertoy.com/embed/dlScDy?gui=true&t=10&paused=true&muted=false', width=700, height=350)\n",
    "cool_columns = 'ncounts ngenes percent_mito percent_ribo'.split(' ')\n",
    "for key in cool_columns:\n",
    "    ct = adata.obs[adata.obs['perturbation'] == 'control'][key].std()\n",
    "    pt = adata.obs[adata.obs['perturbation'] != 'control'][key].std()\n",
    "    print(key, '      ctrl =   ', ct, '   pert = ', pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45167ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "sums = []\n",
    "\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "control_variables = set(['ctrl', 'control', '*'])\n",
    "\n",
    "dependent_variables = list(df['perturbation'].map(lambda val: 0 if val in control_variables else 1).values)\n",
    "\n",
    "geneValues = defaultdict(int)\n",
    "columnMode = defaultdict(list)\n",
    "geneAverages = defaultdict(int)\n",
    "geneOccurences = defaultdict(int)\n",
    "geneVariance = defaultdict(list)\n",
    "cell_variance_score = defaultdict(int)\n",
    "\n",
    "row_variance = [] \n",
    "c,g,v = found\n",
    "\n",
    "cell_variance_score = {}\n",
    "for i in range(df.shape[0]): cell_variance_score[i]= 0\n",
    "\n",
    "for cell,gene,val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneValues[gene] += val\n",
    "    geneOccurences[gene] += 1\n",
    "    columnMode[gene].append(val)\n",
    "    \n",
    "for k in dict(geneValues):\n",
    "    geneAverages[k] =  geneValues[k] / geneOccurences[k]\n",
    "    \n",
    "for k in dict(geneValues): columnMode[k] = getMode(columnMode[k])\n",
    "    \n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneVariance[gene].append(abs(val - geneAverages[gene]))# ** 2\n",
    "    \n",
    "    \n",
    "for k in dict(geneAverages):  \n",
    "    geneVariance[k] = max(set(geneVariance[k]), key=geneVariance[k].count)\n",
    "\n",
    "geneModes = defaultdict(list)\n",
    "\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneModes[gene].append(abs(val))# ** 2\n",
    "\n",
    "for val in geneModes: geneModes[val] = max(set(geneModes[val]), key=geneModes[val].count)\n",
    "\n",
    "num_cells = len(df.select_dtypes(include=[int, float]).values.tolist())\n",
    "    \n",
    "mini_cell_var = defaultdict(list)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if (cellColorForGene - columnColor) < 0:\n",
    "        mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "\n",
    "        \n",
    "for key in mini_cell_var: mini_cell_var[key] = max(mini_cell_var[key])\n",
    "#get cell's max expression value above column average or mode        \n",
    "        \n",
    "df['geneVarianceScore'] = cell_variance_score.values()\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "\n",
    "\n",
    "for k,vi in enumerate(numerical_values):\n",
    "    x = math.ceil((i / 5904) * 50)\n",
    "    numerical_values[k] += adata.uns['pca']['variance_ratio'][x -1]\n",
    "    \n",
    "independent_variables = pd.DataFrame(numerical_values)\n",
    "\n",
    "vals += .01\n",
    "t_dep = tensor([float(i) for i in dependent_variables]) # pertrubations\n",
    "t_indep = tensor(numerical_values, dtype=torch.float)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "\n",
    "from scipy.sparse import csr_matrix, tril\n",
    "\n",
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals\n",
    "trn_split,val_split=RandomSplitter(seed=42)(independent_variables)\n",
    "\n",
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "\n",
    "indep_cols =  df.select_dtypes(include=[int, float]).columns.tolist()\n",
    "indep_cols\n",
    "\n",
    "len([item for item in list(t_dep) if item.item() == 0])\n",
    "len([item for item in list(t_dep) if item.item() > .5]) \n",
    "\n",
    "#len(numerical_values)\n",
    "#len([item for item in list(t_dep) if item.item() > -1])\n",
    "#len([item for item in list(t_dep) if item.item() == 1]) / len([item for item in list(t_dep) if item.item() > -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da8812f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0018,     0.1522,     0.3224,     1.0000,     0.7316,     1.0000,     0.5782],\n",
       "        [    0.0018,     0.0560,     0.1873,     1.0000,     0.4486,     0.3750,     0.7255],\n",
       "        [    0.0018,     0.1424,     0.3383,     1.0000,     0.5952,     0.0001,     0.7288],\n",
       "        [    0.0018,     0.1234,     0.3183,     1.0000,     0.3052,     0.6563,     0.8504],\n",
       "        [    0.0018,     0.0954,     0.2514,     1.0000,     0.1048,     0.3125,     0.5909],\n",
       "        [    0.0018,     0.0431,     0.1583,     1.0000,     0.6458,     1.0000,     0.2421],\n",
       "        [    0.0018,     0.0181,     0.0698,     1.0000,     0.3613,     0.6250,     0.6210],\n",
       "        ...,\n",
       "        [    1.0000,     0.1400,     0.3564,     1.0000,     0.4250,     1.0000,     0.5501],\n",
       "        [    1.0000,     0.1566,     0.4009,     1.0000,     0.5110,     1.0000,     0.6997],\n",
       "        [    1.0000,     0.0737,     0.2284,     1.0000,     0.4810,     1.0000,     0.2888],\n",
       "        [    1.0000,     0.0734,     0.2433,     1.0000,     0.4356,     0.0938,     0.6698],\n",
       "        [    1.0000,     0.1992,     0.4330,     1.0000,     0.5217,     1.0000,     0.4210],\n",
       "        [    1.0000,     0.0163,     0.0816,     1.0000,     0.4488,     0.6875,     0.4061],\n",
       "        [    1.0000,     0.3193,     0.5975,     1.0000,     0.4432,     0.7813,     0.2472]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numerical_values[0] += adata.uns['pca']['variance_ratio'][0]\n",
    "# numerical_values\n",
    "# numerical_values[0] += adata.uns['pca']['variance'][0]\n",
    "#adata.uns['pca']['variance']\n",
    "#t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd3dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct722, total_guess943, perb_total 4585, accuracy 0.7656415694591728\n",
      "precision 0.20567066521264996\n"
     ]
    }
   ],
   "source": [
    "cell_variance_score= defaultdict(int)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if abs(cellColorForGene) > columnColor and columnColor < 1:\n",
    "        #mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "l = cell_variance_score.values()   \n",
    "avg = sum(l) / len(l)\n",
    "avg = 0\n",
    "\n",
    "import random\n",
    "cvs = cell_variance_score.values()\n",
    "mini_cell_var.values()\n",
    "total_guess = len([item for key, item in enumerate(cvs) if item > avg])\n",
    "correct_guess = len([item for key, item in enumerate(cvs) if item > avg and dependent_variables[key] == 1])\n",
    "perb_total =  len([item for key, item in enumerate(dependent_variables) if dependent_variables[key] == 1])\n",
    "\n",
    "#correct_guess = len([item for key, item in enumerate(cell_variance_score.values()) if .5 > random.random() and dependent_variables[key] == 1])\n",
    "#print(f'guess_noPertAndIsNotPert{hand_pred[0]}')\n",
    "\n",
    "print(f'correct{correct_guess}, total_guess{total_guess}, perb_total {perb_total}, accuracy {correct_guess / total_guess}')\n",
    "print(f'precision {total_guess / perb_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c763167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #sc.pl.StackedViolin(adata, , groupby='', use_raw=None, log=False, num_categories=7, categories_order=None, title=None, figsize=None, gene_symbols=None, var_group_positions=None, var_group_labels=None, var_group_rotation=None, layer=None, standard_scale=None, ax=None, vmin=None, vmax=None, vcenter=None, norm=None)\n",
    "\n",
    "# sc.pl.StackedViolin(adata, list(hv_genes), groupby='perturbation', dendrogram=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f17ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg = list(hv_genes)[100:]\n",
    "# sc.pl.DotPlot(adata, hg,  groupby='perturbation').show()\n",
    "# sc.pl.MatrixPlot(adata, hg, groupby='perturbation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a36f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=adata.X.getcol(9400).todense()\n",
    "pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 ])\n",
    "\n",
    "\n",
    "not_pert_and_above_zero = ([k for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] == 1])\n",
    "not_pert_and_above_zero = ([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] == 1])\n",
    "\n",
    "for i in filter(lambda x: x[0] > -1, not_pert_and_above_zero):\n",
    "    pass\n",
    "len(not_pert_and_above_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c75d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "581 60\n",
      "0.906396255850234\n"
     ]
    }
   ],
   "source": [
    "count = []\n",
    "test = defaultdict(int)\n",
    "for i in high_variance_columns:\n",
    "    m=adata.X.getcol(i).todense()\n",
    "    mode = getMode(m.tolist()[0]) #switch to std\n",
    "    avg = sum(m.tolist()[0]) / len(m.tolist()[0])\n",
    "    pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] > 0])\n",
    "    not_pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] < 1])\n",
    "    #print(i,pert_and_above_zero ,( not_pert_and_above_zero + 1),)\n",
    "    #if not_pert_and_above_zero < 5 and pert_and_above_zero > 1: count += pert_and_above_zero\n",
    "    above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0])\n",
    "    eq_zero = len([i for k, i in enumerate(m.tolist()) if i[0] == 0])\n",
    "    test[i] = above_zero\n",
    " \n",
    "    cellCounts = 5904\n",
    "    if (above_zero > 30): continue # 90%\n",
    "\n",
    "    for key,element in enumerate(m.tolist()):\n",
    "        if element[0] > 0: count.append(key)\n",
    "    \n",
    "print(len(set(count)))\n",
    "count = set(count)\n",
    "print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]),len([x for row, x in enumerate(count) if dependent_variables[x] < 1]))\n",
    "print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]) / len([x for row, x in enumerate(count)]))\n",
    "#len([x for row, x in enumerate(count)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0051c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb0b6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "12156\n"
     ]
    }
   ],
   "source": [
    "category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "\n",
    "most_cells = category_indices[2]\n",
    "\n",
    "most_cell_indices = []\n",
    "for i in most_cells:\n",
    "    most_cell_indices.append(adata.obs.index.get_loc(i))\n",
    "\n",
    "a=most_cell_indices[0]\n",
    "b=most_cell_indices[10]\n",
    "\n",
    "b_matrix = adata.X.getrow(b).todense().tolist()[0]\n",
    "a_matrix = adata.X.getrow(a).todense().tolist()[0]\n",
    "# for k,v in enumerate(adata.X.getrow(a).todense().tolist()[0]):\n",
    "#     if b_matrix[k] == v: print(v)\n",
    "a_matrix\n",
    "print(len(most_cells))\n",
    "sum(a_matrix), sum(b_matrix)\n",
    "count = {}\n",
    "# for key,val in enumerate(a_matrix):\n",
    "#     for i in range(10):\n",
    "#     val2 = b_matrix[key]\n",
    "#     if (val == val2): count += 1\n",
    "        \n",
    "distance = defaultdict(int)\n",
    "indicesAbove = defaultdict(list)\n",
    "\n",
    "cellCountWithinGroup\n",
    "\n",
    "\n",
    "for row in range(5904):\n",
    "    m = adata.X.getrow(row).todense().tolist()[0]\n",
    "    for k in high_variance_columns:\n",
    "        if (geneAverages[k]) < m[k] and m[k] < 100:\n",
    "            distance[k] += m[k]\n",
    "            indicesAbove[row].append(k)\n",
    "            \n",
    "#getMode(list(count.values()))\n",
    "distance_max = max(list(distance.values()))\n",
    "\n",
    "for k in distance:\n",
    "    if distance[k] == distance_max: print(k)\n",
    "        \n",
    "#distance_max\n",
    "#getMode(indicesAbove)\n",
    "# indicesAbove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e311659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1011,\n",
       " 1,\n",
       " 1851,\n",
       " 639,\n",
       " 383,\n",
       " 113,\n",
       " 6,\n",
       " 29,\n",
       " 42,\n",
       " 1022,\n",
       " 1851,\n",
       " 2155,\n",
       " 1249,\n",
       " 13,\n",
       " 14,\n",
       " 2408,\n",
       " 2384,\n",
       " 10,\n",
       " 27,\n",
       " 1651,\n",
       " 32,\n",
       " 21,\n",
       " 574,\n",
       " 23,\n",
       " 31,\n",
       " 833,\n",
       " 2011,\n",
       " 869,\n",
       " 786,\n",
       " 29,\n",
       " 41,\n",
       " 156,\n",
       " 33,\n",
       " 33,\n",
       " 360,\n",
       " 2155,\n",
       " 71,\n",
       " 2384,\n",
       " 890,\n",
       " 645,\n",
       " 29,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 1249,\n",
       " 921,\n",
       " 29,\n",
       " 610,\n",
       " 1851,\n",
       " 580,\n",
       " 50,\n",
       " 42,\n",
       " 786,\n",
       " 53,\n",
       " 2082,\n",
       " 29,\n",
       " 22,\n",
       " 869,\n",
       " 140,\n",
       " 85,\n",
       " 8,\n",
       " 61,\n",
       " 1022,\n",
       " 574,\n",
       " 64,\n",
       " 65,\n",
       " 29,\n",
       " 5,\n",
       " 22,\n",
       " 41,\n",
       " 42,\n",
       " 27,\n",
       " 1143,\n",
       " 73,\n",
       " 746,\n",
       " 610,\n",
       " 27,\n",
       " 77,\n",
       " 78,\n",
       " 41,\n",
       " 990,\n",
       " 12,\n",
       " 29,\n",
       " 83,\n",
       " 234,\n",
       " 85,\n",
       " 1651,\n",
       " 40,\n",
       " 869,\n",
       " 26,\n",
       " 121,\n",
       " 156,\n",
       " 92,\n",
       " 27,\n",
       " 610,\n",
       " 29,\n",
       " 412,\n",
       " 921,\n",
       " 408,\n",
       " 24,\n",
       " 1270,\n",
       " 610,\n",
       " 27,\n",
       " 869,\n",
       " 21,\n",
       " 105,\n",
       " 10,\n",
       " 890,\n",
       " 20,\n",
       " 40,\n",
       " 42,\n",
       " 786,\n",
       " 40,\n",
       " 113,\n",
       " 2155,\n",
       " 921,\n",
       " 116,\n",
       " 2384,\n",
       " 27,\n",
       " 2,\n",
       " 869,\n",
       " 1022,\n",
       " 17,\n",
       " 574,\n",
       " 869,\n",
       " 125,\n",
       " 2576,\n",
       " 71,\n",
       " 7,\n",
       " 34,\n",
       " 746,\n",
       " 34,\n",
       " 5,\n",
       " 574,\n",
       " 645,\n",
       " 2384,\n",
       " 31,\n",
       " 869,\n",
       " 639,\n",
       " 38,\n",
       " 2384,\n",
       " 786,\n",
       " 142,\n",
       " 580,\n",
       " 29,\n",
       " 1143,\n",
       " 29,\n",
       " 610,\n",
       " 148,\n",
       " 2155,\n",
       " 1228,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 2384,\n",
       " 157,\n",
       " 1851,\n",
       " 26,\n",
       " 1022,\n",
       " 2384,\n",
       " 42,\n",
       " 27,\n",
       " 164,\n",
       " 869,\n",
       " 33,\n",
       " 167,\n",
       " 168,\n",
       " 574,\n",
       " 170,\n",
       " 610,\n",
       " 610,\n",
       " 610,\n",
       " 174,\n",
       " 175,\n",
       " 2155,\n",
       " 177,\n",
       " 178,\n",
       " 786,\n",
       " 2384,\n",
       " 2082,\n",
       " 740,\n",
       " 32,\n",
       " 786,\n",
       " 185,\n",
       " 869,\n",
       " 187,\n",
       " 29,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 2384,\n",
       " 194,\n",
       " 42,\n",
       " 27,\n",
       " 1041,\n",
       " 26,\n",
       " 2384,\n",
       " 32,\n",
       " 786,\n",
       " 202,\n",
       " 2384,\n",
       " 2384,\n",
       " 786,\n",
       " 1693,\n",
       " 207,\n",
       " 26,\n",
       " 2384,\n",
       " 360,\n",
       " 211,\n",
       " 1041,\n",
       " 213,\n",
       " 31,\n",
       " 2384,\n",
       " 890,\n",
       " 37,\n",
       " 218,\n",
       " 140,\n",
       " 1651,\n",
       " 24,\n",
       " 222,\n",
       " 2384,\n",
       " 17,\n",
       " 517,\n",
       " 2384,\n",
       " 227,\n",
       " 228,\n",
       " 1022,\n",
       " 33,\n",
       " 2384,\n",
       " 1022,\n",
       " 395,\n",
       " 36,\n",
       " 869,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 29,\n",
       " 32,\n",
       " 37,\n",
       " 360,\n",
       " 243,\n",
       " 2155,\n",
       " 33,\n",
       " 580,\n",
       " 247,\n",
       " 574,\n",
       " 277,\n",
       " 2384,\n",
       " 251,\n",
       " 252,\n",
       " 14,\n",
       " 254,\n",
       " 255,\n",
       " 42,\n",
       " 257,\n",
       " 645,\n",
       " 890,\n",
       " 40,\n",
       " 2384,\n",
       " 580,\n",
       " 20,\n",
       " 35,\n",
       " 1143,\n",
       " 890,\n",
       " 267,\n",
       " 268,\n",
       " 21,\n",
       " 21,\n",
       " 271,\n",
       " 2384,\n",
       " 639,\n",
       " 869,\n",
       " 21,\n",
       " 21,\n",
       " 41,\n",
       " 121,\n",
       " 29,\n",
       " 38,\n",
       " 21,\n",
       " 282,\n",
       " 1693,\n",
       " 610,\n",
       " 1011,\n",
       " 517,\n",
       " 287,\n",
       " 37,\n",
       " 37,\n",
       " 890,\n",
       " 29,\n",
       " 20,\n",
       " 37,\n",
       " 25,\n",
       " 295,\n",
       " 869,\n",
       " 24,\n",
       " 1022,\n",
       " 2155,\n",
       " 300,\n",
       " 574,\n",
       " 6,\n",
       " 610,\n",
       " 610,\n",
       " 305,\n",
       " 921,\n",
       " 6,\n",
       " 156,\n",
       " 33,\n",
       " 1041,\n",
       " 311,\n",
       " 14,\n",
       " 313,\n",
       " 26,\n",
       " 786,\n",
       " 2384,\n",
       " 574,\n",
       " 318,\n",
       " 2155,\n",
       " 1851,\n",
       " 321,\n",
       " 580,\n",
       " 35,\n",
       " 29,\n",
       " 325,\n",
       " 326,\n",
       " 574,\n",
       " 1041,\n",
       " 869,\n",
       " 31,\n",
       " 46,\n",
       " 332,\n",
       " 33,\n",
       " 334,\n",
       " 156,\n",
       " 890,\n",
       " 29,\n",
       " 41,\n",
       " 869,\n",
       " 42,\n",
       " 12,\n",
       " 342,\n",
       " 343,\n",
       " 412,\n",
       " 8,\n",
       " 610,\n",
       " 347,\n",
       " 27,\n",
       " 10,\n",
       " 740,\n",
       " 42,\n",
       " 2011,\n",
       " 1228,\n",
       " 9,\n",
       " 121,\n",
       " 11,\n",
       " 877,\n",
       " 41,\n",
       " 786,\n",
       " 2082,\n",
       " 2155,\n",
       " 362,\n",
       " 20,\n",
       " 2384,\n",
       " 1022,\n",
       " 366,\n",
       " 367,\n",
       " 610,\n",
       " 31,\n",
       " 4,\n",
       " 371,\n",
       " 746,\n",
       " 786,\n",
       " 35,\n",
       " 27,\n",
       " 376,\n",
       " 377,\n",
       " 19,\n",
       " 610,\n",
       " 1022,\n",
       " 381,\n",
       " 30,\n",
       " 921,\n",
       " 384,\n",
       " 574,\n",
       " 14,\n",
       " 387,\n",
       " 42,\n",
       " 34,\n",
       " 1011,\n",
       " 15,\n",
       " 392,\n",
       " 412,\n",
       " 1693,\n",
       " 869,\n",
       " 19,\n",
       " 397,\n",
       " 398,\n",
       " 877,\n",
       " 2384,\n",
       " 32,\n",
       " 402,\n",
       " 27,\n",
       " 2384,\n",
       " 405,\n",
       " 406,\n",
       " 574,\n",
       " 639,\n",
       " 26,\n",
       " 410,\n",
       " 21,\n",
       " 2,\n",
       " 36,\n",
       " 36,\n",
       " 877,\n",
       " 740,\n",
       " 73,\n",
       " 32,\n",
       " 740,\n",
       " 58,\n",
       " 877,\n",
       " 35,\n",
       " 33,\n",
       " 2082,\n",
       " 574,\n",
       " 610,\n",
       " 877,\n",
       " 412,\n",
       " 1022,\n",
       " 574,\n",
       " 26,\n",
       " 869,\n",
       " 2384,\n",
       " 1022,\n",
       " 1672,\n",
       " 31,\n",
       " 1,\n",
       " 869,\n",
       " 439,\n",
       " 1228,\n",
       " 441,\n",
       " 746,\n",
       " 610,\n",
       " 444,\n",
       " 890,\n",
       " 446,\n",
       " 2011,\n",
       " 58,\n",
       " 2384,\n",
       " 574,\n",
       " 639,\n",
       " 59,\n",
       " 1249,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 31,\n",
       " 59,\n",
       " 459,\n",
       " 29,\n",
       " 869,\n",
       " 46,\n",
       " 25,\n",
       " 2082,\n",
       " 59,\n",
       " 64,\n",
       " 35,\n",
       " 468,\n",
       " 29,\n",
       " 234,\n",
       " 2,\n",
       " 645,\n",
       " 574,\n",
       " 412,\n",
       " 2384,\n",
       " 19,\n",
       " 877,\n",
       " 20,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 1270,\n",
       " 610,\n",
       " 1651,\n",
       " 921,\n",
       " 58,\n",
       " 21,\n",
       " 277,\n",
       " 890,\n",
       " 574,\n",
       " 360,\n",
       " 574,\n",
       " 610,\n",
       " 921,\n",
       " 31,\n",
       " 496,\n",
       " 2384,\n",
       " 23,\n",
       " 73,\n",
       " 786,\n",
       " 501,\n",
       " 639,\n",
       " 14,\n",
       " 412,\n",
       " 2384,\n",
       " 574,\n",
       " 35,\n",
       " 877,\n",
       " 412,\n",
       " 574,\n",
       " 2155,\n",
       " 42,\n",
       " 59,\n",
       " 746,\n",
       " 515,\n",
       " 645,\n",
       " 35,\n",
       " 360,\n",
       " 14,\n",
       " 64,\n",
       " 35,\n",
       " 877,\n",
       " 523,\n",
       " 35,\n",
       " 18,\n",
       " 526,\n",
       " 610,\n",
       " 9,\n",
       " 529,\n",
       " 2384,\n",
       " 1041,\n",
       " 574,\n",
       " 1011,\n",
       " 395,\n",
       " 1143,\n",
       " 19,\n",
       " 786,\n",
       " 610,\n",
       " 574,\n",
       " 610,\n",
       " 42,\n",
       " 32,\n",
       " 574,\n",
       " 18,\n",
       " 26,\n",
       " 412,\n",
       " 412,\n",
       " 548,\n",
       " 34,\n",
       " 17,\n",
       " 42,\n",
       " 610,\n",
       " 58,\n",
       " 42,\n",
       " 41,\n",
       " 41,\n",
       " 277,\n",
       " 558,\n",
       " 1022,\n",
       " 2384,\n",
       " 42,\n",
       " 562,\n",
       " 33,\n",
       " 59,\n",
       " 746,\n",
       " 1022,\n",
       " 567,\n",
       " 2384,\n",
       " 569,\n",
       " 610,\n",
       " 786,\n",
       " 24,\n",
       " 990,\n",
       " 17,\n",
       " 41,\n",
       " 740,\n",
       " 869,\n",
       " 2384,\n",
       " 1143,\n",
       " 20,\n",
       " 1022,\n",
       " 582,\n",
       " 869,\n",
       " 2082,\n",
       " 610,\n",
       " 59,\n",
       " 990,\n",
       " 786,\n",
       " 2576,\n",
       " 32,\n",
       " 591,\n",
       " 34,\n",
       " 360,\n",
       " 23,\n",
       " 574,\n",
       " 2384,\n",
       " 597,\n",
       " 1022,\n",
       " 13,\n",
       " 13,\n",
       " 645,\n",
       " 869,\n",
       " 603,\n",
       " 2011,\n",
       " 31,\n",
       " 2082,\n",
       " 869,\n",
       " 1693,\n",
       " 610,\n",
       " 610,\n",
       " 574,\n",
       " 33,\n",
       " 412,\n",
       " 786,\n",
       " 610,\n",
       " 610,\n",
       " 2384,\n",
       " 618,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 639,\n",
       " 27,\n",
       " 30,\n",
       " 786,\n",
       " 64,\n",
       " 627,\n",
       " 26,\n",
       " 629,\n",
       " 610,\n",
       " 746,\n",
       " 412,\n",
       " 2384,\n",
       " 24,\n",
       " 27,\n",
       " 1011,\n",
       " 574,\n",
       " 412,\n",
       " 2384,\n",
       " 746,\n",
       " 38,\n",
       " 22,\n",
       " 786,\n",
       " 644,\n",
       " 20,\n",
       " 646,\n",
       " 1693,\n",
       " 26,\n",
       " 645,\n",
       " 2384,\n",
       " 34,\n",
       " 652,\n",
       " 1270,\n",
       " 786,\n",
       " 786,\n",
       " 921,\n",
       " 29,\n",
       " 890,\n",
       " 42,\n",
       " 517,\n",
       " 661,\n",
       " 2408,\n",
       " 14,\n",
       " 25,\n",
       " 26,\n",
       " 34,\n",
       " 31,\n",
       " 786,\n",
       " 383,\n",
       " 670,\n",
       " 14,\n",
       " 672,\n",
       " 746,\n",
       " 786,\n",
       " 12,\n",
       " 574,\n",
       " 610,\n",
       " 610,\n",
       " 41,\n",
       " 58,\n",
       " 25,\n",
       " 13,\n",
       " 890,\n",
       " 684,\n",
       " 14,\n",
       " 2384,\n",
       " 2576,\n",
       " 29,\n",
       " 689,\n",
       " 690,\n",
       " 71,\n",
       " 692,\n",
       " 277,\n",
       " 645,\n",
       " 2384,\n",
       " 1022,\n",
       " 40,\n",
       " 698,\n",
       " 21,\n",
       " 700,\n",
       " 701,\n",
       " 35,\n",
       " 703,\n",
       " 37,\n",
       " 705,\n",
       " 706,\n",
       " 2011,\n",
       " 24,\n",
       " 32,\n",
       " 710,\n",
       " 30,\n",
       " 921,\n",
       " 786,\n",
       " 714,\n",
       " 412,\n",
       " 277,\n",
       " 717,\n",
       " 20,\n",
       " 786,\n",
       " 59,\n",
       " 27,\n",
       " 33,\n",
       " 12,\n",
       " 1693,\n",
       " 574,\n",
       " 746,\n",
       " 38,\n",
       " 38,\n",
       " 2384,\n",
       " 41,\n",
       " 71,\n",
       " 412,\n",
       " 1672,\n",
       " 121,\n",
       " 645,\n",
       " 14,\n",
       " 37,\n",
       " 40,\n",
       " 2082,\n",
       " 156,\n",
       " 31,\n",
       " 1022,\n",
       " 19,\n",
       " 14,\n",
       " 33,\n",
       " 35,\n",
       " 2155,\n",
       " 786,\n",
       " 19,\n",
       " 33,\n",
       " 412,\n",
       " 64,\n",
       " 38,\n",
       " 2384,\n",
       " 41,\n",
       " 19,\n",
       " 757,\n",
       " 786,\n",
       " 5,\n",
       " 1228,\n",
       " 42,\n",
       " 25,\n",
       " 25,\n",
       " 33,\n",
       " 869,\n",
       " 156,\n",
       " 2384,\n",
       " 31,\n",
       " 574,\n",
       " 13,\n",
       " 26,\n",
       " 772,\n",
       " 42,\n",
       " 19,\n",
       " 775,\n",
       " 5,\n",
       " 2155,\n",
       " 2082,\n",
       " 28,\n",
       " 780,\n",
       " 26,\n",
       " 29,\n",
       " 41,\n",
       " 746,\n",
       " 13,\n",
       " 786,\n",
       " 58,\n",
       " 788,\n",
       " 27,\n",
       " 41,\n",
       " 791,\n",
       " 412,\n",
       " 610,\n",
       " 12,\n",
       " 41,\n",
       " 574,\n",
       " 1651,\n",
       " 1022,\n",
       " 412,\n",
       " 574,\n",
       " 2384,\n",
       " 802,\n",
       " 786,\n",
       " 27,\n",
       " 46,\n",
       " 786,\n",
       " 890,\n",
       " 40,\n",
       " 29,\n",
       " 574,\n",
       " 29,\n",
       " 21,\n",
       " 813,\n",
       " 46,\n",
       " 7,\n",
       " 816,\n",
       " 2082,\n",
       " 277,\n",
       " 23,\n",
       " 786,\n",
       " 821,\n",
       " 1022,\n",
       " 823,\n",
       " 746,\n",
       " 20,\n",
       " 1228,\n",
       " 827,\n",
       " 828,\n",
       " 277,\n",
       " 610,\n",
       " 574,\n",
       " 26,\n",
       " 833,\n",
       " 834,\n",
       " 5,\n",
       " 836,\n",
       " 837,\n",
       " 35,\n",
       " 79,\n",
       " 79,\n",
       " 42,\n",
       " 786,\n",
       " 2384,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 786,\n",
       " 17,\n",
       " 1022,\n",
       " 610,\n",
       " 412,\n",
       " 36,\n",
       " 23,\n",
       " 854,\n",
       " 277,\n",
       " 786,\n",
       " 574,\n",
       " 64,\n",
       " 859,\n",
       " 41,\n",
       " 2384,\n",
       " 610,\n",
       " 639,\n",
       " 864,\n",
       " 29,\n",
       " 1228,\n",
       " 867,\n",
       " 1851,\n",
       " 27,\n",
       " 277,\n",
       " 277,\n",
       " 890,\n",
       " 786,\n",
       " 746,\n",
       " 20,\n",
       " 574,\n",
       " 13,\n",
       " 412,\n",
       " 360,\n",
       " 880,\n",
       " 35,\n",
       " 1228,\n",
       " 786,\n",
       " 786,\n",
       " 610,\n",
       " 1851,\n",
       " 815,\n",
       " 1851,\n",
       " 1228,\n",
       " 746,\n",
       " 41,\n",
       " 786,\n",
       " 35,\n",
       " 786,\n",
       " 40,\n",
       " 869,\n",
       " 2384,\n",
       " 42,\n",
       " 610,\n",
       " 610,\n",
       " 14,\n",
       " 902,\n",
       " 14,\n",
       " 904,\n",
       " 277,\n",
       " 27,\n",
       " 27,\n",
       " 610,\n",
       " 909,\n",
       " 910,\n",
       " 31,\n",
       " 869,\n",
       " 913,\n",
       " 914,\n",
       " 41,\n",
       " 29,\n",
       " 64,\n",
       " 1228,\n",
       " 645,\n",
       " 27,\n",
       " 40,\n",
       " 408,\n",
       " 27,\n",
       " 360,\n",
       " 32,\n",
       " 833,\n",
       " 869,\n",
       " 1851,\n",
       " 10,\n",
       " 930,\n",
       " 21,\n",
       " 32,\n",
       " 1192,\n",
       " 20,\n",
       " 935,\n",
       " 46,\n",
       " 35,\n",
       " 8,\n",
       " 29,\n",
       " 1011,\n",
       " 36,\n",
       " 21,\n",
       " 1022,\n",
       " 2384,\n",
       " 921,\n",
       " 786,\n",
       " 610,\n",
       " 869,\n",
       " 277,\n",
       " 2082,\n",
       " 951,\n",
       " 952,\n",
       " 1022,\n",
       " 20,\n",
       " 786,\n",
       " 29,\n",
       " 610,\n",
       " 574,\n",
       " 959,\n",
       " 960,\n",
       " 30,\n",
       " 46,\n",
       " 890,\n",
       " 964,\n",
       " 965,\n",
       " 2384,\n",
       " 990,\n",
       " 21,\n",
       " 412,\n",
       " 970,\n",
       " 746,\n",
       " 972,\n",
       " 2155,\n",
       " 33,\n",
       " 27,\n",
       " 877,\n",
       " 27,\n",
       " 1249,\n",
       " 277,\n",
       " 38,\n",
       " 990,\n",
       " 27,\n",
       " 877,\n",
       " 984,\n",
       " 59,\n",
       " 59,\n",
       " 27,\n",
       " 121,\n",
       " 412,\n",
       " 990,\n",
       " 1022,\n",
       " 992,\n",
       " 993,\n",
       " 19,\n",
       " 2011,\n",
       " 996,\n",
       " 24,\n",
       " 277,\n",
       " 746,\n",
       " ...]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cellCountWithinGroup = list(range(5904))\n",
    "\n",
    "for k in geneAboveMeanOccurances: \n",
    "    for row in geneAboveMeanOccurances[k]:\n",
    "        cellCountWithinGroup[row] = len(geneAboveMeanOccurances[k])\n",
    "        \n",
    "#cellCountWithinGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f01653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.zscore(adata.X.getcol(0).todense().tolist())\n",
    "indicesAbove = dict(indicesAbove)\n",
    "\n",
    "# for cell,gene,val in zip(c,g,v):\n",
    "#     if gene not in high_variance_columns: continue\n",
    "#     geneValues[gene] += val\n",
    "#     geneOccurences[gene] += 1\n",
    "#     columnMode[gene].append(val)\n",
    "\n",
    "timesAbove = defaultdict(int)\n",
    "geneAboveMeanOccurances = defaultdict(list)\n",
    "\n",
    "for row in dict(indicesAbove): \n",
    "    for column in indicesAbove[row]: \n",
    "        geneAboveMeanOccurances[column].append(row)\n",
    "        \n",
    "#or key in timesAbove: print(timesAbove)\n",
    "#magicValues = list(count_per_category.to_dict().values())\n",
    "\n",
    "prob_perts = {} #cell with probability of perturbation\n",
    "\n",
    "filteredGeneCellLists = defaultdict(list)\n",
    "\n",
    "threshold = 30\n",
    "\n",
    "for geneList in geneAboveMeanOccurances:\n",
    "    cellsWithGene = geneAboveMeanOccurances[geneList]\n",
    "    if  threshold < len(cellsWithGene) and len(cellsWithGene) < 100:\n",
    "        filteredGeneCellLists[geneList] = cellsWithGene\n",
    "\n",
    "cellToGeneEmbedding = [[] for i in range(5904)]\n",
    "\n",
    "for column in filteredGeneCellLists:\n",
    "    cellList = filteredGeneCellLists[column]\n",
    "    for cellRow in cellList:\n",
    "        cellToGeneEmbedding[cellRow].append(column)\n",
    "    \n",
    "cellToGeneEmbedding\n",
    "\n",
    "\n",
    "#divide all genes by 33k and then sum ? or get highest one \n",
    "#convert \n",
    "\n",
    "cellCount = 0\n",
    "for cellList in list(filteredGeneCellLists.values()):\n",
    "    cellCount += len(cellList)\n",
    "    \n",
    "totalCells = []\n",
    "for key in (filteredGeneCellLists.keys()):\n",
    "    cellList = filteredGeneCellLists[key]\n",
    "    totalCells += cellList\n",
    "    for cell in cellList:\n",
    "        gene = adata.var.iloc[cell].name\n",
    "        row = df.iloc[cell]\n",
    "        \n",
    "len(set(totalCells))\n",
    "\n",
    "len([item for key, item in enumerate(t_dep) if item.item() > .5 and key in totalCells])\n",
    "total = defaultdict(int)\n",
    "for row in range(500):\n",
    "    total[row] += sum(adata.X.getrow(row).data)\n",
    "avg = sum(list(total.values())) / 500\n",
    "\n",
    "avg\n",
    "counter = 0\n",
    "for key, item in enumerate(list(total.values())):\n",
    "    if item > avg:\n",
    "        counter += 1\n",
    "        \n",
    "counter\n",
    "count_per_category = df.groupby('perturbation').size()\n",
    "#count_per_category.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "a86216ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "52\n",
      "54\n",
      "42\n",
      "33\n",
      "62\n",
      "68\n",
      "42\n",
      "52\n",
      "26\n",
      "5\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# http# ! pip install biomart\n",
    "# mito_gene_names = sc.queries.mitochondrial_genes(\"hsapiens\")\n",
    "# mito_ensembl_ids = sc.queries.mitochondrial_genes(\"hsapiens\", attrname=\"ensembl_gene_id\")\n",
    "\n",
    "\n",
    "# mito_gene_names_fly = sc.queries.mitochondrial_genes(\"dmelanogaster\", chromosome=\"mitochondrion_genome\")\n",
    "\n",
    "\n",
    "# import scanpy as sc\n",
    "# sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=\"hsapiens\")\n",
    "# sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}, org=\"hsapiens\")\n",
    "\n",
    "\n",
    "# pbmcs = sc.datasets.pbmc68k_reduced()\n",
    "# sc.tl.rank_genes_groups(pbmcs, \"bulk_labels\")\n",
    "# sc.queries.enrich(pbmcs, \"CD34+\")\n",
    "\n",
    "# pbmcs\n",
    "category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "\n",
    "df.index.get_loc('TACTTGACCCCN')\n",
    "\n",
    "allRows = defaultdict(int)\n",
    "categories = df['perturbation'].unique()\n",
    "for i, group in enumerate(category_indices):\n",
    "    for row in group:\n",
    "        allRows[categories[i]] += 1\n",
    "        #allRows.append(df.index.get_loc(row))\n",
    "        \n",
    "df.groupby('perturbation')\n",
    "#for every perturbation, find column where \n",
    "\n",
    "categories\n",
    "len(category_indices)\n",
    "#allRows\n",
    "\n",
    "groupCellCounts = list(allRows.values())\n",
    "\n",
    "nonZerosInColumn = list(test.values())\n",
    "\n",
    "for k,v in enumerate(groupCellCounts):\n",
    "    cellCount = nonZerosInColumn[k]\n",
    "    #if abs(cellCount - v) < 10: print(v)\n",
    "\n",
    "#adata.obs[adata.obs['perturbation'] == 'Essential_library_TUBB_2'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e238f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import interact\n",
    "# trn_xs = [1,2,3,4,5]\n",
    "# conts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\n",
    "\n",
    "# def iscore(nm, split):\n",
    "#     col = trn_xs[nm]\n",
    "#     return score(col, trn_y, split)\n",
    "# interact(nm=conts, split=15.5)(iscore);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "767d5681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1001' class='' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1001/1001 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.31893939393939397, 0.44222222222222224, 421, 1990)\n",
      "(0.328030303030303, 0.4811111111111111, 433, 2165)\n",
      "(0.4803030303030303, 0.8577777777777778, 634, 3860)\n",
      "(0.475, 0.9082222222222223, 627, 4087)\n",
      "(0.47878787878787876, 0.9524444444444444, 632, 4286)\n",
      "(0.49318181818181817, 0.9775555555555555, 651, 4399)\n",
      "(0.5613636363636364, 0.9922222222222222, 741, 4465)\n",
      "(0.7, 1.0037777777777779, 924, 4517)\n",
      "(0.7856060606060606, 1.0077777777777779, 1037, 4535)\n",
      "(0.8113636363636364, 1.0102222222222221, 1071, 4546)\n",
      "(0.8265151515151515, 1.0113333333333334, 1091, 4551)\n",
      "(0.8462121212121212, 1.010888888888889, 1117, 4549)\n",
      "(0.8674242424242424, 1.0097777777777779, 1145, 4544)\n",
      "(0.8893939393939394, 1.008, 1174, 4536)\n",
      "(0.9151515151515152, 1.0075555555555555, 1208, 4534)\n",
      "(0.928030303030303, 1.007111111111111, 1225, 4532)\n",
      "(0.9401515151515152, 1.0064444444444445, 1241, 4529)\n",
      "(0.946969696969697, 1.0062222222222221, 1250, 4528)\n",
      "(0.956060606060606, 1.006, 1262, 4527)\n",
      "(0.9636363636363636, 1.006, 1272, 4527)\n",
      "(0.968939393939394, 1.0062222222222221, 1279, 4528)\n",
      "(0.9704545454545455, 1.006, 1281, 4527)\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_prediction(test_predictions):\n",
    "    ctrl = test_predictions.sum(1).tolist()[0]\n",
    "    isFalse = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) <= ctrl and t_dep[idx] == 0])\n",
    "    isTrue = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) > ctrl and t_dep[idx] == 1])\n",
    "    return (isFalse / 1320, isTrue / 4500, isFalse, isTrue)\n",
    "def plot_loss(l):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "    plt.plot(l) #orange false ctrl\n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from fastprogress.fastprogress import master_bar as mb\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "t_indep = torch.Tensor(numerical_values)\n",
    "#t_indep = t_indep / vals\n",
    "#λλλλλ.requires_grad_(True)\n",
    "#3 variations, test, t_indep and t_indep+embedding\n",
    "resultant_tensor = t_indep\n",
    "#resultant_tensor = torch.cat((t_indep,λλλλλ), 1)\n",
    "vals,indices = resultant_tensor.max(dim=0)\n",
    "resultant_tensor = resultant_tensor / vals\n",
    "test_indep = torch.tensor([[t_dep[k].item() for i in enumerate(range(resultant_tensor.shape[1]))] for k, i in enumerate(range(resultant_tensor.shape[0]))])\n",
    "\n",
    "#resultant_tensor = test_indep\n",
    "\n",
    "\n",
    "dim = resultant_tensor.shape[1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim, dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=.1, \n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "n_iterations = 1000\n",
    "loss_track = []\n",
    "accuracy_track = []\n",
    "no_entropy = []\n",
    "mp = mb(range(1))\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "loss_function = torch.nn.BCELoss()\n",
    "for i in range(1):\n",
    "    for i in progress_bar(range(n_iterations + 1)):\n",
    "        loss = loss_function(model(resultant_tensor).sum(1).sigmoid(), t_dep)\n",
    "        optimizer.zero_grad()  # 3\n",
    "        loss.backward()  # 4\n",
    "        optimizer.step()  # 5\n",
    "        if i == 1 or i % 50 == 0:\n",
    "            test_predictions = model(resultant_tensor)\n",
    "            #print(loss.item(), test_predictions.sum().item() / 8)\n",
    "            print(test_prediction(test_predictions))\n",
    "        loss_track.append(loss.item())\n",
    "        accuracy_track.append(test_predictions.sum().item() / 8)\n",
    "        no_entropy += [test_predictions.sum().item() / 8]\n",
    "#         k = 100 * i\n",
    "#         x = np.arange(0, 2*k*np.pi/1000, 0.01)\n",
    "#         y1, y2 = no_entropy[-1], no_entropy[-1]\n",
    "#         graphs = [[no_entropy[-1],y1], [x,y2]]\n",
    "#         x_bounds = [0, 2*np.pi]\n",
    "#         y_bounds = [-1,1]\n",
    "#         mp.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d025c18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "sums = []\n",
    "\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "\n",
    "embedLayer = []\n",
    "for i in high_variance_columns:\n",
    "        intermediate = []\n",
    "        for i in adata.X.getcol(i).toarray():\n",
    "            intermediate.append(i[0])\n",
    "        embedLayer.append(intermediate)\n",
    "        \n",
    "mat_for_embed = np.random.rand( 5905, 200)\n",
    "for key,col in enumerate(list(high_variance_columns)[:200]):\n",
    "    m= adata.X.getcol(col)\n",
    "    m = m.todense().tolist()\n",
    "    for row,val in enumerate(m):\n",
    "        mat_for_embed[row, key] = val[0]\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = mat_for_embed\n",
    "plt.imshow(a[:80], cmap='nipy_spectral_r', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2018f829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 5905])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(list(filter(lambda x: x > 0,mat_for_embed[])))\n",
    "U, S, Vh = torch.linalg.svd(torch.tensor(mat_for_embed))\n",
    "#U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d65cd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #\n",
    " #rename from 0-30k to 0-200\n",
    "count = 0\n",
    "cont_keys = {}\n",
    "for key in filteredGeneCellLists:\n",
    "    cont_keys[key] = count\n",
    "    count += 1\n",
    "\n",
    "continuousFilteredGeneCellLists = {}\n",
    "\n",
    "for k in list(filteredGeneCellLists.keys()):\n",
    "    continuousFilteredGeneCellLists[cont_keys[k]] = filteredGeneCellLists[k]\n",
    "    \n",
    "#continuousFilteredGeneCellLists\n",
    "#cont_keys\n",
    "#len(list(continuousFilteredGeneCellLists.keys()))\n",
    "#cellCountWithinGroup\n",
    "#zscore\n",
    "#\n",
    "\n",
    "#3.4028237 * 10^38\n",
    "#continuousFilteredGeneCellLists check\n",
    "# x = cells in group(s) , cellCountWithinGroup\n",
    "# y = genes affected \n",
    "# z = cluster number\n",
    "\n",
    "#for each cell\n",
    "#make a graph -> \n",
    "\n",
    "#\n",
    "#negative * negative = positive, \n",
    "\n",
    "#x  cluster \"name\" or index (clusters should change)\n",
    "#y = genes above/below threshold \n",
    "#z = total dist above threshold\n",
    "\n",
    "\n",
    "#convert 200 dimensions to 3\n",
    "\n",
    "cellGroups = [0 for i in list(range(5905))]\n",
    "cellGroupLengths = [0 for i in list(range(5905))]\n",
    "cellDistCounts = [0 for i in list(range(5905))]\n",
    "for column in continuousFilteredGeneCellLists:\n",
    "    for cell in continuousFilteredGeneCellLists[column]:\n",
    "        cellGroups[cell] = column\n",
    "        cellGroupLengths[cell] = len(continuousFilteredGeneCellLists[column])\n",
    "        \n",
    "\n",
    "#len(list(filter(lambda x: x > 0, cellGroupLengths)))\n",
    "#30,000 digits -> 38 * 38 * 38 -> max 50,000 genes\n",
    "#on or off\n",
    "#binary \n",
    "#38+38+38 length list \n",
    "for idx, row in enumerate(mat_for_embed):\n",
    "    for val in row: \n",
    "        cellDistCounts[idx] += val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "fbb12978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  31,  51,  66,  68,  84,  87,  88,  98, 106, 110, 111, 112, 121, 122, 125, 144, 150, 158, 176, 195])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solve it from because it helps the wizards and its fun !\n",
    "##   *\n",
    "#   /_\\\n",
    "#  (@@)\n",
    "#  -T-\n",
    "#  /\\\n",
    "# |  \\\n",
    "#_|  \\_\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "d = [1, 2, 3]\n",
    "A = np.diag(d)  # a diagonal covariance matrix\n",
    "x = [4, -2, 5]  # a point of interest\n",
    "#dist = stats.multivariate_normal(mean=[0, 0, 0], cov=mat_for_embed[:200])\n",
    "\n",
    "\n",
    "\n",
    "#U, S, Vh = torch.linalg.svd(torch.tensor(mat_for_embed))\n",
    "#U\n",
    "\n",
    "#38\n",
    "#38\n",
    "#38\n",
    "#38 + 38 + 38 = 115 slots\n",
    "\n",
    "mat_for_embed # vals\n",
    "mat_for_embed #list of indices from clusters\n",
    "mat_for_embed[0].nonzero()[0]\n",
    "#100,000 = 200 * 5000 - 21 nonzeros in a cell - store 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "9725ae78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 3])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "data = torch.Tensor(mat_for_embed)\n",
    "#makeCoolStuff = [[float(k) for k in range(1)] for i in range(200)]\n",
    "#do what they want - invent from scratch\n",
    "\n",
    "cat_ = [i for i in (cellGroups,\n",
    "cellGroupLengths,\n",
    "cellDistCounts)]\n",
    "\n",
    "mat2 = []\n",
    "for col in cat_:\n",
    "    l = []\n",
    "    for row in col: \n",
    "        l.append(row)\n",
    "    mat2.append(l)\n",
    "    \n",
    "#am = torch.cat((cat_[0], cat_[1], cat_[2]), 1)\n",
    "am = torch.tensor(mat2)\n",
    "def customGeneMatrixFindPerturbations(M):\n",
    "    m = torch.ones(200, 5905)\n",
    "    m = M @ m\n",
    "    m = m @ torch.ones(5905, 50)\n",
    "    m = m @ torch.ones(50, 32).triu()\n",
    "    m = m @ torch.eye(32, 3).cos()\n",
    "    #m = m.float() @ am.float()\n",
    "    #torch.stft(m, 128)\n",
    "    # 3 numbers from 0 - 1\n",
    "    # cells in group(s) = x, cellCountWithinGroup\n",
    "    # genes affected = y, \n",
    "    # z = cluster number,\n",
    "    return m\n",
    "#    return M @ torch.ones(5905, 50)@ torch.ones(50, 32).triu()  @ torch.eye(32, 3).cos()\n",
    "\n",
    "class λλλ(nn.Module):\n",
    "    def __init__(self, idn, edn):\n",
    "        super(λλλ, self).__init__()\n",
    "        self.λ = nn.Sequential(nn.Linear(idn, edn))\n",
    "    def forward(self, x):\n",
    "        return customGeneMatrixFindPerturbations(x)\n",
    "model = λλλ(data.shape[1], 3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "# encoder_layer = nn.TransformerEncoderLayer(d_model=80, nhead=8)\n",
    "# transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "# src = torch.rand(20, 80)\n",
    "# out = transformer_encoder(src)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     output = model(data)\n",
    "#     #loss = criterion(output, data)\n",
    "#     #optimizer.zero_grad()\n",
    "#     #loss.backward()\n",
    "#     #optimizer.step()\n",
    "#     #     if epoch % 100 == 0:\n",
    "#     #         print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "#     if epoch % 100 == 0: print('finish demo ', epoch)\n",
    "\n",
    "λλλλλ = model(data)\n",
    "λλλλλ.shape#, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c82ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "380198e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 5905])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.rand(5905, 50)\n",
    "tensor2 = torch.rand(5905, 50)  # Note the shape change\n",
    "result =  tensor2 * tensor1\n",
    "torch.eye(3) @ torch.rand(3,3,3)\n",
    "λλλλλ.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "dbc59c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5403, 1.0000, 1.0000],\n",
       "        [1.0000, 0.5403, 1.0000],\n",
       "        [1.0000, 1.0000, 0.5403]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mat1 = torch.randn(2, 3)\n",
    "# mat2 = torch.randn(3, 3)\n",
    "# torch.mm(mat1, mat2)\n",
    "\n",
    "λλλλλ = λλλλλ @ torch.eye(3)\n",
    "a= torch.eye(3)\n",
    "a.cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the matrix before + after - 200x6k to 3x6k -> bright colors for rows with perturbations \n",
    "#perturbations defined as belonging to a group of rows that have multiple columns that are covarying from mean-zscore\n",
    "#makeCoolStuff = [[float(k) for k in range(5905)] for i in range(200)]\n",
    "tensor2 = torch.rand(5905, 200)\n",
    "\n",
    "tensor3 = torch.rand(5905, 50)\n",
    "tensor2.shape,tensor3.shape \n",
    "#(tensor2.t() @ tensor3.t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = mat_for_embed\n",
    "plt.imshow(λλλλλ[:3,].detach(), cmap='nipy_spectral_r', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.10xgenomics.com/resources/datasets/5-k-a-549-lung-carcinoma-cells-no-treatment-transduced-with-a-crispr-pool-3-1-standard-6-0-0\n",
    "# all_url = [\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406675_10X001.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406677_10X005.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406681_10X010.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AissaBenevolenskaya2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/ChangYe2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2017.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DixitRegev2016.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_protein.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_RNA.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_atscale.h5ad?download=1\",\n",
    "    \n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_highMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_lowMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GehringPachter2019.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/McFarlandTsherniak2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/NormanWeissman2019_filtered.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_essential.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_gwps.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_rpe1.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE106340.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE115943.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_11_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_8_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ShifrutMarson2018.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex2.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex3.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex4.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_day7neuron.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_iPSC.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRa.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRi.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/WeinrebKlein2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/XieHon2017.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ZhaoSims2021.h5ad?download=1\"\n",
    "# ]\n",
    "\n",
    "# import requests\n",
    " \n",
    "# # def download_url(url):\n",
    "# #   print(\"downloading: \",url)\n",
    "# #   # assumes that the last segment after the / represents the file name\n",
    "# #   # if url is abc/xyz/file.txt, the file name will be file.txt\n",
    "# #   file_name_start_pos = url.rfind(\"/\") + 1\n",
    "# #   file_name = url[file_name_start_pos:]\n",
    " \n",
    "# #   r = requests.get(url, stream=True)\n",
    "# #   if r.status_code == requests.codes.ok:\n",
    "# #     with open(file_name, 'wb') as f:\n",
    "# #       for data in r:\n",
    "# #         f.write(data)\n",
    "\n",
    "# #for link in url: download_url(link)\n",
    "#     #https://zenodo.org/record/7058382\n",
    "    \n",
    "# #find data set with some perturbed and some not\n",
    "# #train on a half with some of both \n",
    "# #apply to other half and see if predictions are true\n",
    "\n",
    "\n",
    "# import requests\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# # def download_url(url):\n",
    "# #   print(\"downloading: \",url)\n",
    "# #   # assumes that the last segment after the / represents the file name\n",
    "# #   # if url is abc/xyz/file.txt, the file name will be file.txt\n",
    "# #   file_name_start_pos = url.rfind(\"/\") + 1\n",
    "# #   file_name = url[file_name_start_pos:]\n",
    "\n",
    "# #   r = requests.get(url, stream=True)\n",
    "# #   if r.status_code == requests.codes.ok:\n",
    "# #     with open(file_name, 'wb') as f:\n",
    "# #       for data in r:\n",
    "# #         f.write(data)\n",
    "# #   return url\n",
    "\n",
    "# # results = ThreadPool(5).imap_unordered(download_url, url)\n",
    "# # for r in results:\n",
    "# #     print(r)\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# root_url = \"https://zenodo.org/record/7058382\"\n",
    "\n",
    "# def download_file(file_path):\n",
    "#     if os.path.isfile(folders+file_path): return print(f\"${file_path} already exists\")\n",
    "#     url = f\"{file_path}\"\n",
    "#     print(url)\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error downloading {file_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         # Extract the directory and filename from the file path\n",
    "#         directory, filename = os.path.split(file_path)\n",
    "#         # Create the directory if it doesn't exist\n",
    "#         os.makedirs(directory, exist_ok=True)\n",
    "#         # Save the file as JPEG\n",
    "#         try:\n",
    "#             image = Image.open(BytesIO(response.content))\n",
    "#             image.save(file_path, \"JPEG\")\n",
    "#             return file_path\n",
    "#         except IOError:\n",
    "#             return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Send an HTTP GET request to the URL\n",
    "# response = requests.get(root_url)\n",
    "\n",
    "# # Check if the request was successful\n",
    "# if response.status_code == 200:\n",
    "#     # Parse the HTML content of the response\n",
    "#     #soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Find all <a> tags that represent links\n",
    "#     #links = soup.find_all('a')\n",
    "\n",
    "#     # Extract the href attribute of each link\n",
    "#     file_urls = all_url\n",
    "\n",
    "#     # Create a ThreadPoolExecutor with maximum 256 worker threads\n",
    "#     executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "#     # Use a list to store the download tasks\n",
    "#     tasks = []\n",
    "\n",
    "#     # Use tqdm to create a progress bar\n",
    "#     with tqdm(total=len(file_urls)) as progress_bar:\n",
    "#         error_count = 0\n",
    "#         # Submit the download tasks\n",
    "#         for file_name in file_urls:\n",
    "#             task = executor.submit(download_file, file_name)\n",
    "#             tasks.append(task)\n",
    "\n",
    "#         # Process the completed tasks\n",
    "#         for completed_task in as_completed(tasks):\n",
    "#             result = completed_task.result()\n",
    "#             if result is None:\n",
    "#                 error_count += 1\n",
    "#             progress_bar.update(1)\n",
    "\n",
    "#     print(f\"All downloads completed, errors: {error_count}\")\n",
    "\n",
    "# from time import sleep\n",
    "\n",
    "# def add_features(df):\n",
    "# #     df['LogFare'] = np.log1p(df['Fare'])\n",
    "# #     df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n",
    "# #     df['Family'] = df.SibSp+df.Parch\n",
    "# #     df['Alone'] = df.Family==0\n",
    "# #     df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "# #     df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "# #     df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))\n",
    "# #    df.drop(columns=['n_perts'])\n",
    "#     return 10\n",
    "# loss_function = torch.nn.CrossEntropyLoss()\n",
    "#test_predictions = torch.softmax(model(t_indep), 1)\n",
    "# test_predictions = model(trn_indep)\n",
    "# # test_accuracy = flaoat(sum(test_predictions == y_test)) / y_test.shape[0]\n",
    "# # print(\"\\nFinal Test Accuracy: {}\".format(test_accuracy))\n",
    "#df\n",
    "\n",
    "#scarches.dataset.remove_sparsity(adata)\n",
    "#https://docs.scarches.org/en/latest/api/models.html\n",
    "# mdata = muon.read_10x_h5(\"pbmc_10k_protein_v3_filtered_feature_bc_matrix.h5\")\n",
    "# scvi.model.TOTALVI.setup_mudata(mdata, modalities={\"rna_layer\": \"rna\": \"protein_layer\": \"prot\"})\n",
    "# vae = scvi.model.TOTALVI(mdata)\n",
    "#https://docs.scvi-tools.org/en/stable/api/reference/scvi.module.LDVAE.html\n",
    "#[i for i in test_predictions.tolist() if i < 1]\n",
    "# Regularization in Logistic Regression\n",
    "# Regularization is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. Consequently, most logistic regression models use one of the following two strategies to dampen model complexity:\n",
    "\n",
    "# L2 regularization.\n",
    "# Early stopping, that is, limiting the number of training steps or the learning rate.\n",
    "# (We'll discuss a third strategy—L1 regularization—in a later module.)\n",
    "\n",
    "# Imagine that you assign a unique id to each example, and map each id to its own feature. If you don't specify a regularization function, the model will become completely overfit. That's because the model would try to drive loss to zero on all examples and never get there, driving the weights for each indicator feature to +infinity or -infinity. This can happen in high dimensional data with feature crosses, when there’s a huge mass of rare crosses that happen only on one example each.\n",
    "\n",
    "# Fortunately, using L2 or early stopping will prevent this problem.\n",
    "#[ x for x in [iden(sum(item), 10)  for item in test_predictions.tolist()] if x > .1]\n",
    "#plot(loss_track)\n",
    "\n",
    "def plot_loss(l):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "\n",
    "#     blue = [i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]]\n",
    "#     oj =[i for k,i in enumerate(rowGeneExpression.values()) if not dependent_variables[k]]\n",
    "#     blue.sort()\n",
    "#     oj.sort()\n",
    "#     plt.plot((blue)) #blue true peturbation \n",
    "    plt.plot(l) #orange false ctrl\n",
    "\n",
    "    #legends.append('param %d' % i)\n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "# #https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02021-3\n",
    "\n",
    "# # Medicine Finding anomalies in radiology images, including CT, MRI, and X-ray images; counting features in pathology slides; measuring features in ultrasounds; diagnosing diabetic retinopathy\n",
    "# #Biology Folding proteins; classifying proteins; many genomics tasks, such as tumor-normal sequencing and classifying clinically actionable genetic mutations; cell classification; analyzing protein/protein interactions\n",
    "# #Other applications Financial and logistical forecasting, text to speech, and much more…\n",
    "# # humor analysis - larry david vs seinfeld ? \n",
    "#https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework\n",
    "#handle \"values outside of domain\" by \"SVM\"\n",
    "#random forest classifier\n",
    "#logisitc regression - hard to get right\n",
    "#correct transformations, outlier handling, correct interactions\n",
    "#os.listdir('./data_sets')\n",
    "#wget -m http://www.example.com 2>&1 | grep '^--' | awk '{ print $3 }' | grep -v '\\.\\(css\\|js\\|png\\|gif\\|jpg\\|JPG\\)$' > urls.txt\n",
    "#https://academic.oup.com/bib/article/22/4/bbaa268/5943793\n",
    "#plot(loss_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1fe23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
