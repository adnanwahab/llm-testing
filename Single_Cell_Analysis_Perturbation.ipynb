{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25361d3e",
   "metadata": {},
   "source": [
    "#! ls ./data_sets/* -lh\n",
    "#https://github.com/chriswi93/Neural-Networks-and-Logistic-Regression-Backpropagation-in-depth\n",
    "\n",
    "![Alt text](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-021-22197-x/MediaObjects/41467_2021_22197_Fig3_HTML.png?as=webp)\n",
    "\n",
    "https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bib/22/4/10.1093_bib_bbaa268/1/m_bbaa268f1.jpeg?Expires=1695201196&Signature=1KEY92u4ZstK959i3C6haCKHZ7-6ghmNkBQwGELax4hVBn6N0o7lasyTNgnHk6sQ6eP2yiV~E51~X8JdkQkF9D5PfM7pk0N-z1rOF1HJpYaNBZ7IrUSqzdj-lQHw-TTBMjlW8rFKnSWg8~Y0y2y7q7a1hGweo3LHFNk7pSxu0kgYUaN54HwRrCWvpuMe0Eq~PL4oIh857EOSI9YaYyZ4U3ilKNy9bzbEHrLUiGOdfBBvJV09gq5g1Xp3rl49KqxwnpaFVs1qEj0z94TBYtJMDnUXEoV8ZXGJ2ESWxaXQRGziXBHA-b5l2Ac40c2eSVvTgqGFK2ClL0yGFZM5J458dg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3818fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cancer sample matrix was normalized by the Z-score method, \n",
    "#which scaled the mean of each row (corresponding to feature edge) to zero and variance to one. \n",
    "#First, the rows of the matrix were clustered using hierarchical clustering based on the complete linkage method with the cluster number set to 100, \n",
    "#and clusters containing more than 30 edges were retained.\n",
    "#We then computed the mean values of perturbation for each edge in each subtype through Z-scores.\n",
    "#For each subtype, we counted the percentage of edges whose absolute value of the average perturbation was greater than 0.5 in each retained cluster. \n",
    "#A cluster with a percentage greater than 70% was regarded as a perturbed cluster for this subtype. \n",
    "#All edges in all of the perturbed clusters for each subtype constituted the subtype-specific networks.\n",
    "#All genes involved in each subtype-specific network were used for pathway enrichment analysis by Metascape (http://metascape.org). \n",
    "#The KEGG and Reactome pathways with a P-value less than 0.01 were retained. \n",
    "#Finally, the subtype-specific pathways were identified.\n",
    "\n",
    "#grouping based on shared genes\n",
    "\n",
    "\n",
    "#network = nodes = cell\n",
    "#edges = shared gene expression above mean -> only retain those above 30 \n",
    "#graeter than > .5 of the zscore\n",
    "#a cluster with a percentage greater than ??? (look at ribosomes)\n",
    "# https://metascape.org/blog/\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3609c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncounts       ctrl =    7085.9976    pert =  7251.1616\n",
      "ngenes       ctrl =    1460.5028512358208    pert =  1472.5600646518021\n",
      "percent_mito       ctrl =    2.642741    pert =  2.799472\n",
      "percent_ribo       ctrl =    3.813907    pert =  3.8422022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"350\"\n",
       "            src=\"https://www.shadertoy.com/embed/dlScDy?gui=true&t=10&paused=true&muted=false\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b3d90f940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more datasets\n",
    "from scipy.sparse import csr_matrix, find\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas \n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "rowGeneExpression2 = defaultdict(dict)\n",
    "import math\n",
    "import torch\n",
    "pandas.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# This is required to catch warnings when the multiprocessing module is used\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "import scanpy as sc\n",
    "\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "\n",
    "\n",
    "#one ='DatlingerBock2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "folders = '/home/awahab/llm-testing/data_sets/'\n",
    "#one = 'AdamsonWeissman2016_GSM2406675_10X001.h5ad' #sigmoid returns nan in 0th frame\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "one = 'SrivatsanTrapnell2020_sciplex2.h5ad'\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "\n",
    "def readFiles():\n",
    "    adata = sc.read_h5ad(folders + one)\n",
    "    one ='DatlingerBock2017.h5ad'\n",
    "    return adata\n",
    "adata = sc.read_h5ad(folders + one)\n",
    "#2. Non-negative matrix factorization (NMF)\n",
    "#3. Linear discriminant analysis (LDA)\n",
    "#adata.obs\n",
    "\n",
    "sc.pp.log1p(adata)\n",
    "#sc.pp.highly_variable_genes(adata)\n",
    "sc.pp.highly_variable_genes(adata, \n",
    "                                layer=None, \n",
    "                                n_top_genes=200, \n",
    "                                min_disp=0.5, \n",
    "                                max_disp=1, \n",
    "                                min_mean=0.0125, \n",
    "                                max_mean=3, \n",
    "                                span=0.3, \n",
    "                                n_bins=20, \n",
    "                                flavor='seurat_v3', \n",
    "                                subset=False, \n",
    "                                inplace=True, \n",
    "                                batch_key=None, \n",
    "                                check_values=True)\n",
    "\n",
    "sc.pp.pca(adata)\n",
    "#M = adata.X[:5000, ]\n",
    "found = find(adata.X)\n",
    "torch.manual_seed(440)\n",
    "\n",
    "#adata.obs.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "#adata.obs = adata.iloc[:5000]\n",
    "#adata.obs= adata.obs[adata.obs.iloc[:5000]]\n",
    "#adata.obs.iloc[:5000]\n",
    "#adata.var_names\n",
    "var_df = adata.var\n",
    "df = adata.obs#.iloc[:5000]\n",
    "df = df.drop(columns=['nperts'])\n",
    "df['percent_mito'] = 1\n",
    "def getMode(l): \n",
    "    return max(set(l), key=l.count)\n",
    "\n",
    "#sc.pp.filter_cells(adata, min_counts=None, min_genes=None, max_counts=None, max_genes=10, inplace=True, copy=False)\n",
    "#sc.pp.filter_genes(adata, min_counts=None, min_cells=None, max_counts=None, max_cells=None, inplace=True, copy=False)\n",
    "#sc.pp.highly_variable_genes(adata, layer=None, n_top_genes=None, min_disp=0.5, max_disp=inf, min_mean=0.0125, max_mean=3, span=0.3, n_bins=20, flavor='seurat', subset=False, inplace=True, batch_key=None, check_values=True)\n",
    "#sc.pp.regress_out(adata, keys, n_jobs=None, copy=False)\n",
    "\n",
    "#cell perturbation is defined as molecular response or gene expression that is different to what is \"normal\"\n",
    "\n",
    "from IPython.display import IFrame\n",
    "# check for expression values that are equal from crispr\n",
    "#join with gene ontology\n",
    "#this is a program\n",
    "#input an adata file\n",
    "#outputs a list of cell-IDs and the genes perturbed \n",
    "#and then what that gene does \n",
    "#and what interactions may occur with those perturbations \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical column\n",
    "df['perturbation_2'] = label_encoder1.fit_transform(df['perturbation_2'])\n",
    "\n",
    "# = df.perturbation_2.map(stimulated=1,unstimulated=2)\n",
    "#df\n",
    "df['target_2'] = label_encoder2.fit_transform(df['target'])\n",
    "\n",
    "# df\n",
    "#scipy.stats.zscore(adata.X[1,].data, axis=0, ddof=0, nan_policy='propagate')\n",
    "#talk to every lab in the nation and get/buy/ make a website with an \"offical sounding company name\" all their data\n",
    "#singlecelldata.com or find \n",
    "#scrape a list of all bio-labs doing single cell and get them to upload them to NYC open data or whatever - zenodo??\n",
    "cool_columns = 'ncounts ngenes percent_mito percent_ribo'.split(' ')\n",
    "for key in cool_columns:\n",
    "    ct = adata.obs[adata.obs['perturbation'] == 'control'][key].std()\n",
    "    pt = adata.obs[adata.obs['perturbation'] != 'control'][key].std()\n",
    "    print(key, '      ctrl =   ', ct, '   pert = ', pt)\n",
    "IFrame('https://www.shadertoy.com/embed/dlScDy?gui=true&t=10&paused=true&muted=false', width=700, height=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45167ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4585"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "sums = []\n",
    "\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "control_variables = set(['ctrl', 'control', '*'])\n",
    "\n",
    "dependent_variables = list(df['perturbation'].map(lambda val: 0 if val in control_variables else 1).values)\n",
    "\n",
    "geneValues = defaultdict(int)\n",
    "columnMode = defaultdict(list)\n",
    "geneAverages = defaultdict(int)\n",
    "geneOccurences = defaultdict(int)\n",
    "geneVariance = defaultdict(list)\n",
    "cell_variance_score = defaultdict(int)\n",
    "\n",
    "row_variance = [] \n",
    "c,g,v = found\n",
    "\n",
    "cell_variance_score = {}\n",
    "for i in range(df.shape[0]): cell_variance_score[i]= 0\n",
    "\n",
    "for cell,gene,val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneValues[gene] += val\n",
    "    geneOccurences[gene] += 1\n",
    "    columnMode[gene].append(val)\n",
    "    \n",
    "for k in dict(geneValues):\n",
    "    geneAverages[k] =  geneValues[k] / geneOccurences[k]\n",
    "    \n",
    "for k in dict(geneValues): columnMode[k] = getMode(columnMode[k])\n",
    "    \n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneVariance[gene].append(abs(val - geneAverages[gene]))# ** 2\n",
    "    \n",
    "    \n",
    "for k in dict(geneAverages):  \n",
    "    geneVariance[k] = max(set(geneVariance[k]), key=geneVariance[k].count)\n",
    "\n",
    "geneModes = defaultdict(list)\n",
    "\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneModes[gene].append(abs(val))# ** 2\n",
    "\n",
    "for val in geneModes: geneModes[val] = max(set(geneModes[val]), key=geneModes[val].count)\n",
    "\n",
    "num_cells = len(df.select_dtypes(include=[int, float]).values.tolist())\n",
    "    \n",
    "mini_cell_var = defaultdict(list)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if (cellColorForGene - columnColor) < 0:\n",
    "        mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "\n",
    "        \n",
    "for key in mini_cell_var: mini_cell_var[key] = max(mini_cell_var[key])\n",
    "#get cell's max expression value above column average or mode        \n",
    "        \n",
    "df['geneVarianceScore'] = cell_variance_score.values()\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "\n",
    "\n",
    "for k,vi in enumerate(numerical_values):\n",
    "    x = math.ceil((i / 5904) * 50)\n",
    "    numerical_values[k] += adata.uns['pca']['variance_ratio'][x -1]\n",
    "    \n",
    "independent_variables = pd.DataFrame(numerical_values)\n",
    "\n",
    "vals += .01\n",
    "t_dep = tensor([float(i) for i in dependent_variables]) # pertrubations\n",
    "t_indep = tensor(numerical_values, dtype=torch.float)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "\n",
    "from scipy.sparse import csr_matrix, tril\n",
    "\n",
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals\n",
    "trn_split,val_split=RandomSplitter(seed=42)(independent_variables)\n",
    "\n",
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "\n",
    "indep_cols =  df.select_dtypes(include=[int, float]).columns.tolist()\n",
    "indep_cols\n",
    "\n",
    "len([item for item in list(t_dep) if item.item() == 0])\n",
    "len([item for item in list(t_dep) if item.item() > .5]) \n",
    "\n",
    "#len(numerical_values)\n",
    "#len([item for item in list(t_dep) if item.item() > -1])\n",
    "#len([item for item in list(t_dep) if item.item() == 1]) / len([item for item in list(t_dep) if item.item() > -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8812f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_values[0] += adata.uns['pca']['variance_ratio'][0]\n",
    "# numerical_values\n",
    "# numerical_values[0] += adata.uns['pca']['variance'][0]\n",
    "#adata.uns['pca']['variance']\n",
    "#t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd3dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct722, total_guess943, perb_total 4585, accuracy 0.7656415694591728\n",
      "precision 0.20567066521264996\n"
     ]
    }
   ],
   "source": [
    "cell_variance_score= defaultdict(int)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if abs(cellColorForGene) > columnColor and columnColor < 1:\n",
    "        #mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "l = cell_variance_score.values()   \n",
    "avg = sum(l) / len(l)\n",
    "avg = 0\n",
    "\n",
    "import random\n",
    "cvs = cell_variance_score.values()\n",
    "mini_cell_var.values()\n",
    "total_guess = len([item for key, item in enumerate(cvs) if item > avg])\n",
    "correct_guess = len([item for key, item in enumerate(cvs) if item > avg and dependent_variables[key] == 1])\n",
    "perb_total =  len([item for key, item in enumerate(dependent_variables) if dependent_variables[key] == 1])\n",
    "\n",
    "#correct_guess = len([item for key, item in enumerate(cell_variance_score.values()) if .5 > random.random() and dependent_variables[key] == 1])\n",
    "#print(f'guess_noPertAndIsNotPert{hand_pred[0]}')\n",
    "\n",
    "print(f'correct{correct_guess}, total_guess{total_guess}, perb_total {perb_total}, accuracy {correct_guess / total_guess}')\n",
    "print(f'precision {total_guess / perb_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c763167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #sc.pl.StackedViolin(adata, , groupby='', use_raw=None, log=False, num_categories=7, categories_order=None, title=None, figsize=None, gene_symbols=None, var_group_positions=None, var_group_labels=None, var_group_rotation=None, layer=None, standard_scale=None, ax=None, vmin=None, vmax=None, vcenter=None, norm=None)\n",
    "\n",
    "# sc.pl.StackedViolin(adata, list(hv_genes), groupby='perturbation', dendrogram=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f17ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg = list(hv_genes)[100:]\n",
    "# sc.pl.DotPlot(adata, hg,  groupby='perturbation').show()\n",
    "# sc.pl.MatrixPlot(adata, hg, groupby='perturbation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a36f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=adata.X.getcol(9400).todense()\n",
    "pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 ])\n",
    "\n",
    "\n",
    "not_pert_and_above_zero = ([k for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] == 1])\n",
    "not_pert_and_above_zero = ([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] == 1])\n",
    "\n",
    "for i in filter(lambda x: x[0] > -1, not_pert_and_above_zero):\n",
    "    pass\n",
    "len(not_pert_and_above_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c75d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "581 60\n",
      "0.906396255850234\n"
     ]
    }
   ],
   "source": [
    "count = []\n",
    "test = defaultdict(int)\n",
    "for i in high_variance_columns:\n",
    "    m=adata.X.getcol(i).todense()\n",
    "    mode = getMode(m.tolist()[0]) #switch to std\n",
    "    avg = sum(m.tolist()[0]) / len(m.tolist()[0])\n",
    "    pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] > 0])\n",
    "    not_pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] < 1])\n",
    "    #print(i,pert_and_above_zero ,( not_pert_and_above_zero + 1),)\n",
    "    #if not_pert_and_above_zero < 5 and pert_and_above_zero > 1: count += pert_and_above_zero\n",
    "    above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0])\n",
    "    eq_zero = len([i for k, i in enumerate(m.tolist()) if i[0] == 0])\n",
    "    test[i] = above_zero\n",
    " \n",
    "    cellCounts = 5904\n",
    "    if (above_zero > 30): continue # 90%\n",
    "\n",
    "    for key,element in enumerate(m.tolist()):\n",
    "        if element[0] > 0: count.append(key)\n",
    "    \n",
    "print(len(set(count)))\n",
    "count = set(count)\n",
    "print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]),len([x for row, x in enumerate(count) if dependent_variables[x] < 1]))\n",
    "print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]) / len([x for row, x in enumerate(count)]))\n",
    "#len([x for row, x in enumerate(count)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb0b6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "12156\n"
     ]
    }
   ],
   "source": [
    "category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "\n",
    "most_cells = category_indices[2]\n",
    "\n",
    "most_cell_indices = []\n",
    "for i in most_cells:\n",
    "    most_cell_indices.append(adata.obs.index.get_loc(i))\n",
    "\n",
    "a=most_cell_indices[0]\n",
    "b=most_cell_indices[10]\n",
    "\n",
    "b_matrix = adata.X.getrow(b).todense().tolist()[0]\n",
    "a_matrix = adata.X.getrow(a).todense().tolist()[0]\n",
    "# for k,v in enumerate(adata.X.getrow(a).todense().tolist()[0]):\n",
    "#     if b_matrix[k] == v: print(v)\n",
    "a_matrix\n",
    "print(len(most_cells))\n",
    "sum(a_matrix), sum(b_matrix)\n",
    "count = {}\n",
    "# for key,val in enumerate(a_matrix):\n",
    "#     for i in range(10):\n",
    "#     val2 = b_matrix[key]\n",
    "#     if (val == val2): count += 1\n",
    "        \n",
    "distance = defaultdict(int)\n",
    "indicesAbove = defaultdict(list)\n",
    "\n",
    "for row in range(5904):\n",
    "    m = adata.X.getrow(row).todense().tolist()[0]\n",
    "    for k in high_variance_columns:\n",
    "        if (geneAverages[k]) < m[k] and m[k] < 100:\n",
    "            distance[k] += m[k]\n",
    "            indicesAbove[row].append(k)\n",
    "            \n",
    "#getMode(list(count.values()))\n",
    "distance_max = max(list(distance.values()))\n",
    "\n",
    "for k in distance:\n",
    "    if distance[k] == distance_max: print(k)\n",
    "        \n",
    "#distance_max\n",
    "#getMode(indicesAbove)\n",
    "# indicesAbove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db96bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#cellCountWithinGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f01653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.zscore(adata.X.getcol(0).todense().tolist())\n",
    "indicesAbove = dict(indicesAbove)\n",
    "\n",
    "# for cell,gene,val in zip(c,g,v):\n",
    "#     if gene not in high_variance_columns: continue\n",
    "#     geneValues[gene] += val\n",
    "#     geneOccurences[gene] += 1\n",
    "#     columnMode[gene].append(val)\n",
    "\n",
    "timesAbove = defaultdict(int)\n",
    "geneAboveMeanOccurances = defaultdict(list)\n",
    "\n",
    "for row in dict(indicesAbove): \n",
    "    for column in indicesAbove[row]: \n",
    "        geneAboveMeanOccurances[column].append(row)\n",
    "        \n",
    "#or key in timesAbove: print(timesAbove)\n",
    "#magicValues = list(count_per_category.to_dict().values())\n",
    "\n",
    "prob_perts = {} #cell with probability of perturbation\n",
    "\n",
    "filteredGeneCellLists = defaultdict(list)\n",
    "\n",
    "threshold = 30\n",
    "\n",
    "for geneList in geneAboveMeanOccurances:\n",
    "    cellsWithGene = geneAboveMeanOccurances[geneList]\n",
    "    if  threshold < len(cellsWithGene) and len(cellsWithGene) < 100:\n",
    "        filteredGeneCellLists[geneList] = cellsWithGene\n",
    "\n",
    "cellToGeneEmbedding = [[] for i in range(5904)]\n",
    "\n",
    "for column in filteredGeneCellLists:\n",
    "    cellList = filteredGeneCellLists[column]\n",
    "    for cellRow in cellList:\n",
    "        cellToGeneEmbedding[cellRow].append(column)\n",
    "    \n",
    "cellToGeneEmbedding\n",
    "\n",
    "\n",
    "#divide all genes by 33k and then sum ? or get highest one \n",
    "#convert \n",
    "\n",
    "cellCount = 0\n",
    "for cellList in list(filteredGeneCellLists.values()):\n",
    "    cellCount += len(cellList)\n",
    "    \n",
    "totalCells = []\n",
    "for key in (filteredGeneCellLists.keys()):\n",
    "    cellList = filteredGeneCellLists[key]\n",
    "    totalCells += cellList\n",
    "    for cell in cellList:\n",
    "        gene = adata.var.iloc[cell].name\n",
    "        row = df.iloc[cell]\n",
    "        \n",
    "len(set(totalCells))\n",
    "\n",
    "len([item for key, item in enumerate(t_dep) if item.item() > .5 and key in totalCells])\n",
    "total = defaultdict(int)\n",
    "for row in range(500):\n",
    "    total[row] += sum(adata.X.getrow(row).data)\n",
    "avg = sum(list(total.values())) / 500\n",
    "\n",
    "avg\n",
    "counter = 0\n",
    "for key, item in enumerate(list(total.values())):\n",
    "    if item > avg:\n",
    "        counter += 1\n",
    "        \n",
    "counter\n",
    "count_per_category = df.groupby('perturbation').size()\n",
    "#count_per_category.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86216ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# http# ! pip install biomart\n",
    "# mito_gene_names = sc.queries.mitochondrial_genes(\"hsapiens\")\n",
    "# mito_ensembl_ids = sc.queries.mitochondrial_genes(\"hsapiens\", attrname=\"ensembl_gene_id\")\n",
    "\n",
    "\n",
    "# mito_gene_names_fly = sc.queries.mitochondrial_genes(\"dmelanogaster\", chromosome=\"mitochondrion_genome\")\n",
    "\n",
    "\n",
    "# import scanpy as sc\n",
    "# sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=\"hsapiens\")\n",
    "# sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}, org=\"hsapiens\")\n",
    "\n",
    "\n",
    "# pbmcs = sc.datasets.pbmc68k_reduced()\n",
    "# sc.tl.rank_genes_groups(pbmcs, \"bulk_labels\")\n",
    "# sc.queries.enrich(pbmcs, \"CD34+\")\n",
    "\n",
    "# pbmcs\n",
    "category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "\n",
    "df.index.get_loc('TACTTGACCCCN')\n",
    "\n",
    "allRows = defaultdict(int)\n",
    "categories = df['perturbation'].unique()\n",
    "for i, group in enumerate(category_indices):\n",
    "    for row in group:\n",
    "        allRows[categories[i]] += 1\n",
    "        #allRows.append(df.index.get_loc(row))\n",
    "        \n",
    "df.groupby('perturbation')\n",
    "#for every perturbation, find column where \n",
    "\n",
    "categories\n",
    "len(category_indices)\n",
    "#allRows\n",
    "\n",
    "groupCellCounts = list(allRows.values())\n",
    "\n",
    "nonZerosInColumn = list(test.values())\n",
    "\n",
    "for k,v in enumerate(groupCellCounts):\n",
    "    cellCount = nonZerosInColumn[k]\n",
    "    #if abs(cellCount - v) < 10: print(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1b459d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipywidgets import interact\n",
    "# trn_xs = [1,2,3,4,5]\n",
    "# conts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\n",
    "\n",
    "# def iscore(nm, split):\n",
    "#     col = trn_xs[nm]\n",
    "#     return score(col, trn_y, split)\n",
    "# interact(nm=conts, split=15.5)(iscore);\n",
    "\n",
    "cellCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6283f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "767d5681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1001' class='' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1001/1001 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.553030303030303, 0.5413333333333333, 730, 2436)\n",
      "(0.553030303030303, 0.5417777777777778, 730, 2438)\n",
      "(0.5212121212121212, 0.6906666666666667, 688, 3108)\n",
      "(0.5151515151515151, 0.8286666666666667, 680, 3729)\n",
      "(0.5174242424242425, 0.9002222222222223, 683, 4051)\n",
      "(0.5075757575757576, 0.9611111111111111, 670, 4325)\n",
      "(0.5174242424242425, 0.9817777777777777, 683, 4418)\n",
      "(0.5401515151515152, 0.9962222222222222, 713, 4483)\n",
      "(0.5954545454545455, 1.0062222222222221, 786, 4528)\n",
      "(0.6825757575757576, 1.016, 901, 4572)\n",
      "(0.7696969696969697, 1.018, 1016, 4581)\n",
      "(0.8287878787878787, 1.0175555555555555, 1094, 4579)\n",
      "(0.8651515151515151, 1.0164444444444445, 1142, 4574)\n",
      "(0.8954545454545455, 1.0146666666666666, 1182, 4566)\n",
      "(0.9143939393939394, 1.0124444444444445, 1207, 4556)\n",
      "(0.9356060606060606, 1.0117777777777779, 1235, 4553)\n",
      "(0.946969696969697, 1.0095555555555555, 1250, 4543)\n",
      "(0.9545454545454546, 1.0073333333333334, 1260, 4533)\n",
      "(0.9598484848484848, 1.006888888888889, 1267, 4531)\n",
      "(0.9681818181818181, 1.0053333333333334, 1278, 4524)\n",
      "(0.9734848484848485, 1.0044444444444445, 1285, 4520)\n",
      "(0.9734848484848485, 1.0042222222222221, 1285, 4519)\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_prediction(test_predictions):\n",
    "    ctrl = test_predictions.sum(1).tolist()[0]\n",
    "    isFalse = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) <= ctrl and t_dep[idx] == 0])\n",
    "    isTrue = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) > ctrl and t_dep[idx] == 1])\n",
    "    return (isFalse / 1320, isTrue / 4500, isFalse, isTrue)\n",
    "def plot_loss(l):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "    plt.plot(l) #orange false ctrl\n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from fastprogress.fastprogress import master_bar as mb\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "t_indep = torch.Tensor(numerical_values)\n",
    "#t_indep = t_indep / vals\n",
    "#λλλλλ.requires_grad_(True)\n",
    "#3 variations, test, t_indep and t_indep+embedding\n",
    "resultant_tensor = t_indep\n",
    "\n",
    "resultant_tensor = torch.cat((t_indep,λλλλλ), 1)\n",
    "#resultant_tensor = λλλλλ\n",
    "vals,indices = resultant_tensor.max(dim=0)\n",
    "resultant_tensor = resultant_tensor / vals\n",
    "test_indep = torch.tensor([[t_dep[k].item() for i in enumerate(range(resultant_tensor.shape[1]))] for k, i in enumerate(range(resultant_tensor.shape[0]))])\n",
    "\n",
    "dim = resultant_tensor.shape[1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim, dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=.1, \n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "n_iterations = 1000\n",
    "loss_track = []\n",
    "accuracy_track = []\n",
    "no_entropy = []\n",
    "mp = mb(range(1))\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "loss_function = torch.nn.BCELoss()\n",
    "for i in range(1):\n",
    "    for i in progress_bar(range(n_iterations + 1)):\n",
    "        loss = loss_function(model(resultant_tensor).sum(1).sigmoid(), t_dep)\n",
    "        optimizer.zero_grad()  # 3\n",
    "        loss.backward()  # 4\n",
    "        optimizer.step()  # 5\n",
    "        if i == 1 or i % 50 == 0:\n",
    "            test_predictions = model(resultant_tensor)\n",
    "            #print(loss.item(), test_predictions.sum().item() / 8)\n",
    "            print(test_prediction(test_predictions))\n",
    "        loss_track.append(loss.item())\n",
    "        accuracy_track.append(test_predictions.sum().item() / 8)\n",
    "        no_entropy += [test_predictions.sum().item() / 8]\n",
    "#         k = 100 * i\n",
    "#         x = np.arange(0, 2*k*np.pi/1000, 0.01)\n",
    "#         y1, y2 = no_entropy[-1], no_entropy[-1]\n",
    "#         graphs = [[no_entropy[-1],y1], [x,y2]]\n",
    "#         x_bounds = [0, 2*np.pi]\n",
    "#         y_bounds = [-1,1]\n",
    "#         mp.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d025c18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "sums = []\n",
    "\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "\n",
    "embedLayer = []\n",
    "for i in high_variance_columns:\n",
    "        intermediate = []\n",
    "        for i in adata.X.getcol(i).toarray():\n",
    "            intermediate.append(i[0])\n",
    "        embedLayer.append(intermediate)\n",
    "        \n",
    "mat_for_embed = np.random.rand( 5905, 200)\n",
    "for key,col in enumerate(list(high_variance_columns)[:200]):\n",
    "    m= adata.X.getcol(col)\n",
    "    m = m.todense().tolist()\n",
    "    for row,val in enumerate(m):\n",
    "        mat_for_embed[row, key] = val[0]\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = mat_for_embed\n",
    "plt.imshow(a[:80], cmap='nipy_spectral_r', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b21b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "cont_keys = {}\n",
    "for key in filteredGeneCellLists:\n",
    "    cont_keys[key] = count\n",
    "    count += 1\n",
    "\n",
    "continuousFilteredGeneCellLists = {}\n",
    "\n",
    "for k in list(filteredGeneCellLists.keys()):\n",
    "    continuousFilteredGeneCellLists[cont_keys[k]] = filteredGeneCellLists[k]\n",
    "    \n",
    "#continuousFilteredGeneCellLists\n",
    "#cont_keys\n",
    "#len(list(continuousFilteredGeneCellLists.keys()))\n",
    "#cellCountWithinGroup\n",
    "#zscore\n",
    "#\n",
    "\n",
    "#3.4028237 * 10^38\n",
    "#continuousFilteredGeneCellLists check\n",
    "# x = cells in group(s) , cellCountWithinGroup\n",
    "# y = genes affected \n",
    "# z = cluster number\n",
    "\n",
    "#for each cell\n",
    "#make a graph -> \n",
    "\n",
    "#\n",
    "#negative * negative = positive, \n",
    "\n",
    "#x  cluster \"name\" or index (clusters should change)\n",
    "#y = genes above/below threshold \n",
    "#z = total dist above threshold\n",
    "#convert 200 dimensions to 3\n",
    "cellGroups = [0 for i in list(range(5905))]\n",
    "cellGroupLengths = [0 for i in list(range(5905))]\n",
    "cellDistCounts = [0 for i in list(range(5905))]\n",
    "for column in continuousFilteredGeneCellLists:\n",
    "    for cell in continuousFilteredGeneCellLists[column]:\n",
    "        cellGroups[cell] = column\n",
    "        cellGroupLengths[cell] = len(continuousFilteredGeneCellLists[column])\n",
    "        \n",
    "\n",
    "#len(list(filter(lambda x: x > 0, cellGroupLengths)))\n",
    "#30,000 digits -> 38 * 38 * 38 -> max 50,000 genes\n",
    "#on or off\n",
    "#binary \n",
    "#38+38+38 length list \n",
    "for idx, row in enumerate(mat_for_embed):\n",
    "    for val in row: \n",
    "        cellDistCounts[idx] += val\n",
    "#remember when we focused at computer screen for 13 hours \n",
    "#and the characters moved on the screen slightly -> only a few people but they were focused on trying to use magic \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ab8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# import scanpy as sc\n",
    "# #solve it \n",
    "# ##   *\n",
    "# #   /_\\\n",
    "# #  (@@)\n",
    "# #---T----\n",
    "# #  /\\\n",
    "# #_|  \\_\n",
    "# #100,000 = 200 * 5000 - 21 nonzeros in a cell - store 1\n",
    "# #https://norvig.com/spell-correct.html\n",
    "\n",
    "# def readFiles():\n",
    "#     one ='DatlingerBock2017.h5ad'\n",
    "#     adata = sc.read_h5ad('./data_sets/' + one)\n",
    "#     return adata\n",
    "# d = [1, 2, 3]\n",
    "# A = np.diag(d)  # a diagonal covariance matrix\n",
    "# x = [4, -2, 5]  # a point of interest\n",
    "\n",
    "\n",
    "\n",
    "# adata = readFiles()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #solve it now \n",
    "# from collections import defaultdict\n",
    "# second = adata.X.A[2]\n",
    "# keys = defaultdict(int)\n",
    "# for row in range(100):\n",
    "#     first = adata.X.A[row]\n",
    "#     for key, val in enumerate(first): \n",
    "#         if val > 0:\n",
    "#             keys[key] += 1\n",
    "\n",
    "\n",
    "# #sum(second) / len(second)\n",
    "# def finish_demo(right_now): return 'solve it !'\n",
    "# finish_demo(1)\n",
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b6f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8fff528",
   "metadata": {},
   "outputs": [],
   "source": [
    "['BootstrapMethod',\n",
    " 'CensoredData',\n",
    " 'ConstantInputWarning',\n",
    " 'Covariance',\n",
    " 'DegenerateDataWarning',\n",
    " 'FitError',\n",
    " 'MonteCarloMethod',\n",
    " 'NearConstantInputWarning',\n",
    " 'PermutationMethod',\n",
    " '__all__',\n",
    " '__builtins__',\n",
    " '__cached__',\n",
    " '__doc__',\n",
    " '__file__',\n",
    " '__loader__',\n",
    " '__name__',\n",
    " '__package__',\n",
    " '__path__',\n",
    " '__spec__',\n",
    " '_axis_nan_policy',\n",
    " '_biasedurn',\n",
    " '_binned_statistic',\n",
    " '_binomtest',\n",
    " '_boost',\n",
    " '_censored_data',\n",
    " '_common',\n",
    " '_constants',\n",
    " '_continuous_distns',\n",
    " '_covariance',\n",
    " '_crosstab',\n",
    " '_discrete_distns',\n",
    " '_distn_infrastructure',\n",
    " '_distr_params',\n",
    " '_entropy',\n",
    " '_fit',\n",
    " '_hypotests',\n",
    " '_kde',\n",
    " '_ksstats',\n",
    " '_levy_stable',\n",
    " '_mannwhitneyu',\n",
    " '_morestats',\n",
    " '_mstats_basic',\n",
    " '_mstats_extras',\n",
    " '_multicomp',\n",
    " '_multivariate',\n",
    " '_mvn',\n",
    " '_odds_ratio',\n",
    " '_page_trend_test',\n",
    " '_qmc',\n",
    " '_qmc_cy',\n",
    " '_qmvnt',\n",
    " '_rcont',\n",
    " '_relative_risk',\n",
    " '_resampling',\n",
    " '_rvs_sampling',\n",
    " '_sensitivity_analysis',\n",
    " '_sobol',\n",
    " '_statlib',\n",
    " '_stats',\n",
    " '_stats_mstats_common',\n",
    " '_stats_py',\n",
    " '_stats_pythran',\n",
    " '_survival',\n",
    " '_tukeylambda_stats',\n",
    " '_variation',\n",
    " '_warnings_errors',\n",
    " 'alexandergovern',\n",
    " 'alpha',\n",
    " 'anderson',\n",
    " 'anderson_ksamp',\n",
    " 'anglit',\n",
    " 'ansari',\n",
    " 'arcsine',\n",
    " 'argus',\n",
    " 'barnard_exact',\n",
    " 'bartlett',\n",
    " 'bayes_mvs',\n",
    " 'bernoulli',\n",
    " 'beta',\n",
    " 'betabinom',\n",
    " 'betaprime',\n",
    " 'biasedurn',\n",
    " 'binned_statistic',\n",
    " 'binned_statistic_2d',\n",
    " 'binned_statistic_dd',\n",
    " 'binom',\n",
    " 'binom_test',\n",
    " 'binomtest',\n",
    " 'boltzmann',\n",
    " 'bootstrap',\n",
    " 'boschloo_exact',\n",
    " 'boxcox',\n",
    " 'boxcox_llf',\n",
    " 'boxcox_normmax',\n",
    " 'boxcox_normplot',\n",
    " 'bradford',\n",
    " 'brunnermunzel',\n",
    " 'burr',\n",
    " 'burr12',\n",
    " 'cauchy',\n",
    " 'chi',\n",
    " 'chi2',\n",
    " 'chi2_contingency',\n",
    " 'chisquare',\n",
    " 'circmean',\n",
    " 'circstd',\n",
    " 'circvar',\n",
    " 'combine_pvalues',\n",
    " 'contingency',\n",
    " 'cosine',\n",
    " 'cramervonmises',\n",
    " 'cramervonmises_2samp',\n",
    " 'crystalball',\n",
    " 'cumfreq',\n",
    " 'describe',\n",
    " 'dgamma',\n",
    " 'differential_entropy',\n",
    " 'directional_stats',\n",
    " 'dirichlet',\n",
    " 'dirichlet_multinomial',\n",
    " 'distributions',\n",
    " 'dlaplace',\n",
    " 'dunnett',\n",
    " 'dweibull',\n",
    " 'ecdf',\n",
    " 'energy_distance',\n",
    " 'entropy',\n",
    " 'epps_singleton_2samp',\n",
    " 'erlang',\n",
    " 'expectile',\n",
    " 'expon',\n",
    " 'exponnorm',\n",
    " 'exponpow',\n",
    " 'exponweib',\n",
    " 'f',\n",
    " 'f_oneway',\n",
    " 'false_discovery_control',\n",
    " 'fatiguelife',\n",
    " 'find_repeats',\n",
    " 'fisher_exact',\n",
    " 'fisk',\n",
    " 'fit',\n",
    " 'fligner',\n",
    " 'foldcauchy',\n",
    " 'foldnorm',\n",
    " 'friedmanchisquare',\n",
    " 'gamma',\n",
    " 'gausshyper',\n",
    " 'gaussian_kde',\n",
    " 'genexpon',\n",
    " 'genextreme',\n",
    " 'gengamma',\n",
    " 'genhalflogistic',\n",
    " 'genhyperbolic',\n",
    " 'geninvgauss',\n",
    " 'genlogistic',\n",
    " 'gennorm',\n",
    " 'genpareto',\n",
    " 'geom',\n",
    " 'gibrat',\n",
    " 'gmean',\n",
    " 'gompertz',\n",
    " 'goodness_of_fit',\n",
    " 'gstd',\n",
    " 'gumbel_l',\n",
    " 'gumbel_r',\n",
    " 'gzscore',\n",
    " 'halfcauchy',\n",
    " 'halfgennorm',\n",
    " 'halflogistic',\n",
    " 'halfnorm',\n",
    " 'hmean',\n",
    " 'hypergeom',\n",
    " 'hypsecant',\n",
    " 'invgamma',\n",
    " 'invgauss',\n",
    " 'invweibull',\n",
    " 'invwishart',\n",
    " 'iqr',\n",
    " 'jarque_bera',\n",
    " 'johnsonsb',\n",
    " 'johnsonsu',\n",
    " 'kappa3',\n",
    " 'kappa4',\n",
    " 'kde',\n",
    " 'kendalltau',\n",
    " 'kruskal',\n",
    " 'ks_1samp',\n",
    " 'ks_2samp',\n",
    " 'ksone',\n",
    " 'kstat',\n",
    " 'kstatvar',\n",
    " 'kstest',\n",
    " 'kstwo',\n",
    " 'kstwobign',\n",
    " 'kurtosis',\n",
    " 'kurtosistest',\n",
    " 'laplace',\n",
    " 'laplace_asymmetric',\n",
    " 'levene',\n",
    " 'levy',\n",
    " 'levy_l',\n",
    " 'levy_stable',\n",
    " 'linregress',\n",
    " 'loggamma',\n",
    " 'logistic',\n",
    " 'loglaplace',\n",
    " 'lognorm',\n",
    " 'logrank',\n",
    " 'logser',\n",
    " 'loguniform',\n",
    " 'lomax',\n",
    " 'mannwhitneyu',\n",
    " 'matrix_normal',\n",
    " 'maxwell',\n",
    " 'median_abs_deviation',\n",
    " 'median_test',\n",
    " 'mielke',\n",
    " 'mode',\n",
    " 'moment',\n",
    " 'monte_carlo_test',\n",
    " 'mood',\n",
    " 'morestats',\n",
    " 'moyal',\n",
    " 'mstats',\n",
    " 'mstats_basic',\n",
    " 'mstats_extras',\n",
    " 'multinomial',\n",
    " 'multiscale_graphcorr',\n",
    " 'multivariate_hypergeom',\n",
    " 'multivariate_normal',\n",
    " 'multivariate_t',\n",
    " 'mvn',\n",
    " 'mvsdist',\n",
    " 'nakagami',\n",
    " 'nbinom',\n",
    " 'ncf',\n",
    " 'nchypergeom_fisher',\n",
    " 'nchypergeom_wallenius',\n",
    " 'nct',\n",
    " 'ncx2',\n",
    " 'nhypergeom',\n",
    " 'norm',\n",
    " 'normaltest',\n",
    " 'norminvgauss',\n",
    " 'obrientransform',\n",
    " 'ortho_group',\n",
    " 'page_trend_test',\n",
    " 'pareto',\n",
    " 'pearson3',\n",
    " 'pearsonr',\n",
    " 'percentileofscore',\n",
    " 'permutation_test',\n",
    " 'planck',\n",
    " 'pmean',\n",
    " 'pointbiserialr',\n",
    " 'poisson',\n",
    " 'poisson_means_test',\n",
    " 'power_divergence',\n",
    " 'powerlaw',\n",
    " 'powerlognorm',\n",
    " 'powernorm',\n",
    " 'ppcc_max',\n",
    " 'ppcc_plot',\n",
    " 'probplot',\n",
    " 'qmc',\n",
    " 'randint',\n",
    " 'random_correlation',\n",
    " 'random_table',\n",
    " 'rankdata',\n",
    " 'ranksums',\n",
    " 'rayleigh',\n",
    " 'rdist',\n",
    " 'recipinvgauss',\n",
    " 'reciprocal',\n",
    " 'rel_breitwigner',\n",
    " 'relfreq',\n",
    " 'rice',\n",
    " 'rv_continuous',\n",
    " 'rv_discrete',\n",
    " 'rv_histogram',\n",
    " 'rvs_ratio_uniforms',\n",
    " 'scoreatpercentile',\n",
    " 'sem',\n",
    " 'semicircular',\n",
    " 'shapiro',\n",
    " 'siegelslopes',\n",
    " 'sigmaclip',\n",
    " 'skellam',\n",
    " 'skew',\n",
    " 'skewcauchy',\n",
    " 'skewnorm',\n",
    " 'skewtest',\n",
    " 'sobol_indices',\n",
    " 'somersd',\n",
    " 'spearmanr',\n",
    " 'special_ortho_group',\n",
    " 'statlib',\n",
    " 'stats',\n",
    " 'studentized_range',\n",
    " 't',\n",
    " 'test',\n",
    " 'theilslopes',\n",
    " 'tiecorrect',\n",
    " 'tmax',\n",
    " 'tmean',\n",
    " 'tmin',\n",
    " 'trapezoid',\n",
    " 'trapz',\n",
    " 'triang',\n",
    " 'trim1',\n",
    " 'trim_mean',\n",
    " 'trimboth',\n",
    " 'truncexpon',\n",
    " 'truncnorm',\n",
    " 'truncpareto',\n",
    " 'truncweibull_min',\n",
    " 'tsem',\n",
    " 'tstd',\n",
    " 'ttest_1samp',\n",
    " 'ttest_ind',\n",
    " 'ttest_ind_from_stats',\n",
    " 'ttest_rel',\n",
    " 'tukey_hsd',\n",
    " 'tukeylambda',\n",
    " 'tvar',\n",
    " 'uniform',\n",
    " 'uniform_direction',\n",
    " 'unitary_group',\n",
    " 'variation',\n",
    " 'vonmises',\n",
    " 'vonmises_fisher',\n",
    " 'vonmises_line',\n",
    " 'wald',\n",
    " 'wasserstein_distance',\n",
    " 'weibull_max',\n",
    " 'weibull_min',\n",
    " 'weightedtau',\n",
    " 'wilcoxon',\n",
    " 'wishart',\n",
    " 'wrapcauchy',\n",
    " 'yeojohnson',\n",
    " 'yeojohnson_llf',\n",
    " 'yeojohnson_normmax',\n",
    " 'yeojohnson_normplot',\n",
    " 'yulesimon',\n",
    " 'zipf',\n",
    " 'zipfian',\n",
    " 'zmap',\n",
    " 'zscore']\n",
    "\n",
    "\n",
    "# mat_for_embed\n",
    "\n",
    "\n",
    "# #predict perturbations\n",
    "\n",
    "\n",
    "\n",
    "# col = adata.X.getcol(0)\n",
    "# row = adata.X.getrow(0)\n",
    "\n",
    "# vals = []\n",
    "# for item in col: \n",
    "#     vals.append(item)\n",
    "    \n",
    "# for item in row: \n",
    "#     vals.append(item)\n",
    "# vals[0].A[0][0]\n",
    "\n",
    "\n",
    "\n",
    "# idx = adata.X.A[0].nonzero()\n",
    "# # for i in idx:\n",
    "# #     print(adata.X.A[0][i])\n",
    "    \n",
    "    \n",
    "# adata.X.T.A[0]\n",
    "# idx\n",
    "\n",
    "m1= adata.X.A\n",
    "m2= np.ones((5905,367))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81166b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix2 = adata.X\n",
    "matrix1 = mat_for_embed\n",
    "\n",
    "\n",
    "\n",
    "#solutiosn that are not what you want them to be - works well and is fun to think about\n",
    "\n",
    "\n",
    "def asdflaksdfjalsdfjk() :\n",
    "    if '🐻'> '🐻🐻':\n",
    "        print('🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1231): asdflaksdfjalsdfjk()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cool invention - \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#16471085 stored elements \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4524cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2722\n",
      "1.0 1581\n",
      "1.0 2856\n",
      "1.0 2687\n",
      "1.0 2122\n",
      "0.0 1336\n",
      "1.0 589\n",
      "1.0 5618\n",
      "1.0 3739\n",
      "1.0 2726\n",
      "1.0 1884\n",
      "1.0 1083\n",
      "0.0 2775\n",
      "1.0 614\n",
      "1.0 685\n",
      "1.0 1419\n",
      "1.0 2482\n",
      "1.0 5100\n",
      "1.0 1110\n",
      "1.0 1078\n",
      "0.0 1927\n",
      "1.0 579\n",
      "1.0 2898\n",
      "1.0 638\n",
      "1.0 3284\n",
      "0.0 2641\n",
      "0.0 745\n",
      "1.0 2538\n",
      "1.0 2580\n",
      "0.0 1119\n",
      "1.0 1098\n",
      "0.0 8071\n",
      "0.0 1290\n",
      "1.0 2076\n",
      "0.0 1301\n",
      "1.0 1177\n",
      "1.0 976\n",
      "1.0 1303\n",
      "1.0 2007\n",
      "1.0 4550\n",
      "1.0 1525\n",
      "1.0 569\n",
      "0.0 2134\n",
      "1.0 964\n",
      "1.0 1347\n",
      "1.0 957\n",
      "1.0 1869\n",
      "1.0 2246\n",
      "1.0 1551\n",
      "0.0 724\n",
      "0.0 950\n",
      "1.0 2218\n",
      "1.0 6027\n",
      "1.0 521\n",
      "1.0 645\n",
      "1.0 2397\n",
      "0.0 3966\n",
      "0.0 1824\n",
      "0.0 3735\n",
      "0.0 3146\n",
      "0.0 1546\n",
      "0.0 661\n",
      "1.0 1805\n",
      "1.0 2113\n",
      "1.0 593\n",
      "1.0 1047\n",
      "1.0 3102\n",
      "1.0 3811\n",
      "0.0 1636\n",
      "1.0 3250\n",
      "1.0 5090\n",
      "1.0 2439\n",
      "1.0 2214\n",
      "1.0 663\n",
      "1.0 2183\n",
      "0.0 3929\n",
      "1.0 2188\n",
      "1.0 702\n",
      "1.0 1850\n",
      "1.0 3595\n",
      "1.0 780\n",
      "0.0 5757\n",
      "1.0 3087\n",
      "1.0 513\n",
      "1.0 928\n",
      "1.0 794\n",
      "0.0 1150\n",
      "1.0 4959\n",
      "1.0 2343\n",
      "0.0 3560\n",
      "1.0 1316\n",
      "1.0 2025\n",
      "1.0 810\n",
      "1.0 3543\n",
      "0.0 2884\n",
      "1.0 1381\n",
      "0.0 1757\n",
      "1.0 701\n",
      "1.0 546\n",
      "1.0 4029\n"
     ]
    }
   ],
   "source": [
    "first = adata.X.A[:100]\n",
    "second = adata.X.T.A[:100]\n",
    "\n",
    "\n",
    "perturbations = []\n",
    "for key, row in enumerate(first):\n",
    "    trackPerts = []\n",
    "    for column in row:\n",
    "        if column > 0: trackPerts.append(column)\n",
    "    print(t_dep[key].item(), len(trackPerts))\n",
    "        \n",
    "        \n",
    "#geneAverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9725ae78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "data = torch.Tensor(mat_for_embed)\n",
    "#makeCoolStuff = [[float(k) for k in range(1)] for i in range(200)]\n",
    "#do what they want - invent\n",
    "\n",
    "cat_ = [i for i in (cellGroups,\n",
    "cellGroupLengths,\n",
    "cellDistCounts)]\n",
    "\n",
    "mat2 = []\n",
    "for col in cat_:\n",
    "    l = []\n",
    "    for row in col: \n",
    "        l.append(row)\n",
    "    mat2.append(l)\n",
    "    \n",
    "#am = torch.cat((cat_[0], cat_[1], cat_[2]), 1)\n",
    "am = torch.tensor(mat2)\n",
    "\n",
    "def customGeneMatrixFindPerturbations(M):\n",
    "    m = torch.ones(M.shape[1], M.shape[0])\n",
    "\n",
    "    m = M @ m\n",
    "    m = m @ torch.ones(5905, 50)\n",
    "    m = m @ torch.ones(50, 32).triu()\n",
    "    m = m @ torch.eye(32, 3).cos()\n",
    "\n",
    "    return am.float().t()\n",
    "\n",
    "class λλλ(nn.Module):\n",
    "    def __init__(self, idn, edn):\n",
    "        super(λλλ, self).__init__()\n",
    "        self.λ = nn.Sequential(nn.Linear(idn, edn))\n",
    "    def forward(self, x):\n",
    "        return customGeneMatrixFindPerturbations(x)\n",
    "model = λλλ(data.shape[1], 3)\n",
    "λλλλλ = model(data)\n",
    "λλλλλ.shape#, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09e0b44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e97b9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i want to invent an alogirthm for fidnign perturbations and or clusters in a gene expression matrix\n",
    "# when i invent it the stream will be happy \n",
    "# in 30 minutes the solution will occur\n",
    "# 1000s of people want this \n",
    "# must make solution\n",
    "dim = 4\n",
    "m = torch.ones(dim, dim, dim)\n",
    "#i am going to make a mark on computational biolgoy\n",
    "#in 30 seconds i am going to invent this and it will be so cool\n",
    "#------->\n",
    "#         ()\n",
    "#.      ______\n",
    "#.        |\n",
    "#.       |\n",
    "#.      /\\\n",
    "#.   be serious and solve this now\n",
    "#solve this now is the only way\n",
    "#3d cube\n",
    "#2 rows \n",
    "#2 lists of numbers -> find a pattern\n",
    "#5000x2000 => 10,000,000 \n",
    "m.shape\n",
    "\n",
    "tri = [[1, 0, 1, .5],\n",
    "    [0, 0, 1, .5],\n",
    "    [.5, .4, .5, .1],\n",
    "     [.3, .2, .1, .6],\n",
    "    ]\n",
    "\n",
    "mat_for_embed = mat_for_embed ** mat_for_embed ** mat_for_embed\n",
    "party = torch.Tensor(mat_for_embed)\n",
    "#party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82ba9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invent a new architecture \n",
    "#that captures probability of perturbation across a matrix\n",
    "\n",
    "torch.ones(200, 500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = nn.Conv1d(5905, 5905, 1,  stride=1)\n",
    "#m2 = nn.Conv1d(200, 5905, 1,  stride=1)\n",
    "\n",
    "\n",
    "\n",
    "output = m(data)\n",
    "#output = m2(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26ae2e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    -0.0482,     -0.0026,     -0.0406,     -0.0220,     -0.9844,     -0.9344,     -0.0114,  ...,      0.0538,     -0.0043,\n",
       "             -0.4746,      0.2203,     -0.9521,      0.0298,     -0.0642],\n",
       "        [    -0.0029,      0.0433,     -0.0259,      0.0245,      0.0907,     -0.0618,     -0.1572,  ...,     -0.0265,     -0.0675,\n",
       "             -0.3594,      0.0421,     -0.1747,     -0.1395,      0.0240],\n",
       "        [    -0.0194,      0.0815,      0.0310,     -0.2299,      0.0053,     -0.6030,      0.0086,  ...,     -0.0073,      0.0409,\n",
       "              0.3651,     -0.0053,      0.6302,     -0.0587,      0.0501],\n",
       "        [    -0.0560,      0.0191,     -0.0227,      0.0476,      0.0723,     -0.4773,      0.0529,  ...,      0.0376,      0.0704,\n",
       "             -0.1438,      0.0295,      0.0310,     -0.0344,      0.1065],\n",
       "        [    -0.0317,     -0.0505,     -0.0179,      0.0580,     -0.7742,      0.2574,      0.0454,  ...,     -0.0171,     -0.0747,\n",
       "             -0.0418,      0.0649,     -0.1469,      0.0886,     -0.0063],\n",
       "        [    -0.0546,      0.1245,      0.0166,      0.0323,      0.4222,      2.5098,      0.0513,  ...,      0.0341,      0.1717,\n",
       "              0.5993,      0.0083,      0.4639,     -0.0934,      0.0052],\n",
       "        [     0.0023,     -0.0223,      0.0212,      0.0567,      0.2809,     -0.4491,      0.0372,  ...,     -0.0417,      0.0573,\n",
       "             -0.4257,      0.0463,      0.1813,      0.0820,      0.0472],\n",
       "        ...,\n",
       "        [    -0.0349,      0.0936,     -0.0352,      0.1502,      0.4427,      0.5575,      0.0398,  ...,      0.0235,     -0.1094,\n",
       "              0.4362,     -0.0177,      0.5962,      0.0244,      0.0198],\n",
       "        [    -0.0985,     -0.0448,     -0.1332,      0.0311,     -0.3255,      0.4836,      0.0920,  ...,      0.0065,     -0.1462,\n",
       "              0.3057,     -0.0623,     -0.3357,     -0.0049,      0.0409],\n",
       "        [    -0.1436,     -0.0160,     -0.0525,     -0.0231,     -0.3675,     -1.8443,      0.0185,  ...,     -0.0780,     -0.1244,\n",
       "             -0.8884,      0.0896,     -0.7067,      0.0547,      0.0285],\n",
       "        [     0.0177,     -0.1046,      0.0618,      0.0420,     -0.1497,     -1.3342,     -0.0832,  ...,     -0.0075,      0.0472,\n",
       "              0.2458,      0.0782,     -0.2802,     -0.0743,     -0.0048],\n",
       "        [    -0.0516,     -0.0287,      0.0693,      0.0258,      0.8308,     -0.0225,      0.0676,  ...,      0.0391,      0.1053,\n",
       "              0.8055,      0.0166,      0.8050,     -0.0145,     -0.0988],\n",
       "        [     0.1199,      0.0749,     -0.0108,     -0.0427,      0.3609,      1.1851,      0.0973,  ...,      0.0338,     -0.0462,\n",
       "              0.1719,      0.1183,      1.2787,      0.1300,      0.0408],\n",
       "        [    -0.1143,      0.0123,      0.0758,      0.0490,      0.0887,      0.8168,     -0.0493,  ...,     -0.0057,      0.1109,\n",
       "              0.0164,     -0.0517,     -0.0203,     -0.0729,     -0.0630]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(200, 50, 3)\n",
    "        self.conv2 = nn.Conv2d(50, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 7)\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, stride=2, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, 7)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 32, 7)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        # Decoder\n",
    "#         x = self.relu(self.deconv1(x))\n",
    "#         x = self.relu(self.deconv2(x))\n",
    "#         x = self.sigmoid(self.deconv3(x))\n",
    "        return x\n",
    "from torch import nn, torch\n",
    "#this is for convolutions to encoder \n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv1d(5905, 5905, 1,  stride=1)\n",
    "m2 = nn.Conv1d(5905, 5905, 1,  stride=1)\n",
    "\n",
    "# non-square kernels and unequal stride and with padding\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "# # non-square kernels and unequal stride and with padding and dilation\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(5905, 200)\n",
    "output = m(data)\n",
    "output.shape\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvAutoencoder().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "#popcorn = model(data)\n",
    "num_epochs = 10\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c165fa45",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [200, 5904, 3, 3], expected input[1, 1, 5905, 200] to have 5904 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m cnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      7\u001b[0m     conv(\u001b[38;5;241m5904\u001b[39m ,\u001b[38;5;241m200\u001b[39m),            \u001b[38;5;66;03m#14x14\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     conv(4 ,8),            #7x7\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     conv(16,10, act=False),\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten())\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([mat_for_embed])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [200, 5904, 3, 3], expected input[1, 1, 5905, 200] to have 5904 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "def conv(ni, nf, ks=3, stride=2, act=True):\n",
    "    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    conv(5904 ,200),            #14x14\n",
    "#     conv(4 ,8),            #7x7\n",
    "#     conv(8 ,16),           #4x4\n",
    "#     conv(16,16),           #2x2\n",
    "#     conv(16,10, act=False),\n",
    "    nn.Flatten()).to('cuda')\n",
    "\n",
    "data = torch.Tensor([mat_for_embed])\n",
    "cnn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80c697ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.A\n",
    "adata.X.A\n",
    "#np.moveaxis(adata.X.A[0], -1, 0)\n",
    "cellIntermediateRepresentation = []\n",
    "def convertRowToIntermediateRepresentation(adataXA, sec):\n",
    "    #remove noise from matrix\n",
    "    #filter not important columns from row\n",
    "    #rows with same \"important columns\" = one group\n",
    "    #p=scipy.stats.wasserstein_distance(adataXA, sec)\n",
    "    ixr = np.mean(adataXA)\n",
    "    ixre = np.mean(sec)\n",
    "    ixrm = np.mean(sec)\n",
    "    #dot, transpose, dot\n",
    "    #sum, sum , square\n",
    "    scal_dev = np.tensordot(adataXA.T, np.dot([-1, 1], [1,4]), 1)\n",
    "    maha = np.sum(np.sum(np.square(scal_dev), axis=-1), axis=0)\n",
    "    ixrm =  -0.5 * (numrows*numcols*_LOG_2PI + numcols*log_det_rowcov\n",
    "                   + numrows*log_det_colcov + maha)\n",
    "    cellIntermediateRepresentation.append((ixr,ixre,ixrm))\n",
    "# find gradient of row\n",
    "#given two rows that belong to same perturbation -> return identical or similar values\n",
    "\n",
    "#given a matrix -> return mx5 vals that can be transformed into a p-val\n",
    "\n",
    "#capture the 'features' that can be used to reconstruct -> molecular response\n",
    "\n",
    "# find the molecular response of each phenotype interaction or simply the gene by itself\n",
    "\n",
    "#gradient ascent -> descent -> find distributions -> sparsify them\n",
    "\n",
    "\n",
    "#ring that captures relevant known info about you and stores it cryptographically \n",
    "\n",
    "\n",
    "#given n rows and a matrix -> return a tuple that can be used to identify rows which belong to a perturbation response\n",
    "#given an expression matrix -> group cells by perturbation profiles\n",
    "#transcriptomics, genomics, proteinomics, metabolomics\n",
    "#recorded actions -> comic generator\n",
    "#script -> comic generator\n",
    "#comic -> animation generator\n",
    "cellIntermediateRepresentation\n",
    "#$https://www.youtube.com/watch?v=DzNmUNvnB04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffcbdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of coordinates \n",
    "#for x,y in coordinates\n",
    "    #val = row\n",
    "    \n",
    "#convert list of coordinates into tuple \n",
    "\n",
    "#rows =[]\n",
    "#while len(coordinates) > 0\n",
    "    #x,y,v = coordinates.pop()\n",
    "    #rows[x] += y\n",
    "    #cols[y] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfe2108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat1 = torch.randn(2, 3)\n",
    "# mat2 = torch.randn(3, 3)\n",
    "# torch.mm(mat1, mat2)\n",
    "# λλλλλ = λλλλλ @ torch.eye(3)\n",
    "#try to jimmy neutron\n",
    "#i have a cool idea\n",
    "#solve it for the stream\n",
    "#they can do anything\n",
    "#only positive ^2 \n",
    "#make a cool trick in one of these\n",
    "#magic how it works\n",
    "#data processing\n",
    "#neural net\n",
    "#matrix math\n",
    "#https://explained.ai/regularization/index.html\n",
    "#oft constraint with non-regularized loss function (blue-red) term and penalty term (orange)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99546806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the matrix before + after - 200x6k to 3x6k -> bright colors for rows with perturbations \n",
    "#perturbations defined as belonging to a group of rows that have multiple columns that are covarying from mean-zscore\n",
    "#makeCoolStuff = [[float(k) for k in range(5905)] for i in range(200)]\n",
    "tensor2 = torch.rand(5905, 200)\n",
    "\n",
    "tensor3 = torch.rand(5905, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70e041ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = mat_for_embed\n",
    "plt.imshow(λλλλλ[:3,].detach(), cmap='nipy_spectral_r', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489e50c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n",
      "🐻 🐻 🐯 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻 🐻\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸',\n",
       " '🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐸🐸🐸🐸',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻',\n",
       " '🐻']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.10xgenomics.com/resources/datasets/5-k-a-549-lung-carcinoma-cells-no-treatment-transduced-with-a-crispr-pool-3-1-standard-6-0-0\n",
    "# all_url = [\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406675_10X001.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406677_10X005.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406681_10X010.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AissaBenevolenskaya2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/ChangYe2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2017.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DixitRegev2016.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_protein.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_RNA.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_atscale.h5ad?download=1\",\n",
    "    \n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_highMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_lowMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GehringPachter2019.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/McFarlandTsherniak2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/NormanWeissman2019_filtered.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_essential.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_gwps.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_rpe1.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE106340.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE115943.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_11_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_8_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ShifrutMarson2018.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex2.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex3.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex4.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_day7neuron.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_iPSC.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRa.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRi.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/WeinrebKlein2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/XieHon2017.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ZhaoSims2021.h5ad?download=1\"\n",
    "# ]\n",
    "\n",
    "# import requests\n",
    " \n",
    "# # def download_url(url):\n",
    "# #   print(\"downloading: \",url)\n",
    "# #   # assumes that the last segment after the / represents the file name\n",
    "# #   # if url is abc/xyz/file.txt, the file name will be file.txt\n",
    "# #   file_name_start_pos = url.rfind(\"/\") + 1\n",
    "# #   file_name = url[file_name_start_pos:]\n",
    " \n",
    "# #   r = requests.get(url, stream=True)\n",
    "# #   if r.status_code == requests.codes.ok:\n",
    "# #     with open(file_name, 'wb') as f:\n",
    "# #       for data in r:\n",
    "# #         f.write(data)\n",
    "\n",
    "# #for link in url: download_url(link)\n",
    "#     #https://zenodo.org/record/7058382\n",
    "    \n",
    "# #find data set with some perturbed and some not\n",
    "# #train on a half with some of both \n",
    "# #apply to other half and see if predictions are true\n",
    "\n",
    "\n",
    "# import requests\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# # def download_url(url):\n",
    "# #   print(\"downloading: \",url)\n",
    "# #   # assumes that the last segment after the / represents the file name\n",
    "# #   # if url is abc/xyz/file.txt, the file name will be file.txt\n",
    "# #   file_name_start_pos = url.rfind(\"/\") + 1\n",
    "# #   file_name = url[file_name_start_pos:]\n",
    "\n",
    "# #   r = requests.get(url, stream=True)\n",
    "# #   if r.status_code == requests.codes.ok:\n",
    "# #     with open(file_name, 'wb') as f:\n",
    "# #       for data in r:\n",
    "# #         f.write(data)\n",
    "# #   return url\n",
    "\n",
    "# # results = ThreadPool(5).imap_unordered(download_url, url)\n",
    "# # for r in results:\n",
    "# #     print(r)\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# root_url = \"https://zenodo.org/record/7058382\"\n",
    "\n",
    "# def download_file(file_path):\n",
    "#     if os.path.isfile(folders+file_path): return print(f\"${file_path} already exists\")\n",
    "#     url = f\"{file_path}\"\n",
    "#     print(url)\n",
    "#     try:\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error downloading {file_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         # Extract the directory and filename from the file path\n",
    "#         directory, filename = os.path.split(file_path)\n",
    "#         # Create the directory if it doesn't exist\n",
    "#         os.makedirs(directory, exist_ok=True)\n",
    "#         # Save the file as JPEG\n",
    "#         try:\n",
    "#             image = Image.open(BytesIO(response.content))\n",
    "#             image.save(file_path, \"JPEG\")\n",
    "#             return file_path\n",
    "#         except IOError:\n",
    "#             return None\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Send an HTTP GET request to the URL\n",
    "# response = requests.get(root_url)\n",
    "\n",
    "# # Check if the request was successful\n",
    "# if response.status_code == 200:\n",
    "#     # Parse the HTML content of the response\n",
    "#     #soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Find all <a> tags that represent links\n",
    "#     #links = soup.find_all('a')\n",
    "\n",
    "#     # Extract the href attribute of each link\n",
    "#     file_urls = all_url\n",
    "\n",
    "#     # Create a ThreadPoolExecutor with maximum 256 worker threads\n",
    "#     executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "#     # Use a list to store the download tasks\n",
    "#     tasks = []\n",
    "\n",
    "#     # Use tqdm to create a progress bar\n",
    "#     with tqdm(total=len(file_urls)) as progress_bar:\n",
    "#         error_count = 0\n",
    "#         # Submit the download tasks\n",
    "#         for file_name in file_urls:\n",
    "#             task = executor.submit(download_file, file_name)\n",
    "#             tasks.append(task)\n",
    "\n",
    "#         # Process the completed tasks\n",
    "#         for completed_task in as_completed(tasks):\n",
    "#             result = completed_task.result()\n",
    "#             if result is None:\n",
    "\n",
    "#scarches.dataset.remove_sparsity(adata)\n",
    "#https://docs.scarches.org/en/latest/api/models.html\n",
    "# mdata = muon.read_10x_h5(\"pbmc_10k_protein_v3_filtered_feature_bc_matrix.h5\")\n",
    "# scvi.model.TOTALVI.setup_mudata(mdata, modalities={\"rna_layer\": \"rna\": \"protein_layer\": \"prot\"})\n",
    "# vae = scvi.model.TOTALVI(mdata)\n",
    "#https://docs.scvi-tools.org/en/stable/api/reference/scvi.module.LDVAE.html\n",
    "#[i for i in test_predictions.tolist() if i < 1]\n",
    "# Regularization in Logistic Regression\n",
    "# Regularization is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. Consequently, most logistic regression models use one of the following two strategies to dampen model complexity:\n",
    "\n",
    "# L2 regularization.\n",
    "# Early stopping, that is, limiting the number of training steps or the learning rate.\n",
    "# (We'll discuss a third strategy—L1 regularization—in a later module.)\n",
    "\n",
    "# Imagine that you assign a unique id to each example, and map each id to its own feature. If you don't specify a regularization function, the model will become completely overfit. That's because the model would try to drive loss to zero on all examples and never get there, driving the weights for each indicator feature to +infinity or -infinity. This can happen in high dimensional data with feature crosses, when there’s a huge mass of rare crosses that happen only on one example each.\n",
    "\n",
    "# Fortunately, using L2 or early stopping will prevent this problem.\n",
    "#[ x for x in [iden(sum(item), 10)  for item in test_predictions.tolist()] if x > .1]\n",
    "#plot(loss_track)\n",
    "\n",
    "def plot_loss(l):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "\n",
    "#     blue = [i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]]\n",
    "#     oj =[i for k,i in enumerate(rowGeneExpression.values()) if not dependent_variables[k]]\n",
    "#     blue.sort()\n",
    "#     oj.sort()\n",
    "#     plt.plot((blue)) #blue true peturbation \n",
    "    plt.plot(l) #orange false ctrl\n",
    "\n",
    "    #legends.append('param %d' % i)\n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "# #https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02021-3\n",
    "# # Medicine Finding anomalies in radiology images, including CT, MRI, and X-ray images; counting features in pathology slides; measuring features in ultrasounds; diagnosing diabetic retinopathy\n",
    "# #Biology Folding proteins; classifying proteins; many genomics tasks, such as tumor-normal sequencing and classifying clinically actionable genetic mutations; cell classification; analyzing protein/protein interactions\n",
    "# #Other applications Financial and logistical forecasting, text to speech, and much more…\n",
    "# # humor analysis - larry david vs seinfeld ? \n",
    "#https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework\n",
    "#handle \"values outside of domain\" by \"SVM\"\n",
    "#random forest classifier\n",
    "#logisitc regression - hard to get right\n",
    "#correct transformations, outlier handling, correct interactions\n",
    "#os.listdir('./data_sets')\n",
    "#wget -m http://www.example.com 2>&1 | grep '^--' | awk '{ print $3 }' | grep -v '\\.\\(css\\|js\\|png\\|gif\\|jpg\\|JPG\\)$' > urls.txt\n",
    "#https://academic.oup.com/bib/article/22/4/bbaa268/5943793\n",
    "#plot(loss_track)\n",
    "#https://terrytao.files.wordpress.com/2011/02/matrix-book.pdf\n",
    "#https://academic.oup.com/bioinformatics/article/36/Supplement_2/i610/6055927?login=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c9bdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = adata.X.A\n",
    "# def solveIt():\n",
    "#     ix = []\n",
    "#     for row in l:\n",
    "#         for col in row:\n",
    "#             if col > 0: ix.append(col)\n",
    "#     return ix\n",
    "\n",
    "\n",
    "# #solveIt()\n",
    "# #dont think of it as dimensionality reduction\n",
    "# recordGroups  = defaultdict(int)\n",
    "# for row in range(10):    \n",
    "#     for col in list(high_variance_columns):\n",
    "#         val = adata.X.A[row][col]\n",
    "#         if val > avg:\n",
    "#             recordGroups[col] += val\n",
    "# recordGroups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
