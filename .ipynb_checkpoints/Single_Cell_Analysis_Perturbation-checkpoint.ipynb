{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4fddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas \n",
    "pandas.set_option('mode.use_inf_as_na', True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# This is required to catch warnings when the multiprocessing module is used\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "# import pertpy as pt\n",
    "import scanpy as sc\n",
    "\n",
    "import pertpy as pt\n",
    "adata = pt.dt.kang_2018()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30af6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.var_keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecb19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# json = []\n",
    "# for row in adata.obs.values:\n",
    "#     result.append([item for kev, item in enumerate(row) ])\n",
    "# for row in result: json.append({k: v for k, v in zip(adata.obs.columns.tolist(), row)})\n",
    "\n",
    "# print(json)\n",
    "#adata.var.highly_variable.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0603158c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL627309.1</th>\n",
       "      <td>AL627309.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP11-206L10.2</th>\n",
       "      <td>RP11-206L10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP11-206L10.9</th>\n",
       "      <td>RP11-206L10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM87B</th>\n",
       "      <td>FAM87B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LINC00115</th>\n",
       "      <td>LINC00115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C21orf58</th>\n",
       "      <td>C21orf58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCNT</th>\n",
       "      <td>PCNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIP2A</th>\n",
       "      <td>DIP2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S100B</th>\n",
       "      <td>S100B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRMT2</th>\n",
       "      <td>PRMT2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15706 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name\n",
       "index                       \n",
       "AL627309.1        AL627309.1\n",
       "RP11-206L10.2  RP11-206L10.2\n",
       "RP11-206L10.9  RP11-206L10.9\n",
       "FAM87B                FAM87B\n",
       "LINC00115          LINC00115\n",
       "...                      ...\n",
       "C21orf58            C21orf58\n",
       "PCNT                    PCNT\n",
       "DIP2A                  DIP2A\n",
       "S100B                  S100B\n",
       "PRMT2                  PRMT2\n",
       "\n",
       "[15706 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce738036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata)\n",
    "\n",
    "#hv_genes = filtered_keys = df[df['column_name'] == True].index.tolist()\n",
    "\n",
    "#normal_genes = filtered_keys = df[df['column_name'] == False].index.tolist()\n",
    "\n",
    "#print(hv_genes, normal_genes)\n",
    "hv_genes = (list(adata.var[adata.var['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "hv_columns = [i for i,val in enumerate(normal_genes) if val in hv_genes]\n",
    "#hv_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "3adac277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hv_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5024bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "#batchcontrol\n",
    "#clustering\n",
    "#cell type annotation\n",
    "#embedding\n",
    "#reverse transcriptome\n",
    "#differential expression\n",
    "\n",
    "#rna velocity -> predicts the future state \n",
    "#predict the probability of unseen perturbations\n",
    "#test: first data set => output list of perturbations \n",
    "# take a 2nd dataset and get list of perturbations + their probability \n",
    "\n",
    "\n",
    "#representation learning (in particular, self-supervised, multi-view, and transfer learning\n",
    "#https://registry.opendata.aws/tabula-muris/#usageexamples\n",
    "\n",
    "#see what preprocessing is needed to get better accuracy\n",
    "\n",
    "##load data\n",
    "\n",
    "##import premade model => output list of predicted unseen perturbation\n",
    "\n",
    "#write custom model. get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "819836d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pp.calculate_qc_metrics(adata)\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c17792b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "def download_parallel(args):\n",
    "    cpus = cpu_count()\n",
    "    results = ThreadPool(cpus - 1).imap_unordered(download_url, args)\n",
    "    for result in results:\n",
    "        print('url:', result[0], 'time (s):', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23a91c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "619d5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_expressed = [\"string1\", \"string2\", \"string3\"]\n",
    "\n",
    "    \n",
    "# strings = np.array(gene_expressed)\n",
    "# #adata.obs['genes_expressed'] = strings\n",
    "# coordinates = []\n",
    "cx = adata.X\n",
    "cx = cx.tocoo()\n",
    "\n",
    "# #delete non highly variable genes from matrix\n",
    "\n",
    "\n",
    "# for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "#     if i in hv_columns: coordinates += [[i,j,v]]\n",
    "# for coord in coordinates:\n",
    "#     coord[1] = adata.var_names[coord[1]]\n",
    "\n",
    "#print(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7491d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>tsne1</th>\n",
       "      <th>tsne2</th>\n",
       "      <th>condition</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>replicate</th>\n",
       "      <th>nCount_SCT</th>\n",
       "      <th>nFeature_SCT</th>\n",
       "      <th>integrated_snn_res.0.4</th>\n",
       "      <th>seurat_clusters</th>\n",
       "      <th>geneExpressionCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACATACATTTCC-1</th>\n",
       "      <td>3017.0</td>\n",
       "      <td>877</td>\n",
       "      <td>-27.640373</td>\n",
       "      <td>14.966629</td>\n",
       "      <td>control</td>\n",
       "      <td>9</td>\n",
       "      <td>CD14+ Monocytes</td>\n",
       "      <td>patient_1016</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>234.670774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATACCAGAAA-1</th>\n",
       "      <td>2481.0</td>\n",
       "      <td>713</td>\n",
       "      <td>-27.493646</td>\n",
       "      <td>28.924885</td>\n",
       "      <td>control</td>\n",
       "      <td>9</td>\n",
       "      <td>CD14+ Monocytes</td>\n",
       "      <td>patient_1256</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>214.105606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATACCATGCA-1</th>\n",
       "      <td>703.0</td>\n",
       "      <td>337</td>\n",
       "      <td>-10.468194</td>\n",
       "      <td>-5.984389</td>\n",
       "      <td>control</td>\n",
       "      <td>3</td>\n",
       "      <td>CD4 T cells</td>\n",
       "      <td>patient_1488</td>\n",
       "      <td>908.0</td>\n",
       "      <td>337</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>45.892522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATACCTCGCT-1</th>\n",
       "      <td>3420.0</td>\n",
       "      <td>850</td>\n",
       "      <td>-24.367997</td>\n",
       "      <td>20.429285</td>\n",
       "      <td>control</td>\n",
       "      <td>9</td>\n",
       "      <td>CD14+ Monocytes</td>\n",
       "      <td>patient_1256</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>226.106354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATACCTGGTA-1</th>\n",
       "      <td>3158.0</td>\n",
       "      <td>1111</td>\n",
       "      <td>27.952170</td>\n",
       "      <td>24.159738</td>\n",
       "      <td>control</td>\n",
       "      <td>4</td>\n",
       "      <td>Dendritic cells</td>\n",
       "      <td>patient_1039</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>928</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>212.404950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGCCTGAA-2</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>468</td>\n",
       "      <td>18.268321</td>\n",
       "      <td>1.058202</td>\n",
       "      <td>stimulated</td>\n",
       "      <td>6</td>\n",
       "      <td>CD4 T cells</td>\n",
       "      <td>patient_1244</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>468</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGCCTGTC-2</th>\n",
       "      <td>2116.0</td>\n",
       "      <td>819</td>\n",
       "      <td>-11.563067</td>\n",
       "      <td>2.574095</td>\n",
       "      <td>stimulated</td>\n",
       "      <td>4</td>\n",
       "      <td>B cells</td>\n",
       "      <td>patient_1256</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>799</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGCTAAGC-2</th>\n",
       "      <td>1522.0</td>\n",
       "      <td>523</td>\n",
       "      <td>25.142392</td>\n",
       "      <td>6.603815</td>\n",
       "      <td>stimulated</td>\n",
       "      <td>6</td>\n",
       "      <td>CD4 T cells</td>\n",
       "      <td>patient_107</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGGGACGA-2</th>\n",
       "      <td>1143.0</td>\n",
       "      <td>503</td>\n",
       "      <td>14.359657</td>\n",
       "      <td>10.965601</td>\n",
       "      <td>stimulated</td>\n",
       "      <td>6</td>\n",
       "      <td>CD4 T cells</td>\n",
       "      <td>patient_1488</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGTCTTAC-2</th>\n",
       "      <td>1031.0</td>\n",
       "      <td>421</td>\n",
       "      <td>14.572118</td>\n",
       "      <td>-4.713942</td>\n",
       "      <td>stimulated</td>\n",
       "      <td>5</td>\n",
       "      <td>CD4 T cells</td>\n",
       "      <td>patient_1016</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>419</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24673 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  nCount_RNA  nFeature_RNA      tsne1      tsne2   condition  cluster        cell_type     replicate  nCount_SCT  \\\n",
       "index                                                                                                                              \n",
       "AAACATACATTTCC-1      3017.0           877 -27.640373  14.966629     control        9  CD14+ Monocytes  patient_1016      1704.0   \n",
       "AAACATACCAGAAA-1      2481.0           713 -27.493646  28.924885     control        9  CD14+ Monocytes  patient_1256      1614.0   \n",
       "AAACATACCATGCA-1       703.0           337 -10.468194  -5.984389     control        3      CD4 T cells  patient_1488       908.0   \n",
       "AAACATACCTCGCT-1      3420.0           850 -24.367997  20.429285     control        9  CD14+ Monocytes  patient_1256      1738.0   \n",
       "AAACATACCTGGTA-1      3158.0          1111  27.952170  24.159738     control        4  Dendritic cells  patient_1039      1857.0   \n",
       "...                      ...           ...        ...        ...         ...      ...              ...           ...         ...   \n",
       "TTTGCATGCCTGAA-2      1033.0           468  18.268321   1.058202  stimulated        6      CD4 T cells  patient_1244      1128.0   \n",
       "TTTGCATGCCTGTC-2      2116.0           819 -11.563067   2.574095  stimulated        4          B cells  patient_1256      1669.0   \n",
       "TTTGCATGCTAAGC-2      1522.0           523  25.142392   6.603815  stimulated        6      CD4 T cells   patient_107      1422.0   \n",
       "TTTGCATGGGACGA-2      1143.0           503  14.359657  10.965601  stimulated        6      CD4 T cells  patient_1488      1185.0   \n",
       "TTTGCATGTCTTAC-2      1031.0           421  14.572118  -4.713942  stimulated        5      CD4 T cells  patient_1016      1144.0   \n",
       "\n",
       "                  nFeature_SCT integrated_snn_res.0.4 seurat_clusters  geneExpressionCount  \n",
       "index                                                                                       \n",
       "AAACATACATTTCC-1           711                      1               1           234.670774  \n",
       "AAACATACCAGAAA-1           662                      1               1           214.105606  \n",
       "AAACATACCATGCA-1           337                      6               6            45.892522  \n",
       "AAACATACCTCGCT-1           653                      1               1           226.106354  \n",
       "AAACATACCTGGTA-1           928                     12              12           212.404950  \n",
       "...                        ...                    ...             ...                  ...  \n",
       "TTTGCATGCCTGAA-2           468                      2               2             0.000000  \n",
       "TTTGCATGCCTGTC-2           799                      3               3             0.000000  \n",
       "TTTGCATGCTAAGC-2           523                      0               0             0.000000  \n",
       "TTTGCATGGGACGA-2           503                      0               0             0.000000  \n",
       "TTTGCATGTCTTAC-2           419                      2               2             0.000000  \n",
       "\n",
       "[24673 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs\n",
    "#batch removal - one patient at at time\n",
    "#one cell_type at a time \n",
    "#index cell type\n",
    "#index ctrl/stim\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "e04c40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rowGeneExpression2 = defaultdict(dict)\n",
    "\n",
    "\n",
    "import math\n",
    "math.floor\n",
    "df = adata.obs\n",
    "end = 50 if True else -1\n",
    "for column in hv_columns:\n",
    "    for row_id in range(math.floor(float(df.shape[0])))[:end]:\n",
    "        rowGeneExpression[row_id] += adata.X[row_id, column]\n",
    "        #rowGeneExpression2[row_id][column] = adata.X[row_id, column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225e687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "37853254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs\n",
    "dependent_variables =  [rowGeneExpression[row] for row in range(df.shape[0])]\n",
    "df['geneExpressionCount'] = dependent_variables\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "9aa9e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "4e593d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0010805558152198792,\n",
       " 0.0010089216809272767,\n",
       " 0.0002121972470283508,\n",
       " 0.001045083071231842,\n",
       " 0.0008644464187622069,\n",
       " 0.00026018917322158814,\n",
       " 0.0006210891451835632,\n",
       " 0.0002178950881958008,\n",
       " 0.0007920010080337526,\n",
       " 0.0002853137445449829,\n",
       " 0.00022715255689620973,\n",
       " 0.00048334319543838505,\n",
       " 0.00021494792699813843,\n",
       " 0.0001493660912513733,\n",
       " 0.000495432436466217,\n",
       " 0.00024248584127426146,\n",
       " 0.0009560271172523498,\n",
       " 0.0003118692579269409,\n",
       " 0.0002651469836235046,\n",
       " 0.00018007180786132812,\n",
       " 0.0006126044974327087,\n",
       " 0.00035217081212997434,\n",
       " 0.0002768489360809326,\n",
       " 0.00025924437999725344,\n",
       " 0.00018306866598129273,\n",
       " 0.00035608687353134153,\n",
       " 0.0002900427098274231,\n",
       " 0.0004949977474212647,\n",
       " 0.000280858455657959,\n",
       " 0.00027503374958038327,\n",
       " 0.0007367731051445008,\n",
       " 0.0002733328619003296,\n",
       " 0.0012322799563407897,\n",
       " 0.0003789612865447998,\n",
       " 0.00023014823389053347,\n",
       " 0.00026753033256530763,\n",
       " 0.00024551343870162965,\n",
       " 0.00022465646457672117,\n",
       " 0.0004952262988090515,\n",
       " 0.00025361656188964844,\n",
       " 0.0011239287242889404,\n",
       " 0.0006176947135925293,\n",
       " 0.0005761347732543945,\n",
       " 0.0003070278649330139,\n",
       " 0.00043391656732559206,\n",
       " 0.000546455991268158,\n",
       " 0.0002491553502082825,\n",
       " 0.0013229629464149475,\n",
       " 0.0002445254673957825,\n",
       " 0.0011738340425491334,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_variables = [x / 50 for x in dependent_variables]\n",
    "dependent_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "01957362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0011, 0.0010, 0.0002, 0.0010, 0.0009, 0.0003, 0.0006,  ..., 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(dependent_variables) # pertrubations\n",
    "t_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "17156f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3017.0000,    877.0000,    -27.6404,     14.9666,      9.0000,   1704.0000,    711.0000,    135.0695],\n",
       "        [  2481.0000,    713.0000,    -27.4936,     28.9249,      9.0000,   1614.0000,    662.0000,    126.1152],\n",
       "        [   703.0000,    337.0000,    -10.4682,     -5.9844,      3.0000,    908.0000,    337.0000,     26.5247],\n",
       "        [  3420.0000,    850.0000,    -24.3680,     20.4293,      9.0000,   1738.0000,    653.0000,    130.6354],\n",
       "        [  3158.0000,   1111.0000,     27.9522,     24.1597,      4.0000,   1857.0000,    928.0000,    108.0558],\n",
       "        [  1869.0000,    635.0000,     -0.4702,    -25.3987,      5.0000,   1525.0000,    634.0000,     32.5236],\n",
       "        [  1142.0000,    436.0000,    -15.9062,     20.0853,      9.0000,   1157.0000,    436.0000,     77.6361],\n",
       "        ...,\n",
       "        [   635.0000,    424.0000,     -6.6479,     -5.5475,      3.0000,    882.0000,    423.0000,      0.0000],\n",
       "        [  1340.0000,    480.0000,      7.7202,     33.3402,      8.0000,   1324.0000,    480.0000,      0.0000],\n",
       "        [  1033.0000,    468.0000,     18.2683,      1.0582,      6.0000,   1128.0000,    468.0000,      0.0000],\n",
       "        [  2116.0000,    819.0000,    -11.5631,      2.5741,      4.0000,   1669.0000,    799.0000,      0.0000],\n",
       "        [  1522.0000,    523.0000,     25.1424,      6.6038,      6.0000,   1422.0000,    523.0000,      0.0000],\n",
       "        [  1143.0000,    503.0000,     14.3597,     10.9656,      6.0000,   1185.0000,    503.0000,      0.0000],\n",
       "        [  1031.0000,    421.0000,     14.5721,     -4.7139,      5.0000,   1144.0000,    419.0000,      0.0000]])"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep = tensor(numerical_values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "9294b33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "6564bf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2799, -0.4392,  0.2103,  0.3625,  0.1722,  0.2324, -0.3575, -0.0010])"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88297088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "5dfdf216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(295.1170, dtype=torch.float64)"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n",
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "\n",
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "bab45dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "955bcb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "2926f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0070,  0.1439,  0.1692,  0.1373, -1.4242, -0.0273, -0.2387, -0.2097],\n",
       "        [-0.0058,  0.1170,  0.1683,  0.2654, -1.4242, -0.0259, -0.2223, -0.1958],\n",
       "        [-0.0016,  0.0553,  0.0641, -0.0549, -0.4747, -0.0146, -0.1132, -0.0412],\n",
       "        [-0.0080,  0.1395,  0.1492,  0.1874, -1.4242, -0.0279, -0.2193, -0.2028],\n",
       "        [-0.0074,  0.1823, -0.1711,  0.2216, -0.6330, -0.0298, -0.3116, -0.1677],\n",
       "        [-0.0044,  0.1042,  0.0029, -0.2330, -0.7912, -0.0245, -0.2129, -0.0505],\n",
       "        [-0.0027,  0.0716,  0.0974,  0.1843, -1.4242, -0.0186, -0.1464, -0.1205],\n",
       "        ...,\n",
       "        [-0.0015,  0.0696,  0.0407, -0.0509, -0.4747, -0.0142, -0.1420, -0.0000],\n",
       "        [-0.0031,  0.0788, -0.0473,  0.3059, -1.2659, -0.0212, -0.1612, -0.0000],\n",
       "        [-0.0024,  0.0768, -0.1119,  0.0097, -0.9494, -0.0181, -0.1571, -0.0000],\n",
       "        [-0.0049,  0.1344,  0.0708,  0.0236, -0.6330, -0.0268, -0.2683, -0.0000],\n",
       "        [-0.0036,  0.0858, -0.1539,  0.0606, -0.9494, -0.0228, -0.1756, -0.0000],\n",
       "        [-0.0027,  0.0826, -0.0879,  0.1006, -0.9494, -0.0190, -0.1689, -0.0000],\n",
       "        [-0.0024,  0.0691, -0.0892, -0.0432, -0.7912, -0.0184, -0.1407, -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "8fc0dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "25fea016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0276,  0.4525, -0.2689,  0.3943, -1.5824, -0.0483, -0.4761, -0.2567], requires_grad=True)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "6c5c1597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4974, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "7f25fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = pd.DataFrame(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "f6d67306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(independent_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "42738fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "#len(trn_indep),len(val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "e0499927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493; 0.492; 0.491; 0.490; 0.489; 0.488; 0.487; 0.486; 0.485; 0.484; 0.483; 0.482; 0.481; 0.480; 0.479; 0.478; 0.477; 0.476; {'nCount_RNA': tensor(-0.0276), 'nFeature_RNA': tensor(0.4525), 'tsne1': tensor(-0.2689), 'tsne2': tensor(0.3943), 'cluster': tensor(-1.5824), 'nCount_SCT': tensor(-0.0483), 'nFeature_SCT': tensor(-0.4761), 'geneExpressionCount': tensor(-0.2567)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def init_coeffs(): \n",
    "#     hiddens = [10, 10] # <-- set this to the size of each hidden layer you want_ \n",
    "#     sizes = [n_coeff] + hiddens + [1] \n",
    "#     n = len(sizes) \n",
    "#     layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]  for i in range(n-1)] \n",
    "#     consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)] \n",
    "#     for l in layers+consts:\n",
    "#         l.requires_grad_() \n",
    "#     return layers,consts\n",
    "\n",
    "# import torch.nn.functional as F \n",
    "# def calc_preds(coeffs, indeps): \n",
    "#     layers,consts = coeffs \n",
    "#     n = len(layers) \n",
    "#     res = indeps \n",
    "#     for i,l in enumerate(layers): \n",
    "#         res = res@l + consts[i] \n",
    "#         if i!=n-1: res = F.relu(res) \n",
    "#     return torch.sigmoid(res)\n",
    "\n",
    "# def update_coeffs(coeffs, lr): \n",
    "#     layers, consts = coeffs \n",
    "#     for layer in layers+consts: \n",
    "#         layer.sub_(layer.grad * lr) \n",
    "#         layer.grad.zero_()\n",
    "torch.manual_seed(443)\n",
    "\n",
    "\n",
    "\n",
    "def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.1)).float().mean()\n",
    "def calc_preds(coeffs, indeps): return (coeffs * indeps).sum(axis=1)\n",
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))\n",
    "#def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "#def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)\n",
    "\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()\n",
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()\n",
    "def update_coeffs(coeffs, lr): \n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()\n",
    "\n",
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n",
    "def train_model(epochs=30, lr=0.01):\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs\n",
    "\n",
    "coeffs = train_model(18, lr=4)\n",
    "\n",
    "indep_cols = ['nCount_RNA' ,                \n",
    "'nFeature_RNA'    ,             \n",
    "'tsne1'     ,                 \n",
    "'tsne2'  ,                   \n",
    "'cluster'    ,                  \n",
    "'nCount_SCT'   ,              \n",
    "'nFeature_SCT',\n",
    "'geneExpressionCount'\n",
    "]    \n",
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "print(show_coeffs())\n",
    "len([prob for prob in calc_preds(coeffs, t_indep) if prob > .5]) # should be 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "14ce99b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.1890),\n",
       " tensor(0.2103),\n",
       " tensor(0.3588),\n",
       " tensor(0.1969),\n",
       " tensor(0.2856),\n",
       " tensor(0.2298),\n",
       " tensor(0.2044),\n",
       " tensor(0.2493),\n",
       " tensor(0.1981),\n",
       " tensor(0.1521),\n",
       " tensor(0.1277),\n",
       " tensor(0.2974),\n",
       " tensor(0.2574),\n",
       " tensor(0.2395),\n",
       " tensor(0.2887),\n",
       " tensor(0.3233),\n",
       " tensor(0.2021),\n",
       " tensor(0.1125),\n",
       " tensor(0.2362),\n",
       " tensor(0.2427),\n",
       " tensor(0.2017),\n",
       " tensor(0.2434),\n",
       " tensor(0.3161),\n",
       " tensor(0.1206),\n",
       " tensor(0.2635),\n",
       " tensor(0.1180),\n",
       " tensor(0.2385),\n",
       " tensor(0.2002),\n",
       " tensor(0.2350),\n",
       " tensor(0.3342),\n",
       " tensor(0.3264),\n",
       " tensor(0.2408),\n",
       " tensor(0.2027),\n",
       " tensor(0.3395),\n",
       " tensor(0.2555),\n",
       " tensor(0.2352),\n",
       " tensor(0.2394),\n",
       " tensor(0.3332),\n",
       " tensor(0.3189),\n",
       " tensor(0.2661),\n",
       " tensor(0.2018),\n",
       " tensor(0.1958),\n",
       " tensor(0.4853),\n",
       " tensor(0.1169),\n",
       " tensor(0.3104),\n",
       " tensor(0.3065),\n",
       " tensor(0.2566),\n",
       " tensor(0.1976),\n",
       " tensor(0.2584),\n",
       " tensor(0.1965),\n",
       " tensor(0.3474),\n",
       " tensor(0.2266),\n",
       " tensor(0.2359),\n",
       " tensor(0.4880),\n",
       " tensor(0.2170),\n",
       " tensor(0.2569),\n",
       " tensor(0.3836),\n",
       " tensor(0.3405),\n",
       " tensor(0.2431),\n",
       " tensor(0.2317),\n",
       " tensor(0.3856),\n",
       " tensor(0.1288),\n",
       " tensor(0.2129),\n",
       " tensor(0.3280),\n",
       " tensor(0.4954),\n",
       " tensor(0.2493),\n",
       " tensor(0.1615),\n",
       " tensor(0.2234),\n",
       " tensor(0.2343),\n",
       " tensor(0.2300),\n",
       " tensor(0.2644),\n",
       " tensor(0.2384),\n",
       " tensor(0.2700),\n",
       " tensor(0.3529),\n",
       " tensor(0.1577),\n",
       " tensor(0.1358),\n",
       " tensor(0.3453),\n",
       " tensor(0.2284),\n",
       " tensor(0.2452),\n",
       " tensor(0.2643),\n",
       " tensor(0.2429),\n",
       " tensor(0.2394),\n",
       " tensor(0.2670),\n",
       " tensor(0.2593),\n",
       " tensor(0.1412),\n",
       " tensor(0.2516),\n",
       " tensor(0.2239),\n",
       " tensor(0.1293),\n",
       " tensor(0.2541),\n",
       " tensor(0.2410),\n",
       " tensor(0.2566),\n",
       " tensor(0.2732),\n",
       " tensor(0.2121),\n",
       " tensor(0.1216),\n",
       " tensor(0.3696),\n",
       " tensor(0.2628),\n",
       " tensor(0.2361),\n",
       " tensor(0.1171),\n",
       " tensor(0.2061),\n",
       " tensor(0.2715),\n",
       " tensor(0.2736),\n",
       " tensor(0.2359),\n",
       " tensor(0.4903),\n",
       " tensor(0.1232),\n",
       " tensor(0.1639),\n",
       " tensor(0.2423),\n",
       " tensor(0.2450),\n",
       " tensor(0.2179),\n",
       " tensor(0.2650),\n",
       " tensor(0.2168),\n",
       " tensor(0.3341),\n",
       " tensor(0.1189),\n",
       " tensor(0.1158),\n",
       " tensor(0.4805),\n",
       " tensor(0.2308),\n",
       " tensor(0.3316),\n",
       " tensor(0.2339),\n",
       " tensor(0.2415),\n",
       " tensor(0.2225),\n",
       " tensor(0.2454),\n",
       " tensor(0.2194),\n",
       " tensor(0.2207),\n",
       " tensor(0.2106),\n",
       " tensor(0.3374),\n",
       " tensor(0.1226),\n",
       " tensor(0.3478),\n",
       " tensor(0.3291),\n",
       " tensor(0.3303),\n",
       " tensor(0.3446),\n",
       " tensor(0.1867),\n",
       " tensor(0.4962),\n",
       " tensor(0.2342),\n",
       " tensor(0.3304),\n",
       " tensor(0.2606),\n",
       " tensor(0.2361),\n",
       " tensor(0.2236),\n",
       " tensor(0.2431),\n",
       " tensor(0.2371),\n",
       " tensor(0.2121),\n",
       " tensor(0.2450),\n",
       " tensor(0.1674),\n",
       " tensor(0.2456),\n",
       " tensor(0.4876),\n",
       " tensor(0.2255),\n",
       " tensor(0.3455),\n",
       " tensor(0.3367),\n",
       " tensor(0.2325),\n",
       " tensor(0.4855),\n",
       " tensor(0.2410),\n",
       " tensor(0.1711),\n",
       " tensor(0.2453),\n",
       " tensor(0.2225),\n",
       " tensor(0.2604),\n",
       " tensor(0.3396),\n",
       " tensor(0.2623),\n",
       " tensor(0.2450),\n",
       " tensor(0.2251),\n",
       " tensor(0.2306),\n",
       " tensor(0.2493),\n",
       " tensor(0.2576),\n",
       " tensor(0.2273),\n",
       " tensor(0.2493),\n",
       " tensor(0.2215),\n",
       " tensor(0.2525),\n",
       " tensor(0.2449),\n",
       " tensor(0.2340),\n",
       " tensor(0.1308),\n",
       " tensor(0.1599),\n",
       " tensor(0.1651),\n",
       " tensor(0.3364),\n",
       " tensor(0.2652),\n",
       " tensor(0.2581),\n",
       " tensor(0.1248),\n",
       " tensor(0.1307),\n",
       " tensor(0.3404),\n",
       " tensor(0.2345),\n",
       " tensor(0.2588),\n",
       " tensor(0.2436),\n",
       " tensor(0.1166),\n",
       " tensor(0.1242),\n",
       " tensor(0.2533),\n",
       " tensor(0.2502),\n",
       " tensor(0.1281),\n",
       " tensor(0.5158),\n",
       " tensor(0.2331),\n",
       " tensor(0.3277),\n",
       " tensor(0.3299),\n",
       " tensor(0.2372),\n",
       " tensor(0.2686),\n",
       " tensor(0.2380),\n",
       " tensor(0.2430),\n",
       " tensor(0.2103),\n",
       " tensor(0.1626),\n",
       " tensor(0.2316),\n",
       " tensor(0.1325),\n",
       " tensor(0.2703),\n",
       " tensor(0.2227),\n",
       " tensor(0.2442),\n",
       " tensor(0.3382),\n",
       " tensor(0.1169),\n",
       " tensor(0.2401),\n",
       " tensor(0.1225),\n",
       " tensor(0.2622),\n",
       " tensor(0.2322),\n",
       " tensor(0.3501),\n",
       " tensor(0.2649),\n",
       " tensor(0.2349),\n",
       " tensor(0.3552),\n",
       " tensor(0.1259),\n",
       " tensor(0.1318),\n",
       " tensor(0.3360),\n",
       " tensor(0.2132),\n",
       " tensor(0.2100),\n",
       " tensor(0.2191),\n",
       " tensor(0.2732),\n",
       " tensor(0.2137),\n",
       " tensor(0.2444),\n",
       " tensor(0.1580),\n",
       " tensor(0.2512),\n",
       " tensor(0.2331),\n",
       " tensor(0.2724),\n",
       " tensor(0.2432),\n",
       " tensor(0.3346),\n",
       " tensor(0.3359),\n",
       " tensor(0.3318),\n",
       " tensor(0.3080),\n",
       " tensor(0.2482),\n",
       " tensor(0.2443),\n",
       " tensor(0.1661),\n",
       " tensor(0.2403),\n",
       " tensor(0.1390),\n",
       " tensor(0.3464),\n",
       " tensor(0.3316),\n",
       " tensor(0.2469),\n",
       " tensor(0.2630),\n",
       " tensor(0.2147),\n",
       " tensor(0.2645),\n",
       " tensor(0.2499),\n",
       " tensor(0.2516),\n",
       " tensor(0.1257),\n",
       " tensor(0.3460),\n",
       " tensor(0.1181),\n",
       " tensor(0.2456),\n",
       " tensor(0.2417),\n",
       " tensor(0.2443),\n",
       " tensor(0.1309),\n",
       " tensor(0.2449),\n",
       " tensor(0.2306),\n",
       " tensor(0.2204),\n",
       " tensor(0.2397),\n",
       " tensor(0.1722),\n",
       " tensor(0.2171),\n",
       " tensor(0.2398),\n",
       " tensor(0.2712),\n",
       " tensor(0.3401),\n",
       " tensor(0.1389),\n",
       " tensor(0.3211),\n",
       " tensor(0.3404),\n",
       " tensor(0.2462),\n",
       " tensor(0.2436),\n",
       " tensor(0.2246),\n",
       " tensor(0.2181),\n",
       " tensor(0.2187),\n",
       " tensor(0.2600),\n",
       " tensor(0.3821),\n",
       " tensor(0.2208),\n",
       " tensor(0.2557),\n",
       " tensor(0.2292),\n",
       " tensor(0.2344),\n",
       " tensor(0.2211),\n",
       " tensor(0.3299),\n",
       " tensor(0.1254),\n",
       " tensor(0.2270),\n",
       " tensor(0.2371),\n",
       " tensor(0.2298),\n",
       " tensor(0.2182),\n",
       " tensor(0.2423),\n",
       " tensor(0.3454),\n",
       " tensor(0.3478),\n",
       " tensor(0.3383),\n",
       " tensor(0.2425),\n",
       " tensor(0.3312),\n",
       " tensor(0.3398),\n",
       " tensor(0.3397),\n",
       " tensor(0.1233),\n",
       " tensor(0.3678),\n",
       " tensor(0.1223),\n",
       " tensor(0.2663),\n",
       " tensor(0.3363),\n",
       " tensor(0.2642),\n",
       " tensor(0.1592),\n",
       " tensor(0.2181),\n",
       " tensor(0.3326),\n",
       " tensor(0.3307),\n",
       " tensor(0.2299),\n",
       " tensor(0.3370),\n",
       " tensor(0.2520),\n",
       " tensor(0.2325),\n",
       " tensor(0.1170),\n",
       " tensor(0.2658),\n",
       " tensor(0.3406),\n",
       " tensor(0.2324),\n",
       " tensor(0.2245),\n",
       " tensor(0.2311),\n",
       " tensor(0.2333),\n",
       " tensor(0.2394),\n",
       " tensor(0.1633),\n",
       " tensor(0.2205),\n",
       " tensor(0.2654),\n",
       " tensor(0.2334),\n",
       " tensor(0.3579),\n",
       " tensor(0.3483),\n",
       " tensor(0.2630),\n",
       " tensor(0.2574),\n",
       " tensor(0.2569),\n",
       " tensor(0.1655),\n",
       " tensor(0.2645),\n",
       " tensor(0.3405),\n",
       " tensor(0.1239),\n",
       " tensor(0.2307),\n",
       " tensor(0.2726),\n",
       " tensor(0.2454),\n",
       " tensor(0.2384),\n",
       " tensor(0.2164),\n",
       " tensor(0.2473),\n",
       " tensor(0.1138),\n",
       " tensor(0.2752),\n",
       " tensor(0.4862),\n",
       " tensor(0.2652),\n",
       " tensor(0.2352),\n",
       " tensor(0.2655),\n",
       " tensor(0.1227),\n",
       " tensor(0.1630),\n",
       " tensor(0.2278),\n",
       " tensor(0.2263),\n",
       " tensor(0.3389),\n",
       " tensor(0.1712),\n",
       " tensor(0.2309),\n",
       " tensor(0.2084),\n",
       " tensor(0.2428),\n",
       " tensor(0.2651),\n",
       " tensor(0.3709),\n",
       " tensor(0.2702),\n",
       " tensor(0.1180),\n",
       " tensor(0.2217),\n",
       " tensor(0.2534),\n",
       " tensor(0.2412),\n",
       " tensor(0.2484),\n",
       " tensor(0.4838),\n",
       " tensor(0.2228),\n",
       " tensor(0.1197),\n",
       " tensor(0.2454),\n",
       " tensor(0.2377),\n",
       " tensor(0.2701),\n",
       " tensor(0.1891),\n",
       " tensor(0.2662),\n",
       " tensor(0.2481),\n",
       " tensor(0.3484),\n",
       " tensor(0.1184),\n",
       " tensor(0.2507),\n",
       " tensor(0.1248),\n",
       " tensor(0.1572),\n",
       " tensor(0.3398),\n",
       " tensor(0.2318),\n",
       " tensor(0.2710),\n",
       " tensor(0.2477),\n",
       " tensor(0.2198),\n",
       " tensor(0.1296),\n",
       " tensor(0.1204),\n",
       " tensor(0.3342),\n",
       " tensor(0.4939),\n",
       " tensor(0.1687),\n",
       " tensor(0.2056),\n",
       " tensor(0.2230),\n",
       " tensor(0.2479),\n",
       " tensor(0.2298),\n",
       " tensor(0.2378),\n",
       " tensor(0.2486),\n",
       " tensor(0.2233),\n",
       " tensor(0.2345),\n",
       " tensor(0.2502),\n",
       " tensor(0.2694),\n",
       " tensor(0.2161),\n",
       " tensor(0.2402),\n",
       " tensor(0.2394),\n",
       " tensor(0.2350),\n",
       " tensor(0.2206),\n",
       " tensor(0.3341),\n",
       " tensor(0.2262),\n",
       " tensor(0.2183),\n",
       " tensor(0.3342),\n",
       " tensor(0.2292),\n",
       " tensor(0.3315),\n",
       " tensor(0.5039),\n",
       " tensor(0.3351),\n",
       " tensor(0.2734),\n",
       " tensor(0.1193),\n",
       " tensor(0.2306),\n",
       " tensor(0.2555),\n",
       " tensor(0.4917),\n",
       " tensor(0.2385),\n",
       " tensor(0.3642),\n",
       " tensor(0.2656),\n",
       " tensor(0.2558),\n",
       " tensor(0.2240),\n",
       " tensor(0.2157),\n",
       " tensor(0.3387),\n",
       " tensor(0.1147),\n",
       " tensor(0.2330),\n",
       " tensor(0.4794),\n",
       " tensor(0.3297),\n",
       " tensor(0.1245),\n",
       " tensor(0.3367),\n",
       " tensor(0.1294),\n",
       " tensor(0.4997),\n",
       " tensor(0.2711),\n",
       " tensor(0.4916),\n",
       " tensor(0.2190),\n",
       " tensor(0.2394),\n",
       " tensor(0.2250),\n",
       " tensor(0.2154),\n",
       " tensor(0.3330),\n",
       " tensor(0.3374),\n",
       " tensor(0.2441),\n",
       " tensor(0.3358),\n",
       " tensor(0.3299),\n",
       " tensor(0.2702),\n",
       " tensor(0.2694),\n",
       " tensor(0.1258),\n",
       " tensor(0.2420),\n",
       " tensor(0.2681),\n",
       " tensor(0.4916),\n",
       " tensor(0.5016),\n",
       " tensor(0.3329),\n",
       " tensor(0.2303),\n",
       " tensor(0.1212),\n",
       " tensor(0.3505),\n",
       " tensor(0.3287),\n",
       " tensor(0.2033),\n",
       " tensor(0.2163),\n",
       " tensor(0.2429),\n",
       " tensor(0.2254),\n",
       " tensor(0.2202),\n",
       " tensor(0.2666),\n",
       " tensor(0.2619),\n",
       " tensor(0.2303),\n",
       " tensor(0.1237),\n",
       " tensor(0.3275),\n",
       " tensor(0.2392),\n",
       " tensor(0.1181),\n",
       " tensor(0.2391),\n",
       " tensor(0.1586),\n",
       " tensor(0.1236),\n",
       " tensor(0.2393),\n",
       " tensor(0.3391),\n",
       " tensor(0.3423),\n",
       " tensor(0.2456),\n",
       " tensor(0.2582),\n",
       " tensor(0.2405),\n",
       " tensor(0.2502),\n",
       " tensor(0.2314),\n",
       " tensor(0.1630),\n",
       " tensor(0.2161),\n",
       " tensor(0.1276),\n",
       " tensor(0.3397),\n",
       " tensor(0.1066),\n",
       " tensor(0.1271),\n",
       " tensor(0.2411),\n",
       " tensor(0.2397),\n",
       " tensor(0.2610),\n",
       " tensor(0.2473),\n",
       " tensor(0.1597),\n",
       " tensor(0.3109),\n",
       " tensor(0.2710),\n",
       " tensor(0.1565),\n",
       " tensor(0.2357),\n",
       " tensor(0.3348),\n",
       " tensor(0.3324),\n",
       " tensor(0.3423),\n",
       " tensor(0.2379),\n",
       " tensor(0.2325),\n",
       " tensor(0.2450),\n",
       " tensor(0.3338),\n",
       " tensor(0.2474),\n",
       " tensor(0.3468),\n",
       " tensor(0.2187),\n",
       " tensor(0.1691),\n",
       " tensor(0.2656),\n",
       " tensor(0.1606),\n",
       " tensor(0.2365),\n",
       " tensor(0.3491),\n",
       " tensor(0.4881),\n",
       " tensor(0.2620),\n",
       " tensor(0.2206),\n",
       " tensor(0.4989),\n",
       " tensor(0.3455),\n",
       " tensor(0.1579),\n",
       " tensor(0.3368),\n",
       " tensor(0.2525),\n",
       " tensor(0.2481),\n",
       " tensor(0.3381),\n",
       " tensor(0.2123),\n",
       " tensor(0.2295),\n",
       " tensor(0.1149),\n",
       " tensor(0.2384),\n",
       " tensor(0.3340),\n",
       " tensor(0.2313),\n",
       " tensor(0.2484),\n",
       " tensor(0.3331),\n",
       " tensor(0.3940),\n",
       " tensor(0.4918),\n",
       " tensor(0.1227),\n",
       " tensor(0.2179),\n",
       " tensor(0.1226),\n",
       " tensor(0.2495),\n",
       " tensor(0.2224),\n",
       " tensor(0.3403),\n",
       " tensor(0.2250),\n",
       " tensor(0.2562),\n",
       " tensor(0.2683),\n",
       " tensor(0.2292),\n",
       " tensor(0.2159),\n",
       " tensor(0.3301),\n",
       " tensor(0.3481),\n",
       " tensor(0.2346),\n",
       " tensor(0.2634),\n",
       " tensor(0.3215),\n",
       " tensor(0.2406),\n",
       " tensor(0.1258),\n",
       " tensor(0.2348),\n",
       " tensor(0.2177),\n",
       " tensor(0.2713),\n",
       " tensor(0.2432),\n",
       " tensor(0.2539),\n",
       " tensor(0.2375),\n",
       " tensor(0.2612),\n",
       " tensor(0.2330),\n",
       " tensor(0.2571),\n",
       " tensor(0.2306),\n",
       " tensor(0.2333),\n",
       " tensor(0.2445),\n",
       " tensor(0.1124),\n",
       " tensor(0.2629),\n",
       " tensor(0.3289),\n",
       " tensor(0.2342),\n",
       " tensor(0.2560),\n",
       " tensor(0.2311),\n",
       " tensor(0.2470),\n",
       " tensor(0.2355),\n",
       " tensor(0.2696),\n",
       " tensor(0.2173),\n",
       " tensor(0.2444),\n",
       " tensor(0.3279),\n",
       " tensor(0.2390),\n",
       " tensor(0.2422),\n",
       " tensor(0.2655),\n",
       " tensor(0.2398),\n",
       " tensor(0.2601),\n",
       " tensor(0.2549),\n",
       " tensor(0.2558),\n",
       " tensor(0.1152),\n",
       " tensor(0.3396),\n",
       " tensor(0.2273),\n",
       " tensor(0.2624),\n",
       " tensor(0.2414),\n",
       " tensor(0.2615),\n",
       " tensor(0.1564),\n",
       " tensor(0.2680),\n",
       " tensor(0.1626),\n",
       " tensor(0.2336),\n",
       " tensor(0.3309),\n",
       " tensor(0.2169),\n",
       " tensor(0.2676),\n",
       " tensor(0.2283),\n",
       " tensor(0.3348),\n",
       " tensor(0.3317),\n",
       " tensor(0.2469),\n",
       " tensor(0.3593),\n",
       " tensor(0.3447),\n",
       " tensor(0.3428),\n",
       " tensor(0.3276),\n",
       " tensor(0.2263),\n",
       " tensor(0.3708),\n",
       " tensor(0.2355),\n",
       " tensor(0.2384),\n",
       " tensor(0.1248),\n",
       " tensor(0.2498),\n",
       " tensor(0.2133),\n",
       " tensor(0.2674),\n",
       " tensor(0.3280),\n",
       " tensor(0.2551),\n",
       " tensor(0.2689),\n",
       " tensor(0.1683),\n",
       " tensor(0.2504),\n",
       " tensor(0.1638),\n",
       " tensor(0.2682),\n",
       " tensor(0.2337),\n",
       " tensor(0.4914),\n",
       " tensor(0.2498),\n",
       " tensor(0.1272),\n",
       " tensor(0.2556),\n",
       " tensor(0.2719),\n",
       " tensor(0.2341),\n",
       " tensor(0.2297),\n",
       " tensor(0.2449),\n",
       " tensor(0.3345),\n",
       " tensor(0.2630),\n",
       " tensor(0.2642),\n",
       " tensor(0.2121),\n",
       " tensor(0.2182),\n",
       " tensor(0.2439),\n",
       " tensor(0.2575),\n",
       " tensor(0.1227),\n",
       " tensor(0.2598),\n",
       " tensor(0.2723),\n",
       " tensor(0.2724),\n",
       " tensor(0.2418),\n",
       " tensor(0.2324),\n",
       " tensor(0.2184),\n",
       " tensor(0.2323),\n",
       " tensor(0.2074),\n",
       " tensor(0.2434),\n",
       " tensor(0.3379),\n",
       " tensor(0.2212),\n",
       " tensor(0.3426),\n",
       " tensor(0.2652),\n",
       " tensor(0.2433),\n",
       " tensor(0.2462),\n",
       " tensor(0.2408),\n",
       " tensor(0.2444),\n",
       " tensor(0.2346),\n",
       " tensor(0.2475),\n",
       " tensor(0.2089),\n",
       " tensor(0.2427),\n",
       " tensor(0.2498),\n",
       " tensor(0.2470),\n",
       " tensor(0.2289),\n",
       " tensor(0.1271),\n",
       " tensor(0.3297),\n",
       " tensor(0.2400),\n",
       " tensor(0.1266),\n",
       " tensor(0.2686),\n",
       " tensor(0.2458),\n",
       " tensor(0.2787),\n",
       " tensor(0.2338),\n",
       " tensor(0.2556),\n",
       " tensor(0.3429),\n",
       " tensor(0.2374),\n",
       " tensor(0.2763),\n",
       " tensor(0.2324),\n",
       " tensor(0.2197),\n",
       " tensor(0.2598),\n",
       " tensor(0.3368),\n",
       " tensor(0.2740),\n",
       " tensor(0.2399),\n",
       " tensor(0.2664),\n",
       " tensor(0.2313),\n",
       " tensor(0.1578),\n",
       " tensor(0.2741),\n",
       " tensor(0.2431),\n",
       " tensor(0.2322),\n",
       " tensor(0.2728),\n",
       " tensor(0.2435),\n",
       " tensor(0.2685),\n",
       " tensor(0.1163),\n",
       " tensor(0.2559),\n",
       " tensor(0.2260),\n",
       " tensor(0.2712),\n",
       " tensor(0.2676),\n",
       " tensor(0.2227),\n",
       " tensor(0.2376),\n",
       " tensor(0.1184),\n",
       " tensor(0.2358),\n",
       " tensor(0.2294),\n",
       " tensor(0.2551),\n",
       " tensor(0.2677),\n",
       " tensor(0.2291),\n",
       " tensor(0.2179),\n",
       " tensor(0.3360),\n",
       " tensor(0.2440),\n",
       " tensor(0.2229),\n",
       " tensor(0.1297),\n",
       " tensor(0.3489),\n",
       " tensor(0.2683),\n",
       " tensor(0.2173),\n",
       " tensor(0.2270),\n",
       " tensor(0.2513),\n",
       " tensor(0.2353),\n",
       " tensor(0.1242),\n",
       " tensor(0.4866),\n",
       " tensor(0.2416),\n",
       " tensor(0.1219),\n",
       " tensor(0.1690),\n",
       " tensor(0.2729),\n",
       " tensor(0.2428),\n",
       " tensor(0.3316),\n",
       " tensor(0.2320),\n",
       " tensor(0.1233),\n",
       " tensor(0.2406),\n",
       " tensor(0.2520),\n",
       " tensor(0.2328),\n",
       " tensor(0.2612),\n",
       " tensor(0.2592),\n",
       " tensor(0.3381),\n",
       " tensor(0.2417),\n",
       " tensor(0.2158),\n",
       " tensor(0.2172),\n",
       " tensor(0.4810),\n",
       " tensor(0.1690),\n",
       " tensor(0.2124),\n",
       " tensor(0.2400),\n",
       " tensor(0.3843),\n",
       " tensor(0.2348),\n",
       " tensor(0.2434),\n",
       " tensor(0.2347),\n",
       " tensor(0.2340),\n",
       " tensor(0.2256),\n",
       " tensor(0.2156),\n",
       " tensor(0.2655),\n",
       " tensor(0.2674),\n",
       " tensor(0.3370),\n",
       " tensor(0.2503),\n",
       " tensor(0.2736),\n",
       " tensor(0.3421),\n",
       " tensor(0.2753),\n",
       " tensor(0.2011),\n",
       " tensor(0.2496),\n",
       " tensor(0.2464),\n",
       " tensor(0.3098),\n",
       " tensor(0.3361),\n",
       " tensor(0.2513),\n",
       " tensor(0.2161),\n",
       " tensor(0.2435),\n",
       " tensor(0.2442),\n",
       " tensor(0.3479),\n",
       " tensor(0.2530),\n",
       " tensor(0.2276),\n",
       " tensor(0.2389),\n",
       " tensor(0.1588),\n",
       " tensor(0.2100),\n",
       " tensor(0.2350),\n",
       " tensor(0.2299),\n",
       " tensor(0.3447),\n",
       " tensor(0.2600),\n",
       " tensor(0.1641),\n",
       " tensor(0.2588),\n",
       " tensor(0.2746),\n",
       " tensor(0.1606),\n",
       " tensor(0.3375),\n",
       " tensor(0.2474),\n",
       " tensor(0.2424),\n",
       " tensor(0.2477),\n",
       " tensor(0.2493),\n",
       " tensor(0.2670),\n",
       " tensor(0.1677),\n",
       " tensor(0.2412),\n",
       " tensor(0.3402),\n",
       " tensor(0.2548),\n",
       " tensor(0.2441),\n",
       " tensor(0.2403),\n",
       " tensor(0.3332),\n",
       " tensor(0.3320),\n",
       " tensor(0.2712),\n",
       " tensor(0.1368),\n",
       " tensor(0.2626),\n",
       " tensor(0.2428),\n",
       " tensor(0.1198),\n",
       " tensor(0.2438),\n",
       " tensor(0.1323),\n",
       " tensor(0.1230),\n",
       " tensor(0.1284),\n",
       " tensor(0.2628),\n",
       " tensor(0.2254),\n",
       " tensor(0.1657),\n",
       " tensor(0.2612),\n",
       " tensor(0.2294),\n",
       " tensor(0.3408),\n",
       " tensor(0.2341),\n",
       " tensor(0.1534),\n",
       " tensor(0.3328),\n",
       " tensor(0.1221),\n",
       " tensor(0.3433),\n",
       " tensor(0.2457),\n",
       " tensor(0.2377),\n",
       " tensor(0.2349),\n",
       " tensor(0.1176),\n",
       " tensor(0.2316),\n",
       " tensor(0.2227),\n",
       " tensor(0.2634),\n",
       " tensor(0.2054),\n",
       " tensor(0.3301),\n",
       " tensor(0.2677),\n",
       " tensor(0.3348),\n",
       " tensor(0.2266),\n",
       " tensor(0.2610),\n",
       " tensor(0.2659),\n",
       " tensor(0.2769),\n",
       " tensor(0.2219),\n",
       " tensor(0.2398),\n",
       " tensor(0.2436),\n",
       " tensor(0.2626),\n",
       " tensor(0.2243),\n",
       " tensor(0.1564),\n",
       " tensor(0.3302),\n",
       " tensor(0.1668),\n",
       " tensor(0.1183),\n",
       " tensor(0.1606),\n",
       " tensor(0.3575),\n",
       " tensor(0.2353),\n",
       " tensor(0.2250),\n",
       " tensor(0.1679),\n",
       " tensor(0.2260),\n",
       " tensor(0.1310),\n",
       " tensor(0.2452),\n",
       " tensor(0.2146),\n",
       " tensor(0.2547),\n",
       " tensor(0.1641),\n",
       " tensor(0.2341),\n",
       " tensor(0.2322),\n",
       " tensor(0.2627),\n",
       " tensor(0.3159),\n",
       " tensor(0.2338),\n",
       " tensor(0.2678),\n",
       " tensor(0.3406),\n",
       " tensor(0.2359),\n",
       " tensor(0.3301),\n",
       " tensor(0.2467),\n",
       " tensor(0.2153),\n",
       " tensor(0.3557),\n",
       " tensor(0.2483),\n",
       " tensor(0.2172),\n",
       " tensor(0.4927),\n",
       " tensor(0.3300),\n",
       " tensor(0.2257),\n",
       " tensor(0.2670),\n",
       " tensor(0.2438),\n",
       " tensor(0.3786),\n",
       " tensor(0.2510),\n",
       " tensor(0.1407),\n",
       " tensor(0.2656),\n",
       " tensor(0.2449),\n",
       " tensor(0.2272),\n",
       " tensor(0.1891),\n",
       " tensor(0.2599),\n",
       " tensor(0.2221),\n",
       " tensor(0.4939),\n",
       " tensor(0.2505),\n",
       " tensor(0.2214),\n",
       " tensor(0.3462),\n",
       " tensor(0.2082),\n",
       " tensor(0.2723),\n",
       " tensor(0.2205),\n",
       " tensor(0.3821),\n",
       " tensor(0.2229),\n",
       " tensor(0.2307),\n",
       " tensor(0.1184),\n",
       " tensor(0.2587),\n",
       " tensor(0.2380),\n",
       " tensor(0.3580),\n",
       " tensor(0.2333),\n",
       " tensor(0.2632),\n",
       " tensor(0.2488),\n",
       " tensor(0.3147),\n",
       " tensor(0.2510),\n",
       " tensor(0.3384),\n",
       " tensor(0.1141),\n",
       " tensor(0.2334),\n",
       " tensor(0.2316),\n",
       " tensor(0.2705),\n",
       " tensor(0.4972),\n",
       " tensor(0.2208),\n",
       " tensor(0.2614),\n",
       " tensor(0.2608),\n",
       " tensor(0.2617),\n",
       " tensor(0.1088),\n",
       " tensor(0.2424),\n",
       " tensor(0.2372),\n",
       " tensor(0.1567),\n",
       " tensor(0.1176),\n",
       " tensor(0.2488),\n",
       " tensor(0.1172),\n",
       " tensor(0.1168),\n",
       " tensor(0.3479),\n",
       " tensor(0.1335),\n",
       " tensor(0.2514),\n",
       " tensor(0.2565),\n",
       " tensor(0.2361),\n",
       " tensor(0.2364),\n",
       " tensor(0.2284),\n",
       " tensor(0.2294),\n",
       " tensor(0.1637),\n",
       " tensor(0.2411),\n",
       " tensor(0.1696),\n",
       " tensor(0.2675),\n",
       " tensor(0.2442),\n",
       " tensor(0.2281),\n",
       " tensor(0.3381),\n",
       " tensor(0.2437),\n",
       " tensor(0.4843),\n",
       " tensor(0.2257),\n",
       " tensor(0.3346),\n",
       " tensor(0.2537),\n",
       " tensor(0.2277),\n",
       " tensor(0.3451),\n",
       " tensor(0.1217),\n",
       " tensor(0.2645),\n",
       " tensor(0.1173),\n",
       " tensor(0.2705),\n",
       " tensor(0.2272),\n",
       " tensor(0.2714),\n",
       " tensor(0.2434),\n",
       " tensor(0.2229),\n",
       " tensor(0.2402),\n",
       " tensor(0.1389),\n",
       " tensor(0.2592),\n",
       " tensor(0.3399),\n",
       " tensor(0.2289),\n",
       " tensor(0.2630),\n",
       " tensor(0.2511),\n",
       " tensor(0.3326),\n",
       " tensor(0.2489),\n",
       " tensor(0.2330),\n",
       " tensor(0.1218),\n",
       " tensor(0.2232),\n",
       " tensor(0.2601),\n",
       " tensor(0.2312),\n",
       " tensor(0.2493),\n",
       " tensor(0.2570),\n",
       " tensor(0.1318),\n",
       " tensor(0.2337),\n",
       " tensor(0.2560),\n",
       " tensor(0.2577),\n",
       " tensor(0.4904),\n",
       " tensor(0.2415),\n",
       " tensor(0.2686),\n",
       " tensor(0.1181),\n",
       " tensor(0.3615),\n",
       " tensor(0.4942),\n",
       " tensor(0.2715),\n",
       " tensor(0.1212),\n",
       " tensor(0.2345),\n",
       " tensor(0.2753),\n",
       " tensor(0.3469),\n",
       " tensor(0.2411),\n",
       " tensor(0.2515),\n",
       " tensor(0.2351),\n",
       " tensor(0.1638),\n",
       " tensor(0.2465),\n",
       " tensor(0.2560),\n",
       " tensor(0.4868),\n",
       " tensor(0.2099),\n",
       " tensor(0.2216),\n",
       " tensor(0.2336),\n",
       " tensor(0.1208),\n",
       " tensor(0.1175),\n",
       " tensor(0.1245),\n",
       " tensor(0.2148),\n",
       " tensor(0.1190),\n",
       " tensor(0.2505),\n",
       " tensor(0.2241),\n",
       " tensor(0.2398),\n",
       " tensor(0.3405),\n",
       " tensor(0.2420),\n",
       " tensor(0.2202),\n",
       " tensor(0.2254),\n",
       " tensor(0.2449),\n",
       " tensor(0.2358),\n",
       " tensor(0.2660),\n",
       " tensor(0.2437),\n",
       " tensor(0.1541),\n",
       " tensor(0.1184),\n",
       " tensor(0.2214),\n",
       " tensor(0.2267),\n",
       " tensor(0.3321),\n",
       " tensor(0.2339),\n",
       " tensor(0.3535),\n",
       " tensor(0.1631),\n",
       " tensor(0.2348),\n",
       " tensor(0.2461),\n",
       " tensor(0.1679),\n",
       " tensor(0.2792),\n",
       " tensor(0.2329),\n",
       " tensor(0.3435),\n",
       " tensor(0.3421),\n",
       " tensor(0.2458),\n",
       " tensor(0.2470),\n",
       " tensor(0.2360),\n",
       " tensor(0.3279),\n",
       " tensor(0.1632),\n",
       " tensor(0.2397),\n",
       " tensor(0.2372),\n",
       " tensor(0.2510),\n",
       " tensor(0.2189),\n",
       " tensor(0.2613),\n",
       " tensor(0.3342),\n",
       " tensor(0.2533),\n",
       " tensor(0.3443),\n",
       " tensor(0.2375),\n",
       " tensor(0.3509),\n",
       " tensor(0.1631),\n",
       " ...]"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prob for prob in calc_preds(coeffs, t_indep)] # should be 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "e22a96b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0020)"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acc(coeffs) \n",
    "\n",
    "##\n",
    "# predictions = tf.nn.sigmoid(predictions)\n",
    "# predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "# print('Predictions:\\n', predictions.numpy())\n",
    "# print('Labels:\\n', label_batch)\n",
    "\n",
    "# pass in a h5ad file and get back \n",
    "#Predictions:\n",
    "# [0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0]\n",
    "# Perturbations:\n",
    "# [0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "66dfff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install --quiet hyperopt\n",
    "# !pip install --quiet \"ray[tune]\"\n",
    "# !pip install --quiet scvi-colab\n",
    "# from scvi_colab import install\n",
    "\n",
    "# install()\n",
    "\n",
    "\n",
    "# import ray\n",
    "# import scanpy as sc\n",
    "# import scvi\n",
    "# from ray import tune\n",
    "# from scvi import autotune\n",
    "# model_cls = scvi.model.SCVI\n",
    "# model_cls.setup_anndata(adata)\n",
    "# scvi_tuner = autotune.ModelTuner(model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "385450cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmarkResults():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "7a58542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scgen\n",
    "adata.obs.rename({\"label\": \"condition\"}, axis=1, inplace=True)\n",
    "adata.obs[\"condition\"].replace({\"ctrl\": \"control\", \"stim\": \"stimulated\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02605-1\n",
    "\n",
    "# adata_t = adata[\n",
    "#     ~(\n",
    "#         (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "#         & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "#     )\n",
    "# ].copy()\n",
    "\n",
    "# cd4t_stim = adata[\n",
    "#     (\n",
    "#         (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "#         & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "#     )\n",
    "# ].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scgen.SCGEN.setup_anndata(adata_t, batch_key=\"condition\", labels_key=\"cell_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "05b5f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = scgen.SCGEN(adata_t, n_hidden=800, n_latent=100, n_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "214e901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(\n",
    "#     max_epochs=1, batch_size=32, early_stopping=True, early_stopping_patience=25\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "4f6f2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata_t.obsm[\"scgen\"] = model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "84889a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.neighbors(adata_t, use_rep=\"scgen\")\n",
    "# sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "5ec93614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "6a4a815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred, delta = model.predict(\n",
    "#     ctrl_key=\"control\", stim_key=\"stimulated\", celltype_to_predict=\"CD4 T cells\"\n",
    "# )\n",
    "\n",
    "# # we annotate the predicted cells to distinguish them later from ground truth cells.\n",
    "# pred.obs[\"condition\"] = \"prediction\"\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c5ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "8d6ca81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "b7007635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train = adata\n",
    "# ctrl_adata = adata[\n",
    "#     ((adata.obs[\"cell_type\"] == \"CD4 T cells\") & (adata.obs[\"condition\"] == \"control\"))\n",
    "# ]\n",
    "# stim_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'stimulated'))]\n",
    "\n",
    "# # concatenate pred, control and real CD4 T cells in to one object\n",
    "# eval_adata = ctrl_adata.concatenate(cd4t_stim, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "c1bc85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.pca(eval_adata)\n",
    "# sc.pl.pca(eval_adata, color=\"condition\", frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "66b16e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd4t_adata = adata[adata.obs[\"cell_type\"] == \"CD4 T cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "3508e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.rank_genes_groups(cd4t_adata, groupby=\"condition\", method=\"wilcoxon\")\n",
    "# diff_genes = cd4t_adata.uns[\"rank_genes_groups\"][\"names\"][\"stimulated\"]\n",
    "# diff_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_value = model.reg_mean_plot(\n",
    "#     eval_adata,\n",
    "#     axis_keys={\"x\": \"predicted stimulated\", \"y\": \"stimulated\"},\n",
    "#     gene_list=diff_genes[:10],\n",
    "#     top_100_genes=diff_genes,\n",
    "#     labels={\"x\": \"predicted\", \"y\": \"ground truth\"},\n",
    "#     show=True,\n",
    "#     legend=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.violin(eval_adata, keys=\"ISG15\", groupby=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pertpy as pt\n",
    "# import muon as mu\n",
    "# import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata = pt.dt.papalexi_2021()\n",
    "# for col in mdata.obs: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a027076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.normalize_total(mdata[\"rna\"])\n",
    "# sc.pp.log1p(mdata[\"rna\"])\n",
    "# sc.pp.highly_variable_genes(mdata[\"rna\"], subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.prot.pp.clr(mdata[\"adt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe04851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.pca(mdata[\"rna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5308a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate neighbors with the cosine distance similarly to the original Seurat implementation\n",
    "# sc.pp.neighbors(mdata[\"rna\"], metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0721f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.umap(mdata[\"rna\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40747691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.umap(mdata[\"rna\"], color=[\"replicate\", \"Phase\", \"perturbation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f25d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms = pt.tl.Mixscape()\n",
    "\n",
    "# ms.perturbation_signature(\n",
    "#     mdata[\"rna\"],\n",
    "#     pert_key=\"perturbation\",\n",
    "#     control=\"NT\",\n",
    "#     split_by=\"replicate\",\n",
    "#     n_neighbors=20,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy of the object to recalculate the PCA.\n",
    "# Alternatively we could replace the X of the RNA part of our MuData object with the `X_pert` layer.\n",
    "# adata_pert = mdata[\"rna\"].copy()\n",
    "# adata_pert.X = adata_pert.layers[\"X_pert\"]\n",
    "# sc.pp.pca(adata_pert)\n",
    "# sc.pp.neighbors(adata_pert, metric=\"cosine\")\n",
    "# sc.tl.umap(adata_pert)\n",
    "# sc.pl.umap(adata_pert, color=[\"replicate\", \"Phase\", \"perturbation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3197d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms.mixscape(adata=mdata[\"rna\"], control=\"NT\", labels=\"gene_target\", layer=\"X_pert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ffa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata[\"rna\"].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.perturbscore(\n",
    "#     adata=mdata[\"rna\"], labels=\"gene_target\", target_gene=\"IFNGR2\", color=\"orange\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.settings.set_figure_params(figsize=(10, 10))\n",
    "# pt.pl.ms.violin(\n",
    "#     adata=mdata[\"rna\"],\n",
    "#     target_gene_idents=[\"NT\", \"IFNGR2 NP\", \"IFNGR2 KO\"],\n",
    "#     groupby=\"mixscape_class\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee147bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.heatmap(\n",
    "#     adata=mdata[\"rna\"],\n",
    "#     labels=\"gene_target\",\n",
    "#     target_gene=\"IFNGR2\",\n",
    "#     layer=\"X_pert\",\n",
    "#     control=\"NT\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d44870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdata[\"adt\"].obs[\"mixscape_class_global\"] = mdata[\"rna\"].obs[\"mixscape_class_global\"]\n",
    "# pt.pl.ms.violin(\n",
    "#     adata=mdata[\"adt\"],\n",
    "#     target_gene_idents=[\"NT\", \"JAK2\", \"STAT1\", \"IFNGR1\", \"IFNGR2\", \"IRF1\"],\n",
    "#     keys=\"PDL1\",\n",
    "#     groupby=\"gene_target\",\n",
    "#     hue=\"mixscape_class_global\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms.lda(adata=mdata[\"rna\"], labels=\"gene_target\", layer=\"X_pert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt.pl.ms.lda(adata=mdata[\"rna\"])\n",
    "#https://zenodo.org/record/7058382\n",
    "# folders = '/home/awahab/llm-testing/data_sets/'\n",
    "# fp1 = 'SC3_v3_NextGem_DI_CRISPR_A549_5K_Multiplex_count_raw_feature_bc_matrix.h5'\n",
    "# fp2 = 'SC3_v3_NextGem_DI_CRISPR_A549_5K_Multiplex_count_raw_molecule_info.h5'\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# import anndata\n",
    "\n",
    "# # Read the .h5 File\n",
    "# def explore_h5py_group(group, indent=0):\n",
    "#     \"\"\"Recursively print the contents of an h5py group/dataset.\"\"\"\n",
    "#     print(group.data.name)\n",
    "#     items = sorted(group.items())\n",
    "#     for name, item in items:\n",
    "#         if isinstance(item, h5py.Dataset):  # Check if item is a dataset\n",
    "#             print(\"  \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "#         elif isinstance(item, h5py.Group):  # Check if item is a group\n",
    "#             print(\"  \" * indent + f\"Group: {name}\")\n",
    "#             explore_h5py_group(item, indent + 1)  # Recursive call to explore subgroups\n",
    "\n",
    "# # Open your HDF5 file\n",
    "# with h5py.File(folders + fp1, 'r') as f:\n",
    "#     explore_h5py_group(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
