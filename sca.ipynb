{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d32f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolate sca onto mm datasets\n",
    "# 1. train algo on all data sets available\n",
    "# 2. apply to all multi-omics datasets aviable\n",
    "# 3. identify features which have statistical correlation\n",
    "# 4. improve multi-view algo until it predicts perturbations at earliest possible onset -> \n",
    "# 5. find adjacent problems worth solving\n",
    "\n",
    "#invent algorithm for detecting pertrubations \n",
    "#loop through every high_variable_column\n",
    "#loop through every row\n",
    "#fidn rows where 1 gene is above zscore\n",
    "# find orthogonal features of 7000 element matrix\n",
    "# cant do that without iteration to find nonlinear statistical relationship occurances\n",
    "# remove noise\n",
    "# find where columns overlap \n",
    "# attempt to cluster in batches of 100\n",
    "# happiest bear in the world - (infinite thank you + apologetic) 4ever\n",
    "# dont affect stream negatively - always think of effect on others \n",
    "# dont take any breaks\n",
    "# finsih this problem by noon - continue everyday forever for 100 years\n",
    "# https://zenodo.org/record/6546964\n",
    "\n",
    "\n",
    "# classify how different perturbations contain different profiles of information distance\n",
    "\n",
    "#many people just want a cool matrix transform that encodes probabilitiy from gene expression matrix\n",
    "# we dont want dimensionality reduction\n",
    "#most people just want it to work asap and dont care \n",
    "#eggnog wants to be silent typist and wants everyone in stream to be happy - also finish by noon \n",
    "#timebox - what can be solved in 2-12?\n",
    "#go to austin tomorrow - chill w/ computer\n",
    "\n",
    "#5000 x 2000 = too slow for python\n",
    "#other datasets 100x more data\n",
    "\n",
    "#determine what causes the variation in the gene expression profile\n",
    "#which gene contribute most magnitude in amplitude\n",
    "#filter data that isnt relevant \n",
    "#whats left is is just the perturbations (depending on experiment intent and data)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d538764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "results_file = 'write/pbmc3k.h5ad'  # the file that will store the analysis results\n",
    "adata = sc.read_10x_mtx(\n",
    "    'data/filtered_gene_bc_matrices/hg19/',  # the directory with the `.mtx` file\n",
    "    var_names='gene_symbols',                # use gene symbols for the variable names (variables-axis index)\n",
    "    cache=True)      \n",
    "sc.pp.highly_variable_genes(adata, \n",
    "                                layer=None, \n",
    "                                n_top_genes=200, \n",
    "                                min_disp=0.5, \n",
    "                                max_disp=1, \n",
    "                                min_mean=0.0125, \n",
    "                                max_mean=3, \n",
    "                                span=0.3, \n",
    "                                n_bins=20, \n",
    "                                flavor='seurat_v3', \n",
    "                                subset=False, \n",
    "                                inplace=True, \n",
    "                                batch_key=None, \n",
    "                                check_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3609c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncounts       ctrl =    7085.9976    pert =  7251.1616\n",
      "ngenes       ctrl =    1460.5028512358208    pert =  1472.5600646518021\n",
      "percent_mito       ctrl =    2.642741    pert =  2.799472\n",
      "percent_ribo       ctrl =    3.813907    pert =  3.8422022\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, find\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas \n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "rowGeneExpression2 = defaultdict(dict)\n",
    "import math\n",
    "import torch\n",
    "pandas.set_option('mode.use_inf_as_na', True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "import scanpy as sc\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix, tril\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from fastprogress.fastprogress import master_bar \n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)\n",
    "#one ='DatlingerBock2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "folders = '/home/awahab/llm-testing/data_sets/'\n",
    "#one = 'AdamsonWeissman2016_GSM2406675_10X001.h5ad' #sigmoid returns nan in 0th frame\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "one = 'AissaBenevolenskaya2021.h5ad'\n",
    "one = 'SrivatsanTrapnell2020_sciplex2.h5ad'\n",
    "one ='DatlingerBock2017.h5ad'\n",
    "#one = 'AdamsonWeissman2016_GSM2406675_10X001.h5ad'\n",
    "#one = 'AissaBenevolenskaya2021.h5ad'\n",
    "#one = 'XieHon2017.h5ad'\n",
    "#one = 'SrivatsanTrapnell2020_sciplex2.h5ad'\n",
    "def readFiles():\n",
    "    adata = sc.read_h5ad(folders + one)\n",
    "    one ='DatlingerBock2017.h5ad'\n",
    "    return adata\n",
    "adata = sc.read_h5ad(folders + one)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, \n",
    "                                layer=None, \n",
    "                                n_top_genes=200, \n",
    "                                min_disp=0.5, \n",
    "                                max_disp=1, \n",
    "                                min_mean=0.0125, \n",
    "                                max_mean=3, \n",
    "                                span=0.3, \n",
    "                                n_bins=20, \n",
    "                                flavor='seurat_v3', \n",
    "                                subset=False, \n",
    "                                inplace=True, \n",
    "                                batch_key=None, \n",
    "                                check_values=True)\n",
    "\n",
    "sc.pp.pca(adata)\n",
    "found = find(adata.X)\n",
    "torch.manual_seed(440)\n",
    "#adata.obs.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "#adata.obs = adata.iloc[:5000]\n",
    "#adata.obs= adata.obs[adata.obs.iloc[:5000]]\n",
    "#adata.obs.iloc[:5000]\n",
    "#adata.var_names\n",
    "var_df = adata.var\n",
    "df = adata.obs#.iloc[:5000]\n",
    "df = df.drop(columns=['nperts'])\n",
    "df['percent_mito'] = 1\n",
    "def getMode(l): \n",
    "    return max(set(l), key=l.count)\n",
    "#sc.pp.filter_cells(adata, min_counts=None, min_genes=None, max_counts=None, max_genes=10, inplace=True, copy=False)\n",
    "#sc.pp.filter_genes(adata, min_counts=None, min_cells=None, max_counts=None, max_cells=None, inplace=True, copy=False)\n",
    "#sc.pp.highly_variable_genes(adata, layer=None, n_top_genes=None, min_disp=0.5, max_disp=inf, min_mean=0.0125, max_mean=3, span=0.3, n_bins=20, flavor='seurat', subset=False, inplace=True, batch_key=None, check_values=True)\n",
    "#sc.pp.regress_out(adata, keys, n_jobs=None, copy=False)\n",
    "#cell perturbation is defined as molecular response or gene expression that is different to what is \"normal\"\n",
    "from IPython.display import IFrame\n",
    "#check for expression values that are equal from crispr\n",
    "#join with gene ontology\n",
    "#this is a program\n",
    "#input an adata file\n",
    "#outputs a list of cell-IDs and the genes perturbed \n",
    "#and then what that gene does \n",
    "#and what interactions may occur with those perturbations \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "#df['chembl-ID'] = label_encoder1.fit_transform(df['chembl-ID'])\n",
    "df['perturbation_2'] = label_encoder1.fit_transform(df['perturbation_2'])\n",
    "df['target_2'] = label_encoder2.fit_transform(df['target'])\n",
    "cool_columns = 'ncounts ngenes percent_mito percent_ribo'.split(' ')\n",
    "for key in cool_columns:\n",
    "    ct = adata.obs[adata.obs['perturbation'] == 'control'][key].std()\n",
    "    pt = adata.obs[adata.obs['perturbation'] != 'control'][key].std()\n",
    "    print(key, '      ctrl =   ', ct, '   pert = ', pt)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45167ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4585"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from collections import defaultdict\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "sums = []\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "control_variables = set(['ctrl', 'control', '*'])\n",
    "dependent_variables = list(df['perturbation'].map(lambda val: 0 if val in control_variables else 1).values)\n",
    "geneValues = defaultdict(int)\n",
    "columnMode = defaultdict(list)\n",
    "geneAverages = defaultdict(int)\n",
    "geneOccurences = defaultdict(int)\n",
    "geneVariance = defaultdict(list)\n",
    "cell_variance_score = defaultdict(int)\n",
    "\n",
    "row_variance = [] \n",
    "c,g,v = found\n",
    "\n",
    "cell_variance_score = {}\n",
    "for i in range(df.shape[0]): cell_variance_score[i]= 0\n",
    "\n",
    "for cell,gene,val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneValues[gene] += val\n",
    "    geneOccurences[gene] += 1\n",
    "    columnMode[gene].append(val)\n",
    "    \n",
    "for k in dict(geneValues):\n",
    "    geneAverages[k] =  geneValues[k] / geneOccurences[k]\n",
    "    \n",
    "for k in dict(geneValues): columnMode[k] = getMode(columnMode[k])\n",
    "    \n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneVariance[gene].append(abs(val - geneAverages[gene]))# ** 2\n",
    "    \n",
    "    \n",
    "for k in dict(geneAverages):  \n",
    "    geneVariance[k] = max(set(geneVariance[k]), key=geneVariance[k].count)\n",
    "\n",
    "geneModes = defaultdict(list)\n",
    "\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    geneModes[gene].append(abs(val))# ** 2\n",
    "\n",
    "for val in geneModes: geneModes[val] = max(set(geneModes[val]), key=geneModes[val].count)\n",
    "\n",
    "num_cells = len(df.select_dtypes(include=[int, float]).values.tolist())\n",
    "    \n",
    "mini_cell_var = defaultdict(list)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if (cellColorForGene - columnColor) < 0:\n",
    "        mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "      \n",
    "for key in mini_cell_var: mini_cell_var[key] = max(mini_cell_var[key])\n",
    "        \n",
    "df['geneVarianceScore'] = cell_variance_score.values()\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "independent_variables = pd.DataFrame(numerical_values)\n",
    "\n",
    "vals += .01\n",
    "t_dep = tensor([float(i) for i in dependent_variables]) # pertrubations\n",
    "t_indep = tensor(numerical_values, dtype=torch.float)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "\n",
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals\n",
    "trn_split,val_split=RandomSplitter(seed=42)(independent_variables)\n",
    "\n",
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "\n",
    "indep_cols =  df.select_dtypes(include=[int, float]).columns.tolist()\n",
    "indep_cols\n",
    "\n",
    "len([item for item in list(t_dep) if item.item() == 0])\n",
    "len([item for item in list(t_dep) if item.item() > .5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd3dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct722, total_guess943, perb_total 4585, accuracy 0.7656415694591728\n",
      "precision 0.20567066521264996\n"
     ]
    }
   ],
   "source": [
    "cell_variance_score= defaultdict(int)\n",
    "for cell, gene, val in zip(c,g,v):\n",
    "    if gene not in high_variance_columns: continue\n",
    "    columnColor = geneAverages[gene]\n",
    "    cellColorForGene = val\n",
    "    threshold = columnColor\n",
    "    if abs(cellColorForGene) > columnColor and columnColor < 1:\n",
    "        #mini_cell_var[cell].append(cellColorForGene - columnColor)\n",
    "        cell_variance_score[cell] += abs(cellColorForGene - columnColor)\n",
    "l = cell_variance_score.values()   \n",
    "avg = sum(l) / len(l)\n",
    "avg = 0\n",
    "import random\n",
    "cvs = cell_variance_score.values()\n",
    "mini_cell_var.values()\n",
    "total_guess = len([item for key, item in enumerate(cvs) if item > avg])\n",
    "correct_guess = len([item for key, item in enumerate(cvs) if item > avg and dependent_variables[key] == 1])\n",
    "perb_total =  len([item for key, item in enumerate(dependent_variables) if dependent_variables[key] == 1])\n",
    "print(f'correct{correct_guess}, total_guess{total_guess}, perb_total {perb_total}, accuracy {correct_guess / total_guess}')\n",
    "print(f'precision {total_guess / perb_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c75d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = []\n",
    "# test = defaultdict(int)\n",
    "# for i in high_variance_columns:\n",
    "#     m=adata.X.getcol(i).todense()\n",
    "#     mode = getMode(m.tolist()[0]) \n",
    "#     avg = sum(m.tolist()[0]) / len(m.tolist()[0])\n",
    "#     pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] > 0])\n",
    "#     not_pert_and_above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0 and dependent_variables[k] < 1])\n",
    "#     above_zero = len([i for k, i in enumerate(m.tolist()) if i[0] > 0])\n",
    "#     eq_zero = len([i for k, i in enumerate(m.tolist()) if i[0] == 0])\n",
    "#     test[i] = above_zero\n",
    "#     cellCounts = 5904\n",
    "#     if (above_zero > 30): continue # 90%\n",
    "#     for key,element in enumerate(m.tolist()):\n",
    "#         if element[0] > 0: count.append(key)\n",
    "# print(len(set(count)))\n",
    "# count = set(count)\n",
    "# print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]),len([x for row, x in enumerate(count) if dependent_variables[x] < 1]))\n",
    "# print(len([x for row, x in enumerate(count) if dependent_variables[x] > 0]) / len([x for row, x in enumerate(count)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb0b6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "12156\n"
     ]
    }
   ],
   "source": [
    "category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "most_cells = category_indices[2]\n",
    "\n",
    "most_cell_indices = []\n",
    "for i in most_cells:\n",
    "    most_cell_indices.append(adata.obs.index.get_loc(i))\n",
    "\n",
    "a=most_cell_indices[0]\n",
    "b=most_cell_indices[10]\n",
    "\n",
    "b_matrix = adata.X.getrow(b).todense().tolist()[0]\n",
    "a_matrix = adata.X.getrow(a).todense().tolist()[0]\n",
    "\n",
    "a_matrix\n",
    "print(len(most_cells))\n",
    "sum(a_matrix), sum(b_matrix)\n",
    "count = {}\n",
    "        \n",
    "distance = defaultdict(int)\n",
    "indicesAbove = defaultdict(list)\n",
    "\n",
    "for row in range(5904):\n",
    "    m = adata.X.getrow(row).todense().tolist()[0]\n",
    "    for k in high_variance_columns:\n",
    "        if (geneAverages[k]) < m[k] and m[k] < 100:\n",
    "            distance[k] += m[k]\n",
    "            indicesAbove[row].append(k)\n",
    "            \n",
    "distance_max = max(list(distance.values()))\n",
    "\n",
    "for k in distance:\n",
    "    if distance[k] == distance_max: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f01653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.zscore(adata.X.getcol(0).todense().tolist())\n",
    "indicesAbove = dict(indicesAbove)\n",
    "# for cell,gene,val in zip(c,g,v):\n",
    "#     if gene not in high_variance_columns: continue\n",
    "#     geneValues[gene] += val\n",
    "#     geneOccurences[gene] += 1\n",
    "#     columnMode[gene].append(val)\n",
    "\n",
    "timesAbove = defaultdict(int)\n",
    "geneAboveMeanOccurances = defaultdict(list)\n",
    "\n",
    "for row in dict(indicesAbove): \n",
    "    for column in indicesAbove[row]: \n",
    "        geneAboveMeanOccurances[column].append(row)\n",
    "        \n",
    "prob_perts = {} \n",
    "\n",
    "filteredGeneCellLists = defaultdict(list)\n",
    "\n",
    "threshold = 30\n",
    "\n",
    "for geneList in geneAboveMeanOccurances:\n",
    "    cellsWithGene = geneAboveMeanOccurances[geneList]\n",
    "    if  threshold < len(cellsWithGene) and len(cellsWithGene) < 100:\n",
    "        filteredGeneCellLists[geneList] = cellsWithGene\n",
    "\n",
    "cellToGeneEmbedding = [[] for i in range(5904)]\n",
    "\n",
    "for column in filteredGeneCellLists:\n",
    "    cellList = filteredGeneCellLists[column]\n",
    "    for cellRow in cellList:\n",
    "        cellToGeneEmbedding[cellRow].append(column)\n",
    "    \n",
    "cellToGeneEmbedding\n",
    "\n",
    "cellCount = 0\n",
    "for cellList in list(filteredGeneCellLists.values()):\n",
    "    cellCount += len(cellList)\n",
    "    \n",
    "totalCells = []\n",
    "for key in (filteredGeneCellLists.keys()):\n",
    "    cellList = filteredGeneCellLists[key]\n",
    "    totalCells += cellList\n",
    "    for cell in cellList:\n",
    "        gene = adata.var.iloc[cell].name\n",
    "        row = df.iloc[cell]\n",
    "        \n",
    "len(set(totalCells))\n",
    "\n",
    "len([item for key, item in enumerate(t_dep) if item.item() > .5 and key in totalCells])\n",
    "total = defaultdict(int)\n",
    "for row in range(500):\n",
    "    total[row] += sum(adata.X.getrow(row).data)\n",
    "avg = sum(list(total.values())) / 500\n",
    "\n",
    "counter = 0\n",
    "for key, item in enumerate(list(total.values())):\n",
    "    if item > avg:\n",
    "        counter += 1\n",
    "        \n",
    "counter\n",
    "count_per_category = df.groupby('perturbation').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc8eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAD2CAYAAAB2ieWyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA19klEQVR4nO3dfXQUVZ438G8nkoCBBJqXhEhAwBcYeQs0RmB1OWOO6KMjLIyveMYXVmfcAAruDsucVVbWI46eUR5m0ZlxFd3DKMo5KqOz6oMo+EJEOgRfULLK+wAJKCSBAAGT+/zRXdXV9E13dfet21Wd7+ccTlWqq+veqlvVVP3urXt9QggBIiIiIk1yMp0BIiIi6lx480FERERa8eaDiIiItOLNBxEREWnFmw8iIiLSijcfREREpBVvPoiIiEgr3nwQERGRVrz5ICIiIq1480FERERaOXbzsXz5cpx//vno2rUrKioq8NlnnzmVFBEREXmIIzcfr7zyCubPn49FixZhy5YtGD16NKZMmYJDhw45kRwRERF5iM+JgeUqKiowfvx4/Od//icAoL29HWVlZZgzZw7+9V//Ne5329vbceDAAfTo0QM+n0911oiIiMgBQggcO3YMpaWlyMmJH9s4R3Xip0+fRk1NDRYuXGguy8nJQWVlJaqrq2PWb21tRWtrq/n3/v378ZOf/ER1toiIiEiDffv2YcCAAXHXUX7z8f3336OtrQ3FxcVRy4uLi7F9+/aY9ZcsWYKHH344Zvlf//pXFBQUxCw/f/Jkc373+vWhZYMsy/asTynfTpLlmezx0rEz8upUPlUdi9G5oe183pb8NuLto/TadFH55Q6fDABo+0ZtPozjCQA5n4emtSPUpuFlqq+LdM5fGaev22zU0TFraWnBtddeix49eiTchvKbj2QtXLgQ8+fPN/9ubm5GWVkZCgoK0L1795j1Cy3zxueFPWKXuYksz2SPl46dkVen8qnqWBTmhrfRlvw24u2j9NqULMuU3HBm2hTnwzieAJDTLTTN9L66ierrIp3zV7q98JRlZl+iY2anyYTym48+ffogNzcXDQ0NUcsbGhpQUlISs35+fj7y8/NVZ4OIiIhcSvnNR15eHsaNG4d169Zh2rRpAEKNSNetW4fZs2envf2dwWDswj6WecnHqg0JBDrOi4Td9SjCOMaprJ+p4+2Wck50LHK2hGdGq03Xmta4z0N52HrSssK21LZbnhvZn9q2UBqplHf5/wtNg+fZS9duGk3lkXn/q8+E0pClH94PYx+SkXtJ6Ltt22zuq+SYZYrq6yK3LDQN7lazPaev28CpSFkEu7rjN8INHKl2mT9/Pm6//XYEAgFceumlWLp0KVpaWnDnnXc6kRwRERF5iCM3HzfddBMOHz6Mhx56CPX19RgzZgzeeeedmEao6Qp88ygAIKj5idP/fWhq98478FEvcz54+VFl+ZA9mRlPnABwdJbkS+G879zt7jtwY3+s+zh3XGh+WU1s3q1PL8lGplJhN43A9tB6wWHp58Xu/vR6Lv7nNaM7jh6oOlfNNLpZ00htW9Yn92TL1hoBCJ6XXAZkaVivL2MfjWsKAMSaewEARy2BO2M7ZoTEslm7+yOLeBjf3XMydj3V0Y50IosqrkfrcQ+mEd6O9xviFLdHO6TntIUsYud/4XIA6VU0ONbgdPbs2UqqWYiIiCi7cGwXIiIi0irjr9qmIzj8N5lJN8kqC5VVLVay8Lo1bDYEknDnbkeyokW8UKnuBqfGsQ8URNI9Mjw2fRXVLYbAlkmR7Y79pMP1ZKFTq3iNeROdq0W14Zm2uKuZodxJlv6Tl9XE/44d/nB/hG1f22tQaW0MmnsyuUabMrJj22tNZH7rreH8Sdbz7wlNg4cjy+weTxnju+nsj13pXFOJqgHtiKpCTmN3dVa3GIzGwoCesgr0DVf1HraXVqLfC1l1YXDEU6lkLQojH0RERKSVI2O7pKO5uRlFRUVYv3697U5fjEZEQGbubBMJ7PzcnA8OUfx+o0voiDzoaEgqE+8VySHnW/bb5Y14z+aG15NVyNR5IWNEwoItsXkJ7A9/lqDha7Kv5GZLOZIamWxwf/z4cUyePBlNTU0oLCyUfdXEyAcRERFpxZsPIiIi0iorql3chCFQtXg8neOVYyvLp928yxrXqt5Xu72JGo1woxqFu6jKiJyRqessE+my2oWIiIhcy9Ov2ib71JCoJzcV6cqWZerOV/akpVOy+20tH99toWlbbeTzcqQ+NoZqxutsbUciy4xX0pzqbTXw1TxzPt6rbonO843hBtpD0s5Rx4xoQO7myKCR8V4Pjsd67AIjQ9s90tHKxnrhc8V6/uR+uyqUj5Ry0bHczy835//PHb8FACwOLohZ78FZvwMATLNkwOydNMG4N8m+PukmRpkFv3R33p1qPO5/NXKt6jwCbo+mMfJBREREWvHmg4iIiLTydLWLbDC1eFUM7WMtf6TQo+DZ6Tq1vl2J9tuough+6UjyCSW73z5LFygT80JT1/Z1UBKa1FrC4IE9Rmg8sprSvPT6yNZqR6da/tgd+/lEsy+cjns6TYW1DHK/Cc90u1ZpGnhjNQBgpbjBXDRR1nPqyNCk1hrqF0b+FJ8f/SPl8j94FwCwWLLaI92mAQCmIdKL7KCW0HRnojTWhqdjUslgZomVoWmNoi6O4lUnb7T0+TQxyT6fHOun59hkyx9p/Mdjk+pGzE41imbkg4iIiLTKildt7b7qpoOqRq0qJNtTIiUvnSctL7LbiNl4WrKO65GJ68HaiNAYg0V1PqwRH//HoalsGPXAzo2hz4ZMTDkNtzci1IHHQi/Z8e7od4Cv2hIREZFr8eaDiIiItPJ0g1ODddhsHS9Sxwv7ZbqqxSrbqlvcGG7tDFUtVnbPb1lPpCqvzUQNjGU9m/q+D2djt7p8AID/vyLzsuoW8zNJdYsbz2m384erz7xyxNw+8GkiTv0/x8gHERERaZUVkQ9ro7Z4VL2OyacUZyTqYdBNxz0TT6xO9cDoqO8t87vT35zZiDrBcTd+E6yv1y/rrS4fUYal/lW754+bzv1ME+Fzqua8zObDrk+ej8yret0401T8/jHyQURERFrx5oOIiIi08nS1ixH6OWpdGCcKpLvHt0w3Jst0+slKpyohnWHXU2G3qk+lPQVqtpPOeRGvnw9ZHzeq8mzI2RKalo9Nvm+fuc+GBrkLjk2wYrLW7jBnhzw8FID9Y+u1a9QNjs4Kz3jkkPn6ROY9kuUoTvUXxcgHERERaZUVPZy6qVdR7WOMUEbInli98hSrI59uPBZO5Smda96Nx4kyL53zIpPnFHs4JSIiItfizQcRERFplRUNTmuSbNwFOBeSYvg0dV6vsnI6z3arF910HFUP+ijruTReD6dRnxl9juxOOxsdph+vcZ4sT06Vj5vOAUqem/qhcqoah5EPIiIi0iorGpzqluydIJ9C1HBj4zydZetkFMFNx9QpgVOh/Y03/koq7B5HrzYipPR0puuMDU6JiIjItXjzQURERFp5usGpQXdDvGS/m+2hNjfIVGhTZ1qqexj0ynmpoh8NAJhoVDDXqMiVhWXwvMA74aqdYbH59L9weeizFJLwSlnp4FSPm05JpzfkVM591VV0bHBKREREWSErIh++Hn825+Pdm/HpwXusUa2jks8z1RDPyJc5zgQiTzhO9bKrqiffwMjw0/mXavOZe0kkf23bQttW0UjWWrZGGmNeinwuOxayV3I3rn4q/GFK2eiQ/7X8yB/1X4emwyRn67k/i1nUGRqSxotUzB0XKadlNfaOQe62tQCA4DAFmdNg662WP7Yl991UzgvV59LKcMRwouKIISMfREREpBVvPoiIiEgr9vORxeINf+52sry7KURtNy8q89yZ+gtwglMNFa3lUlSLDtOQpe+mc7qzcvp3csj5lut2d3aXM/v5ICIiItfKigannfWJMNF+m40hPXhIjKcQt5at3bxkIs+qGqaqkEqDwnjSGdvFqVczjWgHADSVh2ckScnSV/H6pFuvEa9w+hrZU+Do5h3nildtlyxZgvHjx6NHjx7o168fpk2bhrq6uqh1Tp06haqqKvTu3Rvdu3fHjBkz0NDQoDTTRERE5F1J3Xxs2LABVVVV+PTTT7F27VqcOXMGV111FVpaWsx15s2bhzfffBOrV6/Ghg0bcODAAUyfPl15xomIiMib0mpwevjwYfTr1w8bNmzAFVdcgaamJvTt2xcvvfQSfv7znwMAtm/fjuHDh6O6uhqXXXZZwm16vcFpKv0apNoQLlG4lY3ZnKd6sDcddDRE7kzn3sZxsVVBEyVVTEYfJUYfKMmQHU+v9fSZDlYteYO2BqdNTU0AAL/fDwCoqanBmTNnUFlZaa4zbNgwDBw4ENXV1dJttLa2orm5OeofERERZa+UG5y2t7fj/vvvx6RJkzBixAgAQH19PfLy8tCzZ8+odYuLi1FfXy/dzpIlS/Dwww+nmg3XSeUpREXPj3Y/70xPpDp0hqfOVLjx/HLq3K/aGpk3GpzulCSRSsQjHp3nXqYjD248n+xyw/gsbpRy5KOqqgpfffUVVq1alVYGFi5ciKamJvPfvn370toeERERuVtKkY/Zs2fjrbfewocffogBAwaYy0tKSnD69Gk0NjZGRT8aGhpQUlIi3VZ+fj7y8/OlnxEREVH2SermQwiBOXPm4PXXX8f69esxePDgqM/HjRuHLl26YN26dZgxYwYAoK6uDnv37sWECROSylj5V5Px7WXJhagAPWEqo8c6WW91sj4WAn0jy4KHMxtGy9YwXqbCwm7qUyNZqTSWTTYcnOlwvZVT6Zt9eyD+IFyBnaFuCYJDLk46DVnedTY4TefYqW7g3BmqJNLZt3QaNtulogySuvmoqqrCSy+9hDVr1qBHjx5mO46ioiJ069YNRUVFmDVrFubPnw+/34/CwkLMmTMHEyZMsPWmCxEREWW/pF619fl80uUrVqzAHXfcASDUydgDDzyAl19+Ga2trZgyZQqefvrpDqtdzpbKq7apPH12hrtnItW8FvnIdPo6dIZ9tOJvt3sl86pt0tUuiXTt2hXLly/H8uXLk9k0ERERdRIcWI6IiIi0yoqB5drHWv5os/eddEJ2Xgn76ejJ0ile6b3RGvKONDZ0Js+qelNN57xItrrFvyeyLHg46eRSJrtGA/tDy4LnqS0fa7nkfvPLUBoX3R2znuy42z3P4zVyd/vvkOrfy+vC19kySaNeNwqcb3nhQFJ+TnF778uMfBAREZFWaY3t4oRUGpx2tgZXnYFx1259jbGzl63xCh3g7Gt0qZINd3+d5ddlmUMRoXisjdF9fUJT1ZGPIZYn2+t6h6ayfY0XvaDs5eXX8YHkIlfaxnYhIiIiShZvPoiIiEirrGhwuuek5Y9tGctGp+RU49vIAF3uDFMaodSjsyLLnM6rG6tarGT7/8nz1pBz+mnIqnbiHXdrmPuIea6mn4+OxKtaklW3eKXxOqXO+hsBDxazU+cmIx9ERESkVVZEPgZ1i8w7+VTjNTqeqpzatrHddBoTO9kQ2Xia0fnEunFcZH+cep03HbJX+1Q3sCuqDU2tDZHt8r8bmtrNkd3zx//THeb8xM+HApBHQIzyS6XsGCGJCIwMHYsjlvFI3XxcMvW6uSqysWJUnI+MfBAREZFWvPkgIiIirbKinw/dvBIC9UovofHYDX1nqq8Xax8PnaH/hkz0VaGq6s2oslF9PVj7XxnzUmgqq27yco/D6VDxe6mjrwyn0tD925TJ/5/YzwcRERG5VlY0ONUt2fEtMhUhydkSnlHwiqMOsicEu8cuY1GoPpZ5h7PgirEajP2VJC8rPxV5tpat3WvKjDJYv1sWzsvulLLRoXLLI1wwzhNzZ4t4GFRcmzqOnVNp6P5tUp2eU/+PMfJBREREWvHmg4iIiLRig1PFZKHnwFbLkMpjOmfoldwnlYZwmWg06aWBI+M1yM2GBuCkRzrXmY5rtKOqGDY4JSIiItfKigangR8skYXeGl5livN0I3syaxsXma9tSz/9wM7vAABHbrw5brqyO+BMN4KNR/aqm9GbIQCIlaGpbDwV2XdljR1VvU5nvF5p7V337DypZvc8T7SPssaYdsU7ZoEtk8z5I9NbAQD+lsjnwcOpHZdez0XmrfsWL0/GeW68XgsAueUbQvkIFthK1+65Etj5vjn/UOBJAMD1ktV7lq8CAHyQwmGIFzVJJTKk83dAdcQnUBDaXrDFfb9hMoGdX5nzwSEjbH0nnd8m8/dR0eEJIHy8rRv8Pjzdnfp2GfkgIiIirXjzQURERFqxwWkWUx1adbohk5caFhqseTaqB7zWA6MqsvJzqkztbtd6zH5/V2iqelC+wCnLgH/hmifZwHKBcHVt0FJd6+ZqUDfx4m+DYa5lQEjZeeF2yfzus8EpERERuZZnIh/xnhDc/kRI5CbG9SJruKtapp9YrekbjeRUj0sTsIzvcyTcA6xsXzMxLo4bqI6Yei1a1Jn+f2Lkg4iIiFyLNx9ERESklWf6+YgXYtMdyooXRkyl0Z3Xwojkbe1jQ1Md55ubzmmnqjvEmsj80Tjr9TLWUzTQo1eqcVT/PrvpnLLDWr3p9OCTXsLIBxEREWnlmchHPLobtcW7k5elnyhPXruTJ29Hq3SMLeLU8YlqQBoWLw3rZ8Yrj6pfd/T1eMqcDwYvT+q76Rwnt0c8nOKViI9RttYeeimCkQ8iIiLSijcfREREpJVn+vmQ2RgOo6rusTCRZMN+1sHRgl86m1dZFZR1gLWm8ujPvMSLVR1ey7PuQRp1UjHA2RBLnx7G9a+zZ1eZztSPBKmXygsRHf3fy34+iIiIyLU8HfkwyIZOz5RM9+hI2ctL55bTDU5T2a5TebJGHnzhn6zgUMnYLvvDY7uc5+6yU031cfdaNLEzYeSDiIiIXIs3H0RERKRVVvTz4SZuCgWqHtBJp2QbB2aqSsJLVSGZkHtJ5Pi0bUvu+MjC63aPsez88X8cmqoupaNTLX9s73i9toEI5ymyzG7jdS9XNajOs9f6zchUswC3N0Rm5IOIiIi0Sivy8dhjj2HhwoW47777sHTpUgDAqVOn8MADD2DVqlVobW3FlClT8PTTT6O4uFhFfqMYTwO5lrEVgucpTyZtTj0dJ9quMYYH2mI+ciXr/tSG98d6927sj+zpwfo0pOMp0XjVDJY0VLzKGY9/ZWQ+XgqJzotkxyayy/rdPSdD0/K/RD4PDk1qc9L0rU+RBtnxXj4mNJ374rzIwh07QtOp8UZgSd7kPuMjf7x6f2g6JHa93G2haXBYZJm/R3hZCul6JbKp+nr0VYamwcNKNmdKJ0oXd7vf/NKcD16kbLMJqTovAn3DDaUPqz3PUo58bN68GX/84x8xatSoqOXz5s3Dm2++idWrV2PDhg04cOAApk+fnnZGiYiIKDuk9Krt8ePHMXbsWDz99NN45JFHMGbMGCxduhRNTU3o27cvXnrpJfz85z8HAGzfvh3Dhw9HdXU1LrvssoTbTuVVW7fXbVHydIwNks62M/HUabezOjeMomyksdLy66KiM8Bk8x44ZYmUhAMUqjv6C3yea84vuyvUi59sX70yJonb6XhlWuV17aauIFKRzG+d46/aVlVV4dprr0VlZWXU8pqaGpw5cyZq+bBhwzBw4EBUV1dLt9Xa2orm5uaof0RERJS9km7zsWrVKmzZsgWbN2+O+ay+vh55eXno2bNn1PLi4mLU19dLt7dkyRI8/PDDyWaDiIiIPCqpm499+/bhvvvuw9q1a9G1a1clGVi4cCHmz59v/t3c3IyysrKktnF0luUP70W1SMKpKgFV281E9Z7d6oJE+5jOMbAb8jY+v81nrQJKOdmY7doV7GpZ/8v005emMTrSort8a2haK1uxj/GF5NPw8qu2qjl1DJy6plVVtdg9B1SfK04dl6SqXWpqanDo0CGMHTsW55xzDs455xxs2LABy5YtwznnnIPi4mKcPn0ajY2NUd9raGhASUmJdJv5+fkoLCyM+kdERETZK6nIx5VXXokvv4x+fLjzzjsxbNgwLFiwAGVlZejSpQvWrVuHGTNmAADq6uqwd+9eTJgwQV2uw/g04BweW/fxYodmKvKpar+dehXa2hB4WV5oOrEmdj3j9WNsSz4Nr5S3jOrfEqdfaVdN1flr97s6xlNSUaZJ3Xz06NEDI0aMiFpWUFCA3r17m8tnzZqF+fPnw+/3o7CwEHPmzMGECRNsvelCRERE2U959+pPPfUUcnJyMGPGjKhOxoiIiIiAFPv5cFIq/Xw4GY5m9QNRdtDRd4yMkR5/S9Tw2nHsTP1QOd7PBxEREVGqsmJU2yLre22KxzHxyt21XW4eD8INPXPalYm82I3webFhql1GY0Nj7BZA3puo7Dw3fyccHOso3vE2enuVNUZNxM3XbSKqrxWvjWrrJTp/1xj5ICIiIq1480FERERaZUWDU6JMSTRolJuqisgZxoBxAODfHZoGJd2Yqq46UXFuZXMVHenHBqdERETkWlnR4LSz3r1n2357aX+MvNY6OI5KqtzQcNfMw/eRZSqGkpe91mp3Pxwb0r6PZf7VF8KJxa7m6xFqKZlK6rKoiYry03F+eqVHUqdeic29JLLdtm3OHwOvRFsZ+SAiIiKtePNBREREWmVFtYubyELe1gZpykO+cXgl3GmIV0WQaD0nycKYZ/daqSNfiRq3GmT93kjPSwfzbqbRx1J+KSZhDYcfTfK7G8dFvmsMd6+af9WDkT9K7wjPSHZ25KzQtCX5AbpUVANkqlozZ0t4ZrSa7TlVreBUHyqjtkfmaztezbWc+n+EkQ8iIiLSipGPFMS785YucyjakejO3ysRj3hkwzhnMg/JfKZaU7nljzjJysrd7rnqdsnm2dr76eXhKMiyFHoYjefIzf9hzvv3hGcOx64XbEm9DJJ92pc1nsxUeR8NB3xSjXydTUdPtSpdPiYyr/rck1Fdzk79P8LIBxEREWnFmw8iIiLSKiuqXXSHE5MN+1kbvckGwdJJFr71ynvhbqSzEZ+O8lG9Pyq2kUpDQKPawQz5A3jLzFPaWerQkUEdp2H095BKXw/JHkc3DUDnlWoAp3zyfGS+RlGj20xT8X8GIx9ERESkVVZEPnS/QpbsnXemox2JeDnioTpqk+z2vHzsZLJlf8wnfw27Y7dRtPHKpRdft0xHZ4+suikKpYqKsmTkg4iIiLTizQcRERFplRXVLrp5JYwYQCif1uG93Z7nePacDM9siyxzqmdON7JbvZhogKx0eo1Ndlh4Fb37WvPbKzQ2W0qhbKeuW+vAYUY/H0cGxZaV1xpKqmKUmQ5uatxvcGrAOq9j5IOIiIi08nTkw7ij9P1XZJmO+0r/ux2nJRt/w6m78YRPlV9cHFrvLvcMVR/v6d36mfE6szkuBADfD6FpsHfsdxKNC6N6v42oEizjNiybGZo69cTlf+Fycz5eCtbXS2Ur+j8OTY8MsyzcHZokekrzXdxx+oGRlnO/PZzWmsi4J8ELOs6z3V6DAzs3h2Ys535Qcu4HjM9fy48sfGZHOO/JjhAT35pu/zfyx3/9FACwM9gam6eaolD645oiy/aHo5PnxT9nZONreCUCO+mu0DSd3j2t0aXyD0PTYO/Y/a7aGpl3S8Ne3w87zHnV555MYOdHobSGXJ5gTZvbKwifo9YxicLXVzq9dzPyQURERFrx5oOIiIi08gkhRKYzYdXc3IyioiKsX78e3bt3T/r7bgxFZmoo62yQTuNIktN5jciqITPFqaHB3djIkSgTjh8/jsmTJ6OpqQmFhYVx12Xkg4iIiLTydINTg9sjC27Mk1fw2Kmn85g2lVv+SDHZdK7vqMiZQy0Q52Th2B1uls4YOeQejHwQERGRVrz5ICIiIq2yotrFyTCyrEfHpHt5dHm1EKVOZ9nabbzppvOtyFrV0ZbaNmQDt6WyX7n+0DR4OLV8dMT6OxAvf+lUF7ixIb1dqhv6eq26RUUvv9mIkQ8iIiLSytORDx2vYcqiG2YPkpKk3PRq4dzwK4DLNL/+l2xkyCB7Yre+xrgqPJXtj+6nfeMpVtVTua00WyLzwa6pbyfV8kkkYHnCE2tC06NTLSvsTm27cy3nwEfhSEo54l9nZk+tlnFFJg4MzyiOfAR2vh/5I9yxafDL2PUGhctvp2WZ3XNG5/gobufUK9NO8a+LzAeHZi4fqQr0DfdwejhyvFWUASMfREREpBVvPoiIiEgrT1e7GKFKa1VHqo3aUklXRhaGylQjsY+2hqa6B1iKVy2VrNt8kfmJcY6j7mM8qJuRrr40a8dF5tu2pb4dp4b1PmKZN86BXtYVUuwD4xNLPxrGdhOVt7GP1uq4t8zvppaPjtT+7Nfm/JiVRvqSFfuEp5b07Z63Xh6K3ezrxbu7kJa2iyLztRr+f1LtSEFoutNSXamiyouRDyIiItLK05EPo1FZoiHEDaoaJabT2EZnY6lMPXGkemytr2UaDQpzLA3tZOVtpCUrW1XlLWsUuDI8ItJtvkgae06GZ9KISsRT/vovzfngRR2vl2hfnWpw2muN5Y9wufl8F5uLkk3NuFas+Qx8E25EPSz+eCpG41dhOX983VPLR8J8WhoCo8eyDtPw37Mj/FlkWHW7Q5MbDa85dox3Gpoacre/ac4HL3Q+PeXXtyRipwIjH0RERKQVbz6IiIhIK58QQiTzhf3792PBggV4++23ceLECVxwwQVYsWIFAuHQtBACixYtwrPPPovGxkZMmjQJzzzzDC680F68qbm5GUVFRVi/fj26d+8e87nRvwKQuZ7uAvvD7z2fZy994z1pIPpd6XSZfRlAHmKzpms4Mig0tVsN4abhwo28RA/kFcpTomNhV+BUuGy72tuGtQ8KWf8jgZ0fhbY35PKU8xSPrF8Zu1VQAUtfGUF0vMwqUBA+Pi3xj0+yffA4VRVkPS/sNlY12K22s/Zv0rYvNM3ZEvn87MavqhpHG2VvHbzPjT2gBnbsAgAEhw5OeRvWXkKNagA37quM7j6IdFTty/r+AIDjx49j8uTJaGpqQmFhYdxtJBX5OHr0KCZNmoQuXbrg7bffxtdff43f/e536NUr0qb98ccfx7Jly/CHP/wBmzZtQkFBAaZMmYJTp04lkxQRERFlqaQanP72t79FWVkZVqxYYS4bPDhyNyuEwNKlS/Fv//ZvmDo11LXhf//3f6O4uBhvvPEGbr755rQzbLziCOh9zdHqyNTk0m+zvIOo8rXXRA1tjVekrA0Bj8auFpebhgs38iLbb2VPzOPDU0kPlVbG08zyk5Fl0rfoSueFZ9LPn+wJSjZkvezpSrZsmeXVXdSEpwWWZdaGlGFt4WeIROexLOKSCbLGyXbZXf9IH8sf4QMjOx9VP/WaT7ZuDwBceUNoms64JpZj7JWIh0F3fnW8aCB7/TZZSUU+/vKXvyAQCOCGG25Av379UF5ejmeffdb8fNeuXaivr0dlZaW5rKioCBUVFaiurpZus7W1Fc3NzVH/iIiIKHsldfOxc+dOs/3Gu+++i3vvvRdz587Fiy++CACor68HABQXF0d9r7i42PzsbEuWLEFRUZH5r6ysLJX9ICIiIo9IqsFpXl4eAoEANm7caC6bO3cuNm/ejOrqamzcuBGTJk3CgQMH0L9/f3OdG2+8ET6fD6+88krMNltbW9Ha2mr+3dzcjLKysg4bnFLn4qbh4TONxyI9Ooald6rhrJfpOO7kDo41OO3fvz9+8pOfRC0bPnw49u7dCwAoKSkBADQ0NESt09DQYH52tvz8fBQWFkb9IyIiouyVVIPTSZMmoa6uLmrZ//7v/2LQoND7m4MHD0ZJSQnWrVuHMWPGAAhFMjZt2oR7771XTY4lVL1maZfxuq/dV31lr0OqkOhJ2GtDT8u44Wkp3pOb9RXARL1UukW812BVX0tuitY4NSy9dR/bjZa4ktbHga3h1xPHeOM8UaUozjEh9XRE31REs5K6+Zg3bx4mTpyIRx99FDfeeCM+++wz/OlPf8Kf/vQnAIDP58P999+PRx55BBdeeCEGDx6MBx98EKWlpZg2bVrKmSQiIqLskdTNx/jx4/H6669j4cKFWLx4MQYPHoylS5di5syZ5jq//vWv0dLSgnvuuQeNjY34u7/7O7zzzjvo2rWr8swTERGR9yQ9sNx1112H6667rsPPfT4fFi9ejMWLF6eVsWTYHVhOlUHh/g922lx/+ZjI/MSaDldLmlNhZLdKtrpLh+t6R+aX7XY2LevAeypC2CstTc2N8zJRqDbZqrxMn6PWKhGzjxsHT58m42W93ZIP+6pNK95Ai9R5TborNF2m8P8aJ3BsFyIiItIq6bFdnJZobBc3SLaxjVON7tzUmI+cZ3fMlnS2l82cipzpGP+os7+u6uVz1akXDtzIsVdtiYiIiNLFmw8iIiLSKukGp27ild4EVTcUNEj7nfBweJLisztgnF2yxqDZfP441VD5Nl9kvtdzzvwmZVtZJMvL+58tVS3x+gdKBSMfREREpJWnIx8GJ5/WZK8WJpuGU3e+2fyU6nayqJvTjQJV9z6qeth3Wf4CIyPLgl9m9hwNhHujDaruifZ7y/yajldLJ1I7N9yodZlDDVqdlA09LadDdw/cTlH9u8bIBxEREWnFmw8iIiLSytPVLr7bQlMnOyqRhQoDWyYBAIJjP7G1jYCleiSoMHQlC4P5LYuM2YBl8LPagtBURy+hcy39H6gIFxvb+2hrZJlRPrpDm3bTMPK19dbIslSPvd2efBP1O2GEwXO/mh7Z3PDfAAACBZZztaXjBs2yc896TMxqgo6zmZJ0qraOhKd2eya2m67/Lxeb821jQwNvDim3VyVqd3/e8hnbiv1MRz8jmWYdwBF9QhOvVDXrrmoxqjqdrOYMfPNoKI3w70YqGPkgIiIirbKih1O7PcixgaYeKl6BVv1alw6yp9jO3jOlU0/liSJdsuOuo9Gm8YS+U9KoNbA//ER6XvLnh1e6FdDBa9dUtjQ4tYM9nBIREZFr8eaDiIiItMqKahfd4g1QpbqRZTq8Fp7MRm4Mlzs1wJpTUhmYyzj3Zb24qi4La18mte2hqezYeqW/C7cPhOaV45jNOvq/hdUuRERE5FqeftXWuPu6zhK70RFtGNQtNJW99iaTqQZHXo54JBu10X2MzQaxlt4tZY0M28eGZxSO6ZOu8prQ9MgwSwNsm71+Gg1IEzUeVdlgOJUnXFlagZ0fAYj7lnJKluVF5stfejuUxsWx6+V+G3rxODhETbrxGremQ3VEobNHYFX9NtmNoqqOtjpVfox8EBERkVa8+SAiIiKtsqLBqdv773Aqf4m267Vwp2x/rI3fDG5oaGbkq6k8sszp4xzoa+l99HD6aTlZVWWUZVFtZJmKcrN7Ppi9uPojy5YNDE1V9wIa+J9ekT8+DU2Ci4/GrHdjINT76auWOhmvXaOpcGOjayun8+emlxCcxganRERE5FqebnBqsg5pvTtTmdAv256WZPuTsyUyb45t4oLdNp+2NebFeHIHABxOf3uqn/SskZTY5341jEhTonPfWM86ltK494wnXLV5avvZUHM+d0F4RjKuxo7nZobSt5w0ZmTIRQ2SOxunIzI3O7p1texG4lRE7Bj5ICIiIq1480FERERaubrB6ajJk83lKqoY3N4wlSI6Q0M80suphoXp/K5wYLnsx4Hl5Bj5ICIiIq1c3eBU9VOvjqdoN93lejl6IMtzvKc/J6Na2fbUqfO8MHrhBFLvidN6TRlSKYvf3xWaTqxJKRsd8r9wuTnfFmfcEdl5lE4ZeOX6Vt0Tq9eiRWYvx4AnGxbLxtJhg1MiIiLyHN58EBERkVaurnaxK3DK0vNjV32DislCTmZfFIAr+qPwuo2W3gHHfd7xerKh01WRhW2NYemNQQaBSJ8NTvXAaj0W8XrpTDQkerxQaTq95soGk/O3RuZTPSrWa2pluHn8nOfjV28aIfett0aWzQ2fI8ExKWakI/tfMGdzN4bTuCe2pxPfph2hz0ZHPnNL1YCT/OE+aVTtoX9PeHsJ+rpxyzHNbYnMB7tmLh+pWj4mNLVWV6ron4aRDyIiItLK1a/aunVsF7tPf7LxSVQ+FSfa787wVJVpOs89VWml01jMK40cDbJojOq8WxvV7ikITdu2dTzejBvGJiJ9dP//pPN3/+wG5XzVloiIiFyLNx9ERESkVVY0ONUdAo6Xnuwzp8Ksifa7M1S3eK0aIB1u2Ec35CEZ1vzKqmCU6BOZ/ShciT1RslpTWXhmtzPZyGY6qs+cIjsHncy7zt/9dPpuYeSDiIiItMqKyAfJebnBqd0nBK88/eiUqJfdznrMnNpv63Zv8xnnrWQ9RT18quC1iKGWCJYGXjneOjDyQURERFrx5oOIiIi0yopql8BISw+nX2bXe9Tp8FWGpol6AnQjo8dSaxXC0amhqSx87VRfKh0x0muyLJMNoKUyvB2A5TyP01+kMYAaIB9ELZ3Ge3b3x1hvpaUXoXi9stplXOtiZWSZ7Do0eoO9zRdZ5n+hGgAQHNEl7XxYXRv41pwfhxsAAIsl670Y2AoAuN3SxWo6fX8YvezK+hRJJF75uWlwTBkVvWvqFCiwXLct7jueicjOMxW/a667+TD6PGtpaUmwpkVzZPb48eOKcyRJ7qS+tNIS7srX9fmUMI5x1LJjoalsf5pzI/PH2zScA+H0mq0LJfkzPlddBsfR8fZOJrgemmOW2M+f3f0x1kuUl6SFt2c9P2TbNdKN2teTLeH11f7steOEOX8GZzrM02mcjPnMOI9SOWdzwzvXpvjcSnRsMy2dY5YRlhvw4y0eybOF7Dzr6HfA+H/bTt+lruvh9G9/+xvKysoSr0hERESus2/fPgwYMCDuOq67+Whvb8eBAwcghMDAgQOxb9++hN20ZpPm5maUlZVxvzsJ7jf3uzPgfneO/RZC4NixYygtLUVOTvwmpa6rdsnJycGAAQPQ3BwK7BQWFnaKQjsb97tz4X53LtzvzqUz7XdRUZGt9fi2CxEREWnFmw8iIiLSyrU3H/n5+Vi0aBHy8/MznRWtuN/c786A+8397gw6637b4boGp0RERJTdXBv5ICIiouzEmw8iIiLSijcfREREpBVvPoiIiEgrV958LF++HOeffz66du2KiooKfPbZZ5nOklJLlizB+PHj0aNHD/Tr1w/Tpk1DXV1d1DqTJ0+Gz+eL+verX/0qQzlW49///d9j9mnYsGHm56dOnUJVVRV69+6N7t27Y8aMGWhoaMhgjtU4//zzY/bb5/OhqqoKQPaU9Ycffoif/exnKC0thc/nwxtvvBH1uRACDz30EPr3749u3bqhsrIS3377bdQ6R44cwcyZM1FYWIiePXti1qxZrhxfxCrefp85cwYLFizAyJEjUVBQgNLSUvziF7/AgQMHorYhO0cee+wxzXuSnETlfccdd8Ts09VXXx21TraVNwDpte7z+fDEE0+Y63ixvFVz3c3HK6+8gvnz52PRokXYsmULRo8ejSlTpuDQoUOZzpoyGzZsQFVVFT799FOsXbsWZ86cwVVXXRUzmN7dd9+NgwcPmv8ef/zxDOVYnUsuuSRqnz7++GPzs3nz5uHNN9/E6tWrsWHDBhw4cADTp0/PYG7V2Lx5c9Q+r127FgBwww03mOtkQ1m3tLRg9OjRWL58ufTzxx9/HMuWLcMf/vAHbNq0CQUFBZgyZQpOnTplrjNz5kxs27YNa9euxVtvvYUPP/wQ99xzj65dSEm8/T5x4gS2bNmCBx98EFu2bMFrr72Guro6XH/99THrLl68OOocmDNnjo7spyxReQPA1VdfHbVPL7/8ctTn2VbeAKL29+DBg3j++efh8/kwY8aMqPW8Vt7KCZe59NJLRVVVlfl3W1ubKC0tFUuWLMlgrpx16NAhAUBs2LDBXPb3f//34r777stcphywaNEiMXr0aOlnjY2NokuXLmL16tXmsm+++UYAENXV1ZpyqMd9990nhg4dKtrb24UQ2VnWAMTrr79u/t3e3i5KSkrEE088YS5rbGwU+fn54uWXXxZCCPH1118LAGLz5s3mOm+//bbw+Xxi//792vKejrP3W+azzz4TAMSePXvMZYMGDRJPPfWUs5lzkGy/b7/9djF16tQOv9NZynvq1Knipz/9adQyr5e3Cq6KfJw+fRo1NTWorKw0l+Xk5KCyshLV1dUZzJmzmpqaAAB+vz9q+Z///Gf06dMHI0aMwMKFC3HixAnZ1z3l22+/RWlpKYYMGYKZM2di7969AICamhqcOXMmquyHDRuGgQMHZlXZnz59GitXrsRdd90Fn89nLs/GsrbatWsX6uvro8q3qKgIFRUVZvlWV1ejZ8+eCAQC5jqVlZXIycnBpk2btOfZKU1NTfD5fOjZs2fU8sceewy9e/dGeXk5nnjiCfz444+ZyaBC69evR79+/XDxxRfj3nvvxQ8//GB+1hnKu6GhAX/9618xa9asmM+ysbyT4aqB5b7//nu0tbWhuLg4anlxcTG2b9+eoVw5q729Hffffz8mTZqEESNGmMtvvfVWDBo0CKWlpfjiiy+wYMEC1NXV4bXXXstgbtNTUVGBF154ARdffDEOHjyIhx9+GJdffjm++uor1NfXIy8vL+YHubi4GPX19ZnJsAPeeOMNNDY24o477jCXZWNZn80oQ9m1bXxWX1+Pfv36RX1+zjnnwO/3Z805cOrUKSxYsAC33HJL1EBjc+fOxdixY+H3+7Fx40YsXLgQBw8exJNPPpnB3Kbn6quvxvTp0zF48GDs2LEDv/nNb3DNNdeguroaubm5naK8X3zxRfTo0SOm+jgbyztZrrr56Iyqqqrw1VdfRbV9ABBV7zly5Ej0798fV155JXbs2IGhQ4fqzqYS11xzjTk/atQoVFRUYNCgQXj11VfRrVu3DOZMn+eeew7XXHMNSktLzWXZWNYU68yZM7jxxhshhMAzzzwT9dn8+fPN+VGjRiEvLw+//OUvsWTJEs92zX3zzTeb8yNHjsSoUaMwdOhQrF+/HldeeWUGc6bP888/j5kzZ6Jr165Ry7OxvJPlqmqXPn36IDc3N+YNh4aGBpSUlGQoV86ZPXs23nrrLXzwwQcYMGBA3HUrKioAAN99952OrGnRs2dPXHTRRfjuu+9QUlKC06dPo7GxMWqdbCr7PXv24L333sM//uM/xl0vG8vaKMN413ZJSUlMw/Iff/wRR44c8fw5YNx47NmzB2vXrk04vHpFRQV+/PFH7N69W08GNRgyZAj69OljntfZXN4A8NFHH6Guri7h9Q5kZ3kn4qqbj7y8PIwbNw7r1q0zl7W3t2PdunWYMGFCBnOmlhACs2fPxuuvv473338fgwcPTvidrVu3AgD69+/vcO70OX78OHbs2IH+/ftj3Lhx6NKlS1TZ19XVYe/evVlT9itWrEC/fv1w7bXXxl0vG8t68ODBKCkpiSrf5uZmbNq0ySzfCRMmoLGxETU1NeY677//Ptrb280bMi8ybjy+/fZbvPfee+jdu3fC72zduhU5OTkx1RJe9re//Q0//PCDeV5na3kbnnvuOYwbNw6jR49OuG42lndCmW7xerZVq1aJ/Px88cILL4ivv/5a3HPPPaJnz56ivr4+01lT5t577xVFRUVi/fr14uDBg+a/EydOCCGE+O6778TixYtFMBgUu3btEmvWrBFDhgwRV1xxRYZznp4HHnhArF+/XuzatUt88sknorKyUvTp00ccOnRICCHEr371KzFw4EDx/vvvi2AwKCZMmCAmTJiQ4Vyr0dbWJgYOHCgWLFgQtTybyvrYsWOitrZW1NbWCgDiySefFLW1teZbHY899pjo2bOnWLNmjfjiiy/E1KlTxeDBg8XJkyfNbVx99dWivLxcbNq0SXz88cfiwgsvFLfcckumdsmWePt9+vRpcf3114sBAwaIrVu3Rl3vra2tQgghNm7cKJ566imxdetWsWPHDrFy5UrRt29f8Ytf/CLDexZfvP0+duyY+Od//mdRXV0tdu3aJd577z0xduxYceGFF4pTp06Z28i28jY0NTWJc889VzzzzDMx3/dqeavmupsPIYT4/e9/LwYOHCjy8vLEpZdeKj799NNMZ0kpANJ/K1asEEIIsXfvXnHFFVcIv98v8vPzxQUXXCD+5V/+RTQ1NWU242m66aabRP/+/UVeXp4477zzxE033SS+++478/OTJ0+Kf/qnfxK9evUS5557rviHf/gHcfDgwQzmWJ13331XABB1dXVRy7OprD/44APpeX377bcLIUKv2z744IOiuLhY5OfniyuvvDLmePzwww/illtuEd27dxeFhYXizjvvFMeOHcvA3tgXb7937drV4fX+wQcfCCGEqKmpERUVFaKoqEh07dpVDB8+XDz66KNR/0m7Ubz9PnHihLjqqqtE3759RZcuXcSgQYPE3XffHfMQmW3lbfjjH/8ounXrJhobG2O+79XyVs0nhBCOhlaIiIiILFzV5oOIiIiyH28+iIiISCvefBAREZFWvPkgIiIirXjzQURERFrx5oOIiIi04s0HERERacWbDyIiItKKNx9ERESkFW8+iIiISCvefBAREZFWvPkgIiIirf4/URYgkaIhD68AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "numerical_values\n",
    "rowGeneExpression = defaultdict(int)\n",
    "\n",
    "hv_genes = set(list(var_df[var_df['highly_variable'] == True].index))\n",
    "normal_genes = (list(adata.var_names))\n",
    "\n",
    "high_variance_columns = set([ i for i,val in enumerate(normal_genes) if val in hv_genes ])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace NaN values with 0 only in numerical columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)\n",
    "\n",
    "sums = []\n",
    "\n",
    "column_averages = defaultdict(list)\n",
    "rowGeneExpression = defaultdict(int)\n",
    "rows, columns, vals = found\n",
    "high_variance = set(high_variance_columns)\n",
    "row_id = 0\n",
    "\n",
    "embedLayer = []\n",
    "for i in high_variance_columns:\n",
    "        intermediate = []\n",
    "        for i in adata.X.getcol(i).toarray():\n",
    "            intermediate.append(i[0])\n",
    "        embedLayer.append(intermediate)\n",
    "\n",
    "mat_for_embed = np.random.rand(t_dep.shape[0], 200)\n",
    "for key,col in enumerate(list(high_variance_columns)[:200]):\n",
    "    m= adata.X.getcol(col)\n",
    "    m = m.todense().tolist()\n",
    "    for row,val in enumerate(m):\n",
    "        mat_for_embed[row, key] = val[0]\n",
    "\n",
    "a = mat_for_embed\n",
    "plt.imshow(a[:80], cmap='nipy_spectral_r', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86216ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # http# ! pip install biomart\n",
    "# # mito_gene_names = sc.queries.mitochondrial_genes(\"hsapiens\")\n",
    "# # mito_ensembl_ids = sc.queries.mitochondrial_genes(\"hsapiens\", attrname=\"ensembl_gene_id\")\n",
    "# # mito_gene_names_fly = sc.queries.mitochondrial_genes(\"dmelanogaster\", chromosome=\"mitochondrion_genome\")\n",
    "# # import scanpy as sc\n",
    "# # sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=\"hsapiens\")\n",
    "# # sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}, org=\"hsapiens\")\n",
    "# # pbmcs = sc.datasets.pbmc68k_reduced()\n",
    "# # sc.tl.rank_genes_groups(pbmcs, \"bulk_labels\")\n",
    "# # sc.queries.enrich(pbmcs, \"CD34+\")\n",
    "# # # pbmcs\n",
    "# # category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "# # df.index.get_loc('TACTTGACCCCN')\n",
    "# # allRows = defaultdict(int)\n",
    "# # categories = df['perturbation'].unique()\n",
    "# # for i, group in enumerate(category_indices):\n",
    "# #     for row in group:\n",
    "# #         allRows[categories[i]] += 1\n",
    "        \n",
    "# # df.groupby('perturbation')\n",
    "\n",
    "# # categories\n",
    "# # len(category_indices)\n",
    "\n",
    "# # groupCellCounts = list(allRows.values())\n",
    "\n",
    "# # nonZerosInColumn = list(test.values())\n",
    "\n",
    "# # for k,v in enumerate(groupCellCounts):\n",
    "# #     cellCount = nonZerosInColumn[k]\n",
    "# # # from ipywidgets import interact\n",
    "# # # trn_xs = [1,2,3,4,5]\n",
    "# # # conts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\n",
    "\n",
    "# # # def iscore(nm, split):\n",
    "# # #     col = trn_xs[nm]\n",
    "# # #     return score(col, trn_y, split)\n",
    "# # # interact(nm=conts, split=15.5)(iscore);\n",
    "# #just get it working - improve it now\n",
    "# from torch import nn\n",
    "# import torch\n",
    "# def conv(ni, nf, ks=3, stride=1, act=True):\n",
    "#     res = nn.Conv1d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
    "#     if act: res = nn.Sequential(res, nn.ReLU())\n",
    "#     return res\n",
    "\n",
    "# def deconv(ni, nf, ks=3, act=True):\n",
    "#     layers = [\n",
    "#     #    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "#               nn.Conv2d(ni, nf, stride=1, kernel_size=ks, padding=ks//2)\n",
    "#     ]\n",
    "#     if act: layers.append(nn.ReLU())\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "# #data /= torch.max(data , 1)\n",
    "# #sort them by cluster and back\n",
    "# finishDemoBy6 = nn.Sequential(\n",
    "#     #nn.RNN(200, 200),\n",
    "#     torch.nn.Linear(200, 200),\n",
    "#     nn.Tanhshrink(),\n",
    "#     #nn.PairwiseDistance(p=2),\n",
    "#     conv(5905,5905, 3),       \n",
    "#     nn.AvgPool1d(101, stride=1),\n",
    "#     conv(5905,5905),\n",
    "#     nn.BatchNorm1d(100),\n",
    "#     nn.AvgPool1d(51, stride=1),\n",
    "#     #conv(5905,5905), \n",
    "#     nn.AvgPool1d(48, stride=1),\n",
    "#     nn.Sigmoid()\n",
    "# ).to('cuda:0')\n",
    "\n",
    "# num_input_channels = 3\n",
    "# c_hid=16\n",
    "# latent_dim = 64\n",
    "# finishDemoBy6= nn.Sequential(\n",
    "#         nn.Conv2d(1, c_hid, kernel_size=2, padding=1, stride=2),  # 32x32 => 16x16\n",
    "#            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "#            nn.Conv2d(c_hid, 2 * c_hid, kernel_size=3, padding=1, stride=2),  # 16x16 => 8x8\n",
    "#            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1),\n",
    "#            nn.Conv2d(2 * c_hid, 3, kernel_size=3, padding=0, stride=1),  # 8x8 => 4x4\n",
    "#            #nn.Flatten(),  # Image grid to single feature vector\n",
    "# #             nn.Linear(2 * 16 * c_hid, 3),\n",
    "# )\n",
    "\n",
    "# opt = optim.SGD(finishDemoBy6.parameters(), lr=0.01)\n",
    "# loss_function2 = torch.nn.MSELoss()\n",
    "# opt = optim.SGD(finishDemoBy6.parameters(), lr=0.01)\n",
    "# loss_function2 = torch.nn.MSELoss()\n",
    "# data = torch.Tensor(mat_for_embed).cuda()\n",
    "# for i in range(50):\n",
    "#     encodedOutput = (finishDemoBy6(data))\n",
    "# #     loss = loss_function2(encodedOutput.sum(1), t_dep.cuda())\n",
    "# #     opt.zero_grad()  # 3\n",
    "# #     loss.backward()\n",
    "#     opt.step()\n",
    "# encodedOutput.to('cuda:0')\n",
    "# encodedOutput\n",
    "# Z = adata.X.A\n",
    "# encodedOutput\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a9d7b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5905, 3])\n"
     ]
    }
   ],
   "source": [
    "# # http# ! pip install biomart\n",
    "# mito_gene_names = sc.queries.mitochondrial_genes(\"hsapiens\")\n",
    "# mito_ensembl_ids = sc.queries.mitochondrial_genes(\"hsapiens\", attrname=\"ensembl_gene_id\")\n",
    "# mito_gene_names_fly = sc.queries.mitochondrial_genes(\"dmelanogaster\", chromosome=\"mitochondrion_genome\")\n",
    "# import scanpy as sc\n",
    "# sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=\"hsapiens\")\n",
    "# sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}, org=\"hsapiens\")\n",
    "# pbmcs = sc.datasets.pbmc68k_reduced()\n",
    "# sc.tl.rank_genes_groups(pbmcs, \"bulk_labels\")\n",
    "# sc.queries.enrich(pbmcs, \"CD34+\")\n",
    "# # pbmcs\n",
    "# category_indices = df.groupby('perturbation').apply(lambda x: x.index.tolist() )\n",
    "# df.index.get_loc('TACTTGACCCCN')\n",
    "# allRows = defaultdict(int)\n",
    "# categories = df['perturbation'].unique()\n",
    "# for i, group in enumerate(category_indices):\n",
    "#     for row in group:\n",
    "#         allRows[categories[i]] += 1\n",
    "       \n",
    "# df.groupby('perturbation')\n",
    "\n",
    "# categories\n",
    "# len(category_indices)\n",
    "\n",
    "# groupCellCounts = list(allRows.values())\n",
    "\n",
    "# nonZerosInColumn = list(test.values())\n",
    "\n",
    "# for k,v in enumerate(groupCellCounts):\n",
    "#     cellCount = nonZerosInColumn[k]\n",
    "# # from ipywidgets import interact\n",
    "# # trn_xs = [1,2,3,4,5]\n",
    "# # conts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\n",
    "\n",
    "# # def iscore(nm, split):\n",
    "# #     col = trn_xs[nm]\n",
    "# #     return score(col, trn_y, split)\n",
    "# # interact(nm=conts, split=15.5)(iscore);\n",
    "#just get it working - improve it now\n",
    "# num_input_channels: int, base_channel_size: int, latent_dim: int, act_fn: object = nn.GELU):\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_input_channels: int, base_channel_size: int, latent_dim: int, act_fn: object = nn.GELU):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "           num_input_channels : Number of input channels of the image. For CIFAR, this parameter is 3\n",
    "           base_channel_size : Number of channels we use in the first convolutional layers. Deeper layers might use a duplicate of it.\n",
    "           latent_dim : Dimensionality of latent representation z\n",
    "           act_fn : Activation function used throughout the encoder network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(num_input_channels, c_hid, kernel_size=3, padding=1, stride=2),  # 32x32 => 16x16\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, 2 * c_hid, kernel_size=3, padding=1, stride=2),  # 16x16 => 8x8\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1, stride=2),  # 8x8 => 4x4\n",
    "            act_fn(),\n",
    "            nn.Flatten(),  # Image grid to single feature vector\n",
    "            nn.Linear(2 * 16 * c_hid, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "from torch import nn\n",
    "import torch\n",
    "def conv(ni, nf, ks=3, stride=1, act=True):\n",
    "    res = nn.Conv1d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res\n",
    "\n",
    "def deconv(ni, nf, ks=3, act=True):\n",
    "    layers = [\n",
    "    #    nn.UpsamplingNearest2d(scale_factor=2),\n",
    "              nn.Conv2d(ni, nf, stride=1, kernel_size=ks, padding=ks//2)\n",
    "    ]\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#data /= torch.max(data , 1)\n",
    "#sort them by cluster and back\n",
    "c_hid=16\n",
    "latent_dim = 3\n",
    "kernel_size = (1, 5)\n",
    "finishDemo= nn.Sequential(\n",
    "            nn.Conv2d(1, c_hid, kernel_size=(1, 5)),  # 32x32 => 16x16\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=kernel_size),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(c_hid, 2 * c_hid, kernel_size=kernel_size),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=kernel_size),\n",
    "            nn.LeakyReLU(), #L\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(2 * c_hid, 1, kernel_size=kernel_size),  # 8x8 => 4x4\n",
    "            nn.Linear(180, 3)\n",
    ").to('cuda:0')\n",
    "\n",
    "opt = optim.SGD(finishDemo.parameters(), lr=0.01)\n",
    "loss_function2 = torch.nn.MSELoss()\n",
    "data = torch.Tensor([[mat_for_embed]]).to('cuda')\n",
    "\n",
    "for i in range(5):\n",
    "    encodedOutput = (finishDemo(data.to('cuda:0')))\n",
    "    loss = loss_function2(encodedOutput.squeeze().sum(1), t_dep.cuda())\n",
    "    opt.zero_grad()  # 3\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "encodedOutput.to('cuda:0')\n",
    "encodedOutput = (finishDemo(data))\n",
    "tensor = encodedOutput\n",
    "tensor = tensor.squeeze()\n",
    "tensor\n",
    "print(tensor.shape)\n",
    "#spongebob\n",
    "#tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f5e5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5905, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(tensor.sum(1).shape[0])\n",
    "#     print(tensor.sum(1))\n",
    "import scvi\n",
    "\n",
    "#tensor.sum(1)\n",
    "#simplify model, use a decoder, use another simple function on ('latent representation') to figure out stochastic relationships between columns and \n",
    "#mean, variance, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa16f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for latent_dim in [64, 128, 256, 384]:\n",
    "#     model_ld, result_ld = train_cifar(latent_dim)\n",
    "#     model_dict[latent_dim] = {\"model\": model_ld, \"result\": result_ld}\n",
    "#     print(model_dict)\n",
    "    \n",
    "    \n",
    "# model = model_dict[128][\"model\"]\n",
    "# model = model_dict[256][\"model\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d6a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain_imgs = torch.zeros(4, 3, 32, 32)\n",
    "\n",
    "# # Single color channel\n",
    "# plain_imgs[1, 0] = 1\n",
    "# # Checkboard pattern\n",
    "# plain_imgs[2, :, :16, :16] = 1\n",
    "# plain_imgs[2, :, 16:, 16:] = -1\n",
    "# # Color progression\n",
    "# xx, yy = torch.meshgrid(torch.linspace(-1, 1, 32), torch.linspace(-1, 1, 32))\n",
    "# plain_imgs[3, 0, :, :] = xx\n",
    "# plain_imgs[3, 1, :, :] = yy\n",
    "\n",
    "# visualize_reconstructions(model_dict[256][\"model\"], plain_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4522d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for latent_dim in model_dict:\n",
    "#     visualize_reconstructions(model_dict[latent_dim][\"model\"], input_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "767d5681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='200' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [200/200 01:26&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.23939393939393938, 0.7448200654307524, 316, 3415)\n",
      "(0.23863636363636365, 0.7465648854961832, 315, 3423)\n",
      "(0.22803030303030303, 0.7552889858233369, 301, 3463)\n",
      "(0.22803030303030303, 0.7552889858233369, 301, 3463)\n",
      "(0.22803030303030303, 0.7550708833151581, 301, 3462)\n"
     ]
    }
   ],
   "source": [
    "dev = 'cuda:0'\n",
    "def test_prediction(test_predictions):\n",
    "    ctrl = test_predictions.sum(1).tolist()[0]\n",
    "    isFalse = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) <= ctrl and t_dep[idx] == 0])\n",
    "    isTrue = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if sum(row) > ctrl and t_dep[idx] == 1])\n",
    "    allFalse = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if t_dep[idx] == 0])\n",
    "    allTrue = len([sum(row) for idx, row in enumerate(test_predictions.tolist()) if t_dep[idx] == 1])\n",
    "    return (isFalse / allFalse, isTrue / allTrue, isFalse, isTrue)\n",
    "def plot_loss(l):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "    plt.plot(l) \n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "\n",
    "numerical_values = df.select_dtypes(include=[int, float]).values.tolist()\n",
    "t_indep = torch.Tensor(numerical_values).to(dev)\n",
    "#t_indep = t_indep / vals\n",
    "#λλλλλ.requires_grad_(True)\n",
    "#3 variations, test, t_indep and t_indep+embedding\n",
    "resultant_tensor = t_indep\n",
    "encodedOutput.requires_grad_(True)\n",
    "resultant_tensor = torch.cat((t_indep.to(dev),tensor.to(dev)), 1)\n",
    "#resultant_tensor = λλλλλ\n",
    "resultant_tensor = tensor\n",
    "\n",
    "\n",
    "vals,indices = resultant_tensor.max(dim=0)\n",
    "resultant_tensor = resultant_tensor / vals\n",
    "resultant_tensor = resultant_tensor.to(dev)\n",
    "test_indep = torch.tensor([[t_dep[k].item() for i in enumerate(range(resultant_tensor.shape[1]))] for k, i in enumerate(range(resultant_tensor.shape[0]))])\n",
    "dim = resultant_tensor.shape[1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim,dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(dim, dim),\n",
    "    nn.Sigmoid()\n",
    ").to(dev)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=.1, \n",
    "    weight_decay=0.01\n",
    ")\n",
    "# model = model.to(device)\n",
    "# input_tensor = input_tensor.to(device)\n",
    "\n",
    "n_iterations = 1000\n",
    "loss_track = []\n",
    "accuracy_track = []\n",
    "no_entropy = []\n",
    "loss_function = torch.nn.BCELoss()\n",
    "def plot_loss_update(epoch, epochs, mb, train_loss, valid_loss):\n",
    "    \"\"\" dynamically print the loss plot during the training/validation loop.\n",
    "        expects epoch to start from 1.\n",
    "    \"\"\"\n",
    "    x = range(1, epoch+1)\n",
    "    y = np.concatenate((train_loss, valid_loss))\n",
    "    graphs = [[x,train_loss], [x,valid_loss]]\n",
    "    x_margin = 0.2\n",
    "    y_margin = 0.05\n",
    "    x_bounds = [1-x_margin, epochs+x_margin]\n",
    "    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "mb = master_bar(range(1))\n",
    "def plot_loss_update(epoch, epochs, mb, train_loss, valid_loss):\n",
    "    \"\"\" dynamically print the loss plot during the training/validation loop.\n",
    "        expects epoch to start from 1.\n",
    "    \"\"\"\n",
    "    x = range(1, epoch+1)\n",
    "    y = np.concatenate((train_loss, valid_loss))\n",
    "    graphs = [[x,train_loss], [x,valid_loss]]\n",
    "    x_margin = 0.2\n",
    "    y_margin = 0.05\n",
    "    x_bounds = [1-x_margin, epochs+x_margin]\n",
    "    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "\n",
    "for i in mb:    \n",
    "#for j in progress_bar(range(2000), parent=mb):\n",
    "    for j in progress_bar(range(200)):\n",
    "        loss = loss_function(model(resultant_tensor).sum(1).sigmoid(), t_dep.to(dev))\n",
    "        optimizer.zero_grad()  # 3\n",
    "        loss.backward(retain_graph=True)  # 4\n",
    "        optimizer.step()  # 5\n",
    "        if j == 1 or j % 50 == 0:\n",
    "            test_predictions = model(resultant_tensor)\n",
    "            #print(loss.item(), test_predictions.sum().item() / 8)\n",
    "            print(test_prediction(test_predictions))\n",
    "        loss_track.append(loss.item())\n",
    "        accuracy_track.append(test_predictions.sum().item() / 8)\n",
    "        no_entropy += [test_predictions.sum().item() / 8]\n",
    "#         k = 100 * i + j\n",
    "#         x = np.arange(0, 2*k*np.pi/1000, 0.01)\n",
    "#         y1, y2 = np.cos(x), np.sin(x)\n",
    "#         graphs = [[x,y], [x,y2]]\n",
    "#         x_bounds = [0, 2*np.pi]\n",
    "#         y_bounds = [-1,1]\n",
    "        #mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "        #print(loss_track, accuracy_track)\n",
    "        #plot_loss_update(j, n_iterations, mb, loss_track, accuracy_track)\n",
    "    # emulate validation sub-loop\n",
    "        #for batch in progress_bar(range(2), parent=mb): sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b21b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "cont_keys = {}\n",
    "for key in filteredGeneCellLists:\n",
    "    cont_keys[key] = count\n",
    "    count += 1\n",
    "continuousFilteredGeneCellLists = {}\n",
    "for k in list(filteredGeneCellLists.keys()):\n",
    "    continuousFilteredGeneCellLists[cont_keys[k]] = filteredGeneCellLists[k]\n",
    "#continuousFilteredGeneCellLists\n",
    "#cont_keys\n",
    "#len(list(continuousFilteredGeneCellLists.keys()))\n",
    "#cellCountWithinGroup\n",
    "#zscore\n",
    "#continuousFilteredGeneCellLists check\n",
    "# x = cells in group(s) , cellCountWithinGroup\n",
    "# y = genes affected \n",
    "# z = cluster number\n",
    "#for each cell\n",
    "#make a graph -> \n",
    "#negative * negative = positive, \n",
    "#x  cluster \"name\" or index (clusters should change)\n",
    "#y = genes above/below threshold \n",
    "#z = total dist above threshold\n",
    "#convert 200 dimensions to 3\n",
    "cellGroups = [0 for i in list(range(5905))]\n",
    "cellGroupLengths = [0 for i in list(range(5905))]\n",
    "cellDistCounts = [0 for i in list(range(5905))]\n",
    "for column in continuousFilteredGeneCellLists:\n",
    "    for cell in continuousFilteredGeneCellLists[column]:\n",
    "        cellGroups[cell] = column\n",
    "        cellGroupLengths[cell] = len(continuousFilteredGeneCellLists[column])\n",
    "for idx, row in enumerate(mat_for_embed):\n",
    "    for val in row: \n",
    "        cellDistCounts[idx] += val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489e50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find gradient of row\n",
    "#given two rows that belong to same perturbation -> return identical or similar values\n",
    "#given a matrix -> return mx5 vals that can be transformed into a p-val\n",
    "#capture the 'features' that can be used to reconstruct -> molecular response\n",
    "# find the molecular response of each phenotype interaction or simply the gene by itself\n",
    "#gradient ascent -> descent -> find distributions -> sparsify them\n",
    "#ring that captures relevant known info about you and stores it cryptographically \n",
    "#given n rows and a matrix -> return a tuple that can be used to identify rows which belong to a perturbation response\n",
    "#given an expression matrix -> group cells by perturbation profiles\n",
    "#transcriptomics, genomics, proteinomics, metabolomics\n",
    "#recorded actions -> comic generator\n",
    "#script -> comic generator\n",
    "#comic -> animation generator\n",
    "#$https://www.youtube.com/watch?v=DzNmUNvnB04\n",
    "#plot the matrix before + after - 200x6k to 3x6k -> bright colors for rows with perturbations \n",
    "#perturbations defined as belonging to a group of rows that have multiple columns that are covarying from mean-zscore\n",
    "#makeCoolStuff = [[float(k) for k in range(5905)] for i in range(200)]\n",
    "#https://explained.ai/regularization/index.html\n",
    "#oft constraint with non-regularized loss function (blue-red) term and penalty term (orange).\n",
    "#invent a new architecture \n",
    "#that captures probability of perturbation across a matrix\n",
    "#https://www.10xgenomics.com/resources/datasets/5-k-a-549-lung-carcinoma-cells-no-treatment-transduced-with-a-crispr-pool-3-1-standard-6-0-0\n",
    "# all_url = [\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406675_10X001.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406677_10X005.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AdamsonWeissman2016_GSM2406681_10X010.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/AissaBenevolenskaya2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/ChangYe2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2017.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DatlingerBock2021.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/DixitRegev2016.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_protein.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/FrangiehIzar2021_RNA.h5ad?download=1\",\n",
    "# #     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_atscale.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_highMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GasperiniShendure2019_lowMOI.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/GehringPachter2019.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/McFarlandTsherniak2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/NormanWeissman2019_filtered.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_arrayed_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_protein.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/PapalexiSatija2021_eccite_RNA.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_essential.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_K562_gwps.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ReplogleWeissman2022_rpe1.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE106340.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchiebingerLander2019_GSE115943.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_11_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SchraivogelSteinmetz2020_TAP_SCREEN__chromosome_8_screen.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ShifrutMarson2018.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex2.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex3.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/SrivatsanTrapnell2020_sciplex4.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_day7neuron.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2019_iPSC.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRa.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/TianKampmann2021_CRISPRi.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/WeinrebKlein2020.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/XieHon2017.h5ad?download=1\",\n",
    "#     \"https://zenodo.org/record/7416068/files/ZhaoSims2021.h5ad?download=1\"\n",
    "# ]\n",
    "#scarches.dataset.remove_sparsity(adata)\n",
    "#https://docs.scarches.org/en/latest/api/models.html\n",
    "# mdata = muon.read_10x_h5(\"pbmc_10k_protein_v3_filtered_feature_bc_matrix.h5\")\n",
    "# scvi.model.TOTALVI.setup_mudata(mdata, modalities={\"rna_layer\": \"rna\": \"protein_layer\": \"prot\"})\n",
    "# vae = scvi.model.TOTALVI(mdata)\n",
    "#https://docs.scvi-tools.org/en/stable/api/reference/scvi.module.LDVAE.html\n",
    "#[i for i in test_predictions.tolist() if i < 1]\n",
    "# Regularization in Logistic Regression\n",
    "# Regularization is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in high dimensions. Consequently, most logistic regression models use one of the following two strategies to dampen model complexity:\n",
    "# L2 regularization.\n",
    "# Early stopping, that is, limiting the number of training steps or the learning rate.\n",
    "# (We'll discuss a third strategy—L1 regularization—in a later module.)\n",
    "# Imagine that you assign a unique id to each example, and map each id to its own feature. If you don't specify a regularization function, the model will become completely overfit. That's because the model would try to drive loss to zero on all examples and never get there, driving the weights for each indicator feature to +infinity or -infinity. This can happen in high dimensional data with feature crosses, when there’s a huge mass of rare crosses that happen only on one example each.\n",
    "# Fortunately, using L2 or early stopping will prevent this problem.\n",
    "#[ x for x in [iden(sum(item), 10)  for item in test_predictions.tolist()] if x > .1]\n",
    "#plot(loss_track)\n",
    "def plot_loss(l):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    legends = []\n",
    "#     blue = [i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]]\n",
    "#     oj =[i for k,i in enumerate(rowGeneExpression.values()) if not dependent_variables[k]]\n",
    "#     blue.sort()\n",
    "#     oj.sort()\n",
    "#     plt.plot((blue)) #blue true peturbation \n",
    "    plt.plot(l) #orange false ctrl\n",
    "    #legends.append('param %d' % i)\n",
    "    plt.plot([0, len([i for k,i in enumerate(rowGeneExpression.values()) if dependent_variables[k]])], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "    plt.legend(legends);\n",
    "# #https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02021-3\n",
    "# # Medicine Finding anomalies in radiology images, including CT, MRI, and X-ray images; counting features in pathology slides; measuring features in ultrasounds; diagnosing diabetic retinopathy\n",
    "# #Biology Folding proteins; classifying proteins; many genomics tasks, such as tumor-normal sequencing and classifying clinically actionable genetic mutations; cell classification; analyzing protein/protein interactions\n",
    "# #Other applications Financial and logistical forecasting, text to speech, and much more…\n",
    "# # humor analysis - larry david vs seinfeld ? \n",
    "#https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework\n",
    "#handle \"values outside of domain\" by \"SVM\"\n",
    "#random forest classifier\n",
    "#logisitc regression - hard to get right\n",
    "#correct transformations, outlier handling, correct interactions\n",
    "#os.listdir('./data_sets')\n",
    "#wget -m http://www.example.com 2>&1 | grep '^--' | awk '{ print $3 }' | grep -v '\\.\\(css\\|js\\|png\\|gif\\|jpg\\|JPG\\)$' > urls.txt\n",
    "#https://academic.oup.com/bib/article/22/4/bbaa268/5943793\n",
    "#plot(loss_track)\n",
    "#https://terrytao.files.wordpress.com/2011/02/matrix-book.pdf\n",
    "#https://academic.oup.com/bioinformatics/article/36/Supplement_2/i610/6055927?login=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b693a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sc.pl.StackedViolin(adata, , groupby='', use_raw=None, log=False, num_categories=7, categories_order=None, title=None, figsize=None, gene_symbols=None, var_group_positions=None, var_group_labels=None, var_group_rotation=None, layer=None, standard_scale=None, ax=None, vmin=None, vmax=None, vcenter=None, norm=None)\n",
    "# sc.pl.StackedViolin(adata, list(hv_genes), groupby='perturbation', dendrogram=True).show()\n",
    "# hg = list(hv_genes)[100:]\n",
    "# sc.pl.DotPlot(adata, hg,  groupby='perturbation').show()\n",
    "# sc.pl.MatrixPlot(adata, hg, groupby='perturbation').show()\n",
    "# first = adata.X.A[:100]\n",
    "# second = adata.X.T.A[:100]\n",
    "# perturbations = []\n",
    "# for key, row in enumerate(first):\n",
    "#     trackPerts = []\n",
    "#     for column in row:\n",
    "#         if column > 0: trackPerts.append(column)\n",
    "#     print(t_dep[key].item(), len(trackPerts))\n",
    "#https://datahacker.rs/003-gans-autoencoder-implemented-with-pytorch/\n",
    "#https://blog.paperspace.com/adversarial-autoencoders-with-pytorch/\n",
    "#https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf\n",
    "#https://www.cs.utoronto.ca/~hinton/absps/cogscibm.pdf\n",
    "#Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and\n",
    "# Pierre-Antoine Manzagol. 2008. Extracting and\n",
    "# composing robust features with denoising autoencoders. In Proceedings of the 25th international\n",
    "# conference on Machine learning, pages 1096–1103.\n",
    "# ACM.\n",
    "#https://github.com/fastai/course22p2/blob/master/nbs/08_autoencoder.ipynb\n",
    "#file:///Users/adnanwahab/Downloads/Molecular%20Systems%20Biology%20-%202016%20-%20Angermueller.pdf\n",
    "#https://www.cell.com/patterns/pdf/S2666-3899(21)00001-5.pdf\n",
    "#https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter3_MCMC/Ch3_IntroMCMC_PyMC3.ipynb\n",
    "##https://www.genome.gov/research-funding/Funded-Programs-Projects/Multi-Omics-for-Health-and-Disease\n",
    "#IFrame('https://www.shadertoy.com/embed/dlScDy?gui=true&t=10&paused=true&muted=false', width=700, height=350)\n",
    "#https://github.com/AntixK/PyTorch-VAE/blob/master/models/lvae.py\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# import os\n",
    "# import urllib.request\n",
    "# from urllib.error import HTTPError\n",
    "\n",
    "# import lightning as L\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib_inline.backend_inline\n",
    "# import seaborn as sns\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torch.utils.data as data\n",
    "# import torchvision\n",
    "# from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# from torchvision import transforms\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# from tqdm.notebook import tqdm\n",
    "# model_dict = {}\n",
    "\n",
    "# class GenerateCallback(Callback):\n",
    "#     def __init__(self, input_imgs, every_n_epochs=1):\n",
    "#         super().__init__()\n",
    "#         self.input_imgs = input_imgs  # Images to reconstruct during training\n",
    "#         # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
    "#         self.every_n_epochs = every_n_epochs\n",
    "\n",
    "#     def on_train_epoch_end(self, trainer, pl_module):\n",
    "#         if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "#             # Reconstruct images\n",
    "#             input_imgs = self.input_imgs.to(pl_module.device)\n",
    "#             with torch.no_grad():\n",
    "#                 pl_module.eval()\n",
    "#                 reconst_imgs = pl_module(input_imgs)\n",
    "#                 pl_module.train()\n",
    "#             # Plot and add to tensorboard\n",
    "#             imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0, 1)\n",
    "#             grid = torchvision.utils.make_grid(imgs, nrow=2, normalize=True, range=(-1, 1))\n",
    "#             trainer.logger.experiment.add_image(\"Reconstructions\", grid, global_step=trainer.global_step)    \n",
    "    \n",
    "# def train_cifar(latent_dim):\n",
    "#     # Create a PyTorch Lightning trainer with the generation callback\n",
    "#     trainer = L.Trainer(\n",
    "#         default_root_dir=os.path.join(CHECKPOINT_PATH, \"cifar10_%i\" % latent_dim),\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=1,\n",
    "#         max_epochs=500,\n",
    "#         callbacks=[\n",
    "#             ModelCheckpoint(save_weights_only=True),\n",
    "#             GenerateCallback(get_train_images(8), every_n_epochs=10),\n",
    "#             LearningRateMonitor(\"epoch\"),\n",
    "#         ],\n",
    "#     )\n",
    "#     trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "#     trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "#     # Check whether pretrained model exists. If yes, load it and skip training\n",
    "#     pretrained_filename = os.path.join(CHECKPOINT_PATH, \"cifar10_%i.ckpt\" % latent_dim)\n",
    "#     if os.path.isfile(pretrained_filename):\n",
    "#         print(\"Found pretrained model, loading...\")\n",
    "#         model = Autoencoder.load_from_checkpoint(pretrained_filename)\n",
    "#     else:\n",
    "#         model = Autoencoder(base_channel_size=32, latent_dim=latent_dim)\n",
    "#         trainer.fit(model, train_loader, val_loader)\n",
    "#     # Test best model on validation and test set\n",
    "#     val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "#     test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "#     result = {\"test\": test_result, \"val\": val_result}\n",
    "#     return model, result\n",
    "\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, num_input_channels: int, base_channel_size: int, latent_dim: int, act_fn: object = nn.GELU):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#            num_input_channels : Number of channels of the image to reconstruct. For CIFAR, this parameter is 3\n",
    "#            base_channel_size : Number of channels we use in the last convolutional layers. Early layers might use a duplicate of it.\n",
    "#            latent_dim : Dimensionality of latent representation z\n",
    "#            act_fn : Activation function used throughout the decoder network\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         c_hid = base_channel_size\n",
    "#         self.linear = nn.Sequential(nn.Linear(latent_dim, 2 * 16 * c_hid), act_fn())\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(\n",
    "#                 2 * c_hid, 2 * c_hid, kernel_size=3, output_padding=1, padding=1, stride=2\n",
    "#             ),  # 4x4 => 8x8\n",
    "#             act_fn(),\n",
    "#             nn.Conv2d(2 * c_hid, 2 * c_hid, kernel_size=3, padding=1),\n",
    "#             act_fn(),\n",
    "#             nn.ConvTranspose2d(2 * c_hid, c_hid, kernel_size=3, output_padding=1, padding=1, stride=2),  # 8x8 => 16x16\n",
    "#             act_fn(),\n",
    "#             nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "#             act_fn(),\n",
    "#             nn.ConvTranspose2d(\n",
    "#                 c_hid, num_input_channels, kernel_size=3, output_padding=1, padding=1, stride=2\n",
    "#             ),  # 16x16 => 32x32\n",
    "#             nn.Tanh(),  # The input images is scaled between -1 and 1, hence the output has to be bounded as well\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear(x)\n",
    "#         x = x.reshape(x.shape[0], -1, 4, 4)\n",
    "#         x = self.net(x)\n",
    "#         return x    \n",
    "    \n",
    "# class Autoencoder(L.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         base_channel_size: int,\n",
    "#         latent_dim: int,\n",
    "#         encoder_class: object = Encoder,\n",
    "#         decoder_class: object = Decoder,\n",
    "#         num_input_channels: int = 3,\n",
    "#         width: int = 32,\n",
    "#         height: int = 32,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         # Saving hyperparameters of autoencoder\n",
    "#         self.save_hyperparameters()\n",
    "#         # Creating encoder and decoder\n",
    "#         self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "#         self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "#         # Example input array needed for visualizing the graph of the network\n",
    "#         self.example_input_array = torch.zeros(2, num_input_channels, width, height)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"The forward function takes in an image and returns the reconstructed image.\"\"\"\n",
    "#         z = self.encoder(x)\n",
    "#         x_hat = self.decoder(z)\n",
    "#         return x_hat\n",
    "\n",
    "#     def _get_reconstruction_loss(self, batch):\n",
    "#         \"\"\"Given a batch of images, this function returns the reconstruction loss (MSE in our case)\"\"\"\n",
    "#         x, _ = batch  # We do not need the labels\n",
    "#         x_hat = self.forward(x)\n",
    "#         loss = F.mse_loss(x, x_hat, reduction=\"none\")\n",
    "#         loss = loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "#         # Using a scheduler is optional but can be helpful.\n",
    "#         # The scheduler reduces the LR if the validation performance hasn't improved for the last N epochs\n",
    "#         scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=20, min_lr=5e-5)\n",
    "#         return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss = self._get_reconstruction_loss(batch)\n",
    "#         self.log(\"train_loss\", loss)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         loss = self._get_reconstruction_loss(batch)\n",
    "#         self.log(\"val_loss\", loss)\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         loss = self._get_reconstruction_loss(batch)\n",
    "#         self.log(\"test_loss\", loss)\n",
    "\n",
    "\n",
    "# from torchvision import transforms\n",
    "# #%matplotlib inline\n",
    "# #matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "# #matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "# sns.reset_orig()\n",
    "# sns.set()\n",
    "\n",
    "# # Tensorboard extension (for visualization purposes later)\n",
    "\n",
    "# # Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "# DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data\")\n",
    "# # Path to the folder where the pretrained models are saved\n",
    "# CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/tutorial9\")\n",
    "\n",
    "# # Setting the seed\n",
    "# L.seed_everything(42)\n",
    "\n",
    "# # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(\"Device:\", device)\n",
    "# #model = Autoencoder(base_channel_size=32, latent_dim=latent_dim)\n",
    "\n",
    "# m = Encoder(200, 50, 10)\n",
    "# #m(data)\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# # Loading the training dataset. We need to split it into a training and validation part\n",
    "# # train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "# # L.seed_everything(42)\n",
    "# # train_set, val_set = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "# # # Loading the test set\n",
    "# # test_set = CIFAR10(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "# # # We define a set of data loaders that we can use for various purposes later.\n",
    "# # train_loader = data.DataLoader(train_set, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "# # val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
    "# # test_loader = data.DataLoader(test_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "\n",
    "# def get_train_images(num):\n",
    "#     return torch.stack([train_dataset[i][0] for i in range(num)], dim=0)\n",
    "# base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial9/\"\n",
    "# # Files to download\n",
    "# pretrained_files = [\"cifar10_64.ckpt\", \"cifar10_128.ckpt\", \"cifar10_256.ckpt\", \"cifar10_384.ckpt\"]\n",
    "# # Create checkpoint path if it doesn't exist yet\n",
    "# os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# # For each file, check whether it already exists. If not, try downloading it.\n",
    "# # for file_name in pretrained_files:\n",
    "# #     file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "# #     if not os.path.isfile(file_path):\n",
    "# #         file_url = base_url + file_name\n",
    "# #         print(\"Downloading %s...\" % file_url)\n",
    "# #         try:\n",
    "# #             urllib.request.urlretrieve(file_url, file_path)\n",
    "# #         except HTTPError as e:\n",
    "# #             print(\n",
    "# #                 \"Something went wrong. Please try to download the files manually,\"\n",
    "# #                 \" or contact the author with the full output including the following error:\\n\",\n",
    "# #                 e,\n",
    "# #             )\n",
    "# def visualize_reconstructions(model, input_imgs):\n",
    "#     # Reconstruct images\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         reconst_imgs = model(input_imgs.to(model.device))\n",
    "#     reconst_imgs = reconst_imgs.cpu()\n",
    "\n",
    "#     # Plotting\n",
    "#     imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0, 1)\n",
    "#     grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=True, range=(-1, 1))\n",
    "#     grid = grid.permute(1, 2, 0)\n",
    "#     plt.figure(figsize=(7, 4.5))\n",
    "#     plt.title(\"Reconstructed from %i latents\" % (model.hparams.latent_dim))\n",
    "#     plt.imshow(grid)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "# input_imgs = get_train_images(4)\n",
    "# def find_similar_images(query_img, query_z, key_embeds, K=8):\n",
    "#     # Find closest K images. We use the euclidean distance here but other like cosine distance can also be used.\n",
    "#     dist = torch.cdist(query_z[None, :], key_embeds[1], p=2)\n",
    "#     dist = dist.squeeze(dim=0)\n",
    "#     dist, indices = torch.sort(dist)\n",
    "#     # Plot K closest images\n",
    "#     imgs_to_display = torch.cat([query_img[None], key_embeds[0][indices[:K]]], dim=0)\n",
    "#     grid = torchvision.utils.make_grid(imgs_to_display, nrow=K + 1, normalize=True, range=(-1, 1))\n",
    "#     grid = grid.permute(1, 2, 0)\n",
    "#     plt.figure(figsize=(12, 3))\n",
    "#     plt.imshow(grid)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "# # Plot the closest images for the first N test images as example\n",
    "\n",
    "# def embed_imgs(model, data_loader):\n",
    "#     # Encode all images in the data_laoder using model, and return both images and encodings\n",
    "#     img_list, embed_list = [], []\n",
    "#     model.eval()\n",
    "#     for imgs, _ in tqdm(data_loader, desc=\"Encoding images\", leave=False):\n",
    "#         with torch.no_grad():\n",
    "#             z = model.encoder(imgs.to(model.device))\n",
    "#         img_list.append(imgs)\n",
    "#         embed_list.append(z)\n",
    "#     return (torch.cat(img_list, dim=0), torch.cat(embed_list, dim=0))\n",
    "\n",
    "\n",
    "# train_img_embeds = embed_imgs(model, train_loader)\n",
    "# test_img_embeds = embed_imgs(model, test_loader)\n",
    "# for i in range(8):\n",
    "#     find_similar_images(test_img_embeds[0][i], test_img_embeds[1][i], key_embeds=train_img_embeds)     \n",
    "    \n",
    "\n",
    "# latent_vectors = torch.randn(8, model.hparams.latent_dim, device=model.device)\n",
    "# # with torch.no_grad():\n",
    "# #     imgs = model.decoder(latent_vectors)\n",
    "# #     imgs = imgs.cpu()\n",
    "\n",
    "# # grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=True, range=(-1, 1), pad_value=0.5)\n",
    "# # grid = grid.permute(1, 2, 0)\n",
    "# # plt.figure(figsize=(8, 5))\n",
    "# # plt.imshow(grid)\n",
    "# # plt.axis(\"off\")\n",
    "# # plt.show()\n",
    "\n",
    "#! ls ./data_sets/* -lh\n",
    "#https://github.com/chriswi93/Neural-Networks-and-Logistic-Regression-Backpropagation-in-depth\n",
    "# ![Alt text](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-021-22197-x/MediaObjects/41467_2021_22197_Fig3_HTML.png?as=webp)\n",
    "# https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bib/22/4/10.1093_bib_bbaa268/1/m_bbaa268f1.jpeg?Expires=1695201196&Signature=1KEY92u4ZstK959i3C6haCKHZ7-6ghmNkBQwGELax4hVBn6N0o7lasyTNgnHk6sQ6eP2yiV~E51~X8JdkQkF9D5PfM7pk0N-z1rOF1HJpYaNBZ7IrUSqzdj-lQHw-TTBMjlW8rFKnSWg8~Y0y2y7q7a1hGweo3LHFNk7pSxu0kgYUaN54HwRrCWvpuMe0Eq~PL4oIh857EOSI9YaYyZ4U3ilKNy9bzbEHrLUiGOdfBBvJV09gq5g1Xp3rl49KqxwnpaFVs1qEj0z94TBYtJMDnUXEoV8ZXGJ2ESWxaXQRGziXBHA-b5l2Ac40c2eSVvTgqGFK2ClL0yGFZM5J458dg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA\n",
    "#https://muon-tutorials.readthedocs.io/en/latest/trimodal/tea-seq/1-TEA-seq-PBMC.html\n",
    "#solve known perturbations 100%\n",
    "#solve unknown perturbations -> when exactly \n",
    "#predict perturbations before they occur -> multimodal\n",
    "#solve adjacent problems in preventative medicine#\n",
    "#put flask in notebook / torch script\n",
    "#https://towardsdatascience.com/variational-autoencoder-demystified-with-pytorch-implementation-3a06bee395ed\n",
    "#-> make notebook where you can select all the files and learn everything there is to know in single cell omics (transcript, protein, metabolimcs )\n",
    "\n",
    "\n",
    "\n",
    "# The cancer sample matrix was normalized by the Z-score method, \n",
    "#which scaled the mean of each row (corresponding to feature edge) to zero and variance to one. \n",
    "#First, the rows of the matrix were clustered using hierarchical clustering based on the complete linkage method with the cluster number set to 100, \n",
    "#and clusters containing more than 30 edges were retained.\n",
    "#We then computed the mean values of perturbation for each edge in each subtype through Z-scores.\n",
    "#For each subtype, we counted the percentage of edges whose absolute value of the average perturbation was greater than 0.5 in each retained cluster. \n",
    "#A cluster with a percentage greater than 70% was regarded as a perturbed cluster for this subtype. \n",
    "#All edges in all of the perturbed clusters for each subtype constituted the subtype-specific networks.\n",
    "#All genes involved in each subtype-specific network were used for pathway enrichment analysis by Metascape (http://metascape.org). \n",
    "#The KEGG and Reactome pathways with a P-value less than 0.01 were retained. \n",
    "#Finally, the subtype-specific pathways were identified.\n",
    "#grouping based on shared genes\n",
    "#network = nodes = cell\n",
    "#edges = shared gene expression above mean -> only retain those above 30 \n",
    "#graeter than > .5 of the zscore\n",
    "#a cluster with a percentage greater than ??? (look at ribosomes)\n",
    "# https://metascape.org/blog/\n",
    "# ##   *\n",
    "# #   /_\\\n",
    "# #  (@@)\n",
    "# #---T----\n",
    "# #  /\\\n",
    "# #_|  \\_\n",
    "#https://www.genecards.org/cgi-bin/carddisp.pl?gene=A1BG\n",
    "#https://cancer.sanger.ac.uk/cosmic#:~:text=COSMIC%2C%20the%20Catalogue%20Of%20Somatic,%2C%20mutation%2C%20etc.%20below.\n",
    "#https://observablehq.com/d/124e11318fe98788\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def lda(X, y):\n",
    "#     # 1. Compute the within-class scatter matrix\n",
    "#     n_features = X.shape[1]\n",
    "#     class_labels = np.unique(y)\n",
    "#     mean_overall = np.mean(X, axis=0)\n",
    "#     S_W = np.zeros((n_features, n_features))\n",
    "#     for class_label in class_labels:\n",
    "#         X_c = X[y == class_label]\n",
    "#         mean_c = np.mean(X_c, axis=0)\n",
    "#         S_W += (X_c - mean_c).T.dot(X_c - mean_c)\n",
    "\n",
    "#     # 2. Compute the between-class scatter matrix\n",
    "#     S_B = np.zeros((n_features, n_features))\n",
    "#     for class_label in class_labels:\n",
    "#         X_c = X[y == class_label]\n",
    "#         mean_c = np.mean(X_c, axis=0)\n",
    "#         N_c = X_c.shape[0]\n",
    "#         mean_diff = (mean_c - mean_overall).reshape(n_features, 1)\n",
    "#         S_B += N_c * mean_diff.dot(mean_diff.T)\n",
    "\n",
    "#     # 3. Find eigenvalues and eigenvectors\n",
    "#     eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "\n",
    "#     # 4. Sort eigenvalues in descending order\n",
    "#     sorted_idx = np.argsort(eig_vals)[::-1]\n",
    "#     eig_vecs = eig_vecs[:, sorted_idx]\n",
    "\n",
    "#     # 5. Transform data points\n",
    "#     X_lda = X.dot(eig_vecs)\n",
    "\n",
    "#     return X_lda\n",
    "\n",
    "# # Example dataset\n",
    "# X = np.array([[4, 2],\n",
    "#               [2, 4],\n",
    "#               [2, 3],\n",
    "#               [3, 6],\n",
    "#               [4, 4]])\n",
    "# y = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "# X_lda = lda(X, y)\n",
    "# a=np.array(adata.X.A[:10][0])\n",
    "\n",
    "# len(a.nonzero()[0])\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def matrix_factorization(R, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "#     \"\"\"\n",
    "#     R     : a matrix to be factorized, dimension N x M\n",
    "#     K     : number of latent features\n",
    "#     steps : number of iterations\n",
    "#     alpha : learning rate\n",
    "#     beta  : regularization parameter\n",
    "#     \"\"\"\n",
    "#     N, M = R.shape\n",
    "#     P = np.random.rand(N, K)\n",
    "#     Q = np.random.rand(M, K)\n",
    "#     Q = Q.T\n",
    "\n",
    "#     for step in range(steps):\n",
    "#         for i in range(N):\n",
    "#             for j in range(M):\n",
    "#                 if R[i][j] > 0: # Check if rating exists\n",
    "#                     eij = R[i][j] - np.dot(P[i,:], Q[:,j])\n",
    "#                     for k in range(K):\n",
    "#                         P[i][k] += alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "#                         Q[k][j] += alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "#         eR = np.dot(P, Q)\n",
    "#         e = 0\n",
    "#         for i in range(N):\n",
    "#             for j in range(M):\n",
    "#                 if R[i][j] > 0:\n",
    "#                     e += (R[i][j] - np.dot(P[i,:], Q[:,j]))**2\n",
    "#                     for k in range(K):\n",
    "#                         e += (beta/2) * (P[i][k]**2 + Q[k][j]**2)\n",
    "#         if e < 0.001:\n",
    "#             break\n",
    "\n",
    "#     return P, Q.T\n",
    "\n",
    "# # Test\n",
    "# R = np.array([\n",
    "#     [5, 3, 0, 1],\n",
    "#     [4, 0, 0, 1],\n",
    "#     [1, 1, 0, 5],\n",
    "#     [1, 0, 0, 4],\n",
    "#     [0, 1, 5, 4]\n",
    "# ])\n",
    "# N, M = R.shape\n",
    "# K = 2\n",
    "\n",
    "# P, Q = matrix_factorization(R, K)\n",
    "# print(np.dot(P, Q.T))  # Approximated matrix\n",
    "\n",
    "# #use simulation to extend single cell data\n",
    "# #in a way that actually makes \"algorithm\" better\n",
    "# #simulation = change state of \"object\" = number some place in memory\n",
    "# def makeCell():\n",
    "#     X = torch.rand(33000)\n",
    "#     return {'X': X, 'obs':obs}\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# data = torch.Tensor(mat_for_embed)\n",
    "# cat_ = [i for i in (cellGroups,\n",
    "# cellGroupLengths,\n",
    "# cellDistCounts)]\n",
    "\n",
    "# mat2 = []\n",
    "# for col in cat_:\n",
    "#     l = []\n",
    "#     for row in col: \n",
    "#         l.append(row)\n",
    "#     mat2.append(l)\n",
    "# am = torch.tensor(mat2)\n",
    "\n",
    "# def customGeneMatrixFindPerturbations(M):\n",
    "#     m = torch.ones(M.shape[1], M.shape[0])    \n",
    "#     result = am\n",
    "#     #     m = M @ m\n",
    "#     #     m = m @ torch.ones(5905, 50)\n",
    "#     #     m = m @ torch.ones(50, 32).triu()\n",
    "#     #     m = m @ torch.eye(32, 3).cos()\n",
    "#     return result#.float().t()\n",
    "\n",
    "# class λλλ(nn.Module):\n",
    "#     def __init__(self, idn, edn):\n",
    "#         super(λλλ, self).__init__()\n",
    "#         self.λ = nn.Sequential(nn.Linear(idn, edn))\n",
    "#     def forward(self, x):\n",
    "#         return customGeneMatrixFindPerturbations(x)\n",
    "#     data = torch.Tensor(mat_for_embed)\n",
    "\n",
    "# model = λλλ(data.shape[1], 3)\n",
    "# λλλλλ = model(data)\n",
    "# λλλλλ.shape\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# a = mat_for_embed\n",
    "# plt.imshow(λλλλλ[:3,].detach(), cmap='nipy_spectral_r', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bbeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def extractor(\n",
    "    data,\n",
    "    cell_type,\n",
    "    condition_key,\n",
    "    cell_type_key,\n",
    "    ctrl_key,\n",
    "    stim_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of `data` files while filtering for a specific `cell_type`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: `~anndata.AnnData`\n",
    "        Annotated data matrix\n",
    "    cell_type: basestring\n",
    "        specific cell type to be extracted from `data`.\n",
    "    condition_key: basestring\n",
    "        key for `.obs` of `data` where conditions can be found.\n",
    "    cell_type_key: basestring\n",
    "        key for `.obs` of `data` where cell types can be found.\n",
    "    ctrl_key: basestring\n",
    "        key for `control` part of the `data` found in `condition_key`.\n",
    "    stim_key: basestring\n",
    "        key for `stimulated` part of the `data` found in `condition_key`.\n",
    "    Returns\n",
    "    ----------\n",
    "    data_list: list\n",
    "        list of `data` files while filtering for a specific `cell_type`.\n",
    "    Example\n",
    "    ----------\n",
    "    ```python\n",
    "    import scgen\n",
    "    import anndata\n",
    "\n",
    "    train_data = anndata.read(\"./data/train.h5ad\")\n",
    "    test_data = anndata.read(\"./data/test.h5ad\")\n",
    "    train_data_extracted_list = extractor(\n",
    "        train_data, \"CD4T\", \"conditions\", \"cell_type\", \"control\", \"stimulated\"\n",
    "    )\n",
    "    ```\n",
    "    \"\"\"\n",
    "    cell_with_both_condition = data[data.obs[cell_type_key] == cell_type]\n",
    "    condition_1 = data[\n",
    "        (data.obs[cell_type_key] == cell_type) & (data.obs[condition_key] == ctrl_key)\n",
    "    ]\n",
    "    condition_2 = data[\n",
    "        (data.obs[cell_type_key] == cell_type) & (data.obs[condition_key] == stim_key)\n",
    "    ]\n",
    "    training = data[\n",
    "        ~(\n",
    "            (data.obs[cell_type_key] == cell_type)\n",
    "            & (data.obs[condition_key] == stim_key)\n",
    "        )\n",
    "    ]\n",
    "    return [training, condition_1, condition_2, cell_with_both_condition]\n",
    "\n",
    "\n",
    "def balancer(\n",
    "    adata,\n",
    "    cell_type_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Makes cell type population equal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata: `~anndata.AnnData`\n",
    "        Annotated data matrix.\n",
    "    cell_type_key: basestring\n",
    "        key for `.obs` of `data` where cell types can be found.\n",
    "    Returns\n",
    "    ----------\n",
    "    balanced_data: `~anndata.AnnData`\n",
    "        Equal cell type population Annotated data matrix.\n",
    "    Example\n",
    "    ----------\n",
    "    ```python\n",
    "    import scgen\n",
    "    import anndata\n",
    "\n",
    "    train_data = anndata.read(\"./train_kang.h5ad\")\n",
    "    train_ctrl = train_data[train_data.obs[\"condition\"] == \"control\", :]\n",
    "    train_ctrl = balancer(train_ctrl, \"conditions\", \"cell_type\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "    class_names = np.unique(adata.obs[cell_type_key])\n",
    "    class_pop = {}\n",
    "    for cls in class_names:\n",
    "        class_pop[cls] = adata[adata.obs[cell_type_key] == cls].shape[0]\n",
    "    max_number = np.max(list(class_pop.values()))\n",
    "    index_all = []\n",
    "    for cls in class_names:\n",
    "        class_index = np.array(adata.obs[cell_type_key] == cls)\n",
    "        index_cls = np.nonzero(class_index)[0]\n",
    "        index_cls_r = index_cls[np.random.choice(len(index_cls), max_number)]\n",
    "        index_all.append(index_cls_r)\n",
    "\n",
    "    balanced_data = adata[np.concatenate(index_all)].copy()\n",
    "    return balanced_data\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from scvi.nn import FCLayers\n",
    "from torch import nn as nn\n",
    "\n",
    "\n",
    "# Decoder SCGEN\n",
    "class DecoderSCGEN(nn.Module):\n",
    "    \"\"\"\n",
    "    Decodes data from latent space to data space.\n",
    "\n",
    "    ``n_input`` dimensions to ``n_output``\n",
    "    dimensions using a fully-connected neural network of ``n_hidden`` layers.\n",
    "    Output is the mean and variance of a multivariate Gaussian\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input\n",
    "        The dimensionality of the input (latent space)\n",
    "    n_output\n",
    "        The dimensionality of the output (data space)\n",
    "    n_cat_list\n",
    "        A list containing the number of categories\n",
    "        for each category of interest. Each category will be\n",
    "        included using a one-hot encoding\n",
    "    n_layers\n",
    "        The number of fully-connected hidden layers\n",
    "    n_hidden\n",
    "        The number of nodes per hidden layer\n",
    "    dropout_rate\n",
    "        Dropout rate to apply to each of the hidden layers\n",
    "    kwargs\n",
    "        Keyword args for :class:`~scvi.modules._base.FCLayers`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int,\n",
    "        n_cat_list: Iterable[int] = None,\n",
    "        n_layers: int = 1,\n",
    "        n_hidden: int = 128,\n",
    "        dropout_rate: float = 0.2,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.decoder = FCLayers(\n",
    "            n_in=n_input,\n",
    "            n_out=n_hidden,\n",
    "            n_cat_list=n_cat_list,\n",
    "            n_layers=n_layers,\n",
    "            n_hidden=n_hidden,\n",
    "            dropout_rate=dropout_rate,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.linear_out = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, *cat_list: int):\n",
    "        \"\"\"\n",
    "        The forward computation for a single sample.\n",
    "\n",
    "         #. Decodes the data from the latent space using the decoder network\n",
    "         #. Returns tensors for the mean and variance of a multivariate distribution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x\n",
    "            tensor with shape ``(n_input,)``\n",
    "        cat_list\n",
    "            list of category membership(s) for this sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        2-tuple of :py:class:`torch.Tensor`\n",
    "            Mean and variance tensors of shape ``(n_output,)``\n",
    "\n",
    "        \"\"\"\n",
    "        p = self.linear_out(self.decoder(x, *cat_list))\n",
    "        return p\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from adjustText import adjust_text\n",
    "from anndata import AnnData\n",
    "from matplotlib import pyplot\n",
    "from scipy import stats\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi.data.fields import CategoricalObsField, LayerField\n",
    "from scvi.model.base import BaseModelClass, UnsupervisedTrainingMixin, VAEMixin\n",
    "from scvi.utils import setup_anndata_dsp\n",
    "\n",
    "\n",
    "\n",
    "font = {\"family\": \"Arial\", \"size\": 14}\n",
    "\n",
    "\n",
    "class CUSTOM_ALGORITHM(VAEMixin, UnsupervisedTrainingMixin, BaseModelClass):\n",
    "    \"\"\"\n",
    "    Implementation of scGen model for batch removal and perturbation prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object that has been registered via :meth:`~scgen.SCGEN.setup_anndata`.\n",
    "    n_hidden\n",
    "        Number of nodes per hidden layer.\n",
    "    n_latent\n",
    "        Dimensionality of the latent space.\n",
    "    n_layers\n",
    "        Number of hidden layers used for encoder and decoder NNs.\n",
    "    dropout_rate\n",
    "        Dropout rate for neural networks.\n",
    "    **model_kwargs\n",
    "        Keyword args for :class:`~scgen.SCGENVAE`\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> vae = scgen.SCGEN(adata)\n",
    "    >>> vae.train()\n",
    "    >>> adata.obsm[\"X_scgen\"] = vae.get_latent_representation()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        n_hidden: int = 800,\n",
    "        n_latent: int = 100,\n",
    "        n_layers: int = 2,\n",
    "        dropout_rate: float = 0.2,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super().__init__(adata)\n",
    "\n",
    "        self.module = SCGENVAE(\n",
    "            n_input=self.summary_stats.n_vars,\n",
    "            n_hidden=n_hidden,\n",
    "            n_latent=n_latent,\n",
    "            n_layers=n_layers,\n",
    "            dropout_rate=dropout_rate,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        self._model_summary_string = (\n",
    "            \"SCGEN Model with the following params: \\nn_hidden: {}, n_latent: {}, n_layers: {}, dropout_rate: \"\n",
    "            \"{}\"\n",
    "        ).format(\n",
    "            n_hidden,\n",
    "            n_latent,\n",
    "            n_layers,\n",
    "            dropout_rate,\n",
    "        )\n",
    "        self.init_params_ = self._get_init_params(locals())\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ctrl_key=None,\n",
    "        stim_key=None,\n",
    "        adata_to_predict=None,\n",
    "        celltype_to_predict=None,\n",
    "        restrict_arithmetic_to=\"all\",\n",
    "    ) -> AnnData:\n",
    "        \"\"\"\n",
    "        Predicts the cell type provided by the user in stimulated condition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ctrl_key: basestring\n",
    "            key for `control` part of the `data` found in `condition_key`.\n",
    "        stim_key: basestring\n",
    "            key for `stimulated` part of the `data` found in `condition_key`.\n",
    "        adata_to_predict: `~anndata.AnnData`\n",
    "            Adata for unperturbed cells you want to be predicted.\n",
    "        celltype_to_predict: basestring\n",
    "            The cell type you want to be predicted.\n",
    "        restrict_arithmetic_to: basestring or dict\n",
    "            Dictionary of celltypes you want to be observed for prediction.\n",
    "        Returns\n",
    "        -------\n",
    "        predicted_cells: np nd-array\n",
    "            `np nd-array` of predicted cells in primary space.\n",
    "        delta: float\n",
    "            Difference between stimulated and control cells in latent space\n",
    "        \"\"\"\n",
    "        # use keys registered from `setup_anndata()`\n",
    "        cell_type_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.LABELS_KEY\n",
    "        ).original_key\n",
    "        condition_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.BATCH_KEY\n",
    "        ).original_key\n",
    "\n",
    "        if restrict_arithmetic_to == \"all\":\n",
    "            ctrl_x = self.adata[self.adata.obs[condition_key] == ctrl_key, :]\n",
    "            stim_x = self.adata[self.adata.obs[condition_key] == stim_key, :]\n",
    "            ctrl_x = balancer(ctrl_x, cell_type_key)\n",
    "            stim_x = balancer(stim_x, cell_type_key)\n",
    "        else:\n",
    "            key = list(restrict_arithmetic_to.keys())[0]\n",
    "            values = restrict_arithmetic_to[key]\n",
    "            subset = self.adata[self.adata.obs[key].isin(values)]\n",
    "            ctrl_x = subset[subset.obs[condition_key] == ctrl_key, :]\n",
    "            stim_x = subset[subset.obs[condition_key] == stim_key, :]\n",
    "            if len(values) > 1:\n",
    "                ctrl_x = balancer(ctrl_x, cell_type_key)\n",
    "                stim_x = balancer(stim_x, cell_type_key)\n",
    "        if celltype_to_predict is not None and adata_to_predict is not None:\n",
    "            raise Exception(\"Please provide either a cell type or adata not both!\")\n",
    "        if celltype_to_predict is None and adata_to_predict is None:\n",
    "            raise Exception(\n",
    "                \"Please provide a cell type name or adata for your unperturbed cells\"\n",
    "            )\n",
    "        if celltype_to_predict is not None:\n",
    "            ctrl_pred = extractor(\n",
    "                self.adata,\n",
    "                celltype_to_predict,\n",
    "                condition_key,\n",
    "                cell_type_key,\n",
    "                ctrl_key,\n",
    "                stim_key,\n",
    "            )[1]\n",
    "        else:\n",
    "            ctrl_pred = adata_to_predict\n",
    "\n",
    "        eq = min(ctrl_x.X.shape[0], stim_x.X.shape[0])\n",
    "        cd_ind = np.random.choice(range(ctrl_x.shape[0]), size=eq, replace=False)\n",
    "        stim_ind = np.random.choice(range(stim_x.shape[0]), size=eq, replace=False)\n",
    "        ctrl_adata = ctrl_x[cd_ind, :]\n",
    "        stim_adata = stim_x[stim_ind, :]\n",
    "\n",
    "        latent_ctrl = self._avg_vector(ctrl_adata)\n",
    "        latent_stim = self._avg_vector(stim_adata)\n",
    "\n",
    "        delta = latent_stim - latent_ctrl\n",
    "\n",
    "        latent_cd = self.get_latent_representation(ctrl_pred)\n",
    "\n",
    "        stim_pred = delta + latent_cd\n",
    "        predicted_cells = (\n",
    "            self.module.generative(torch.Tensor(stim_pred))[\"px\"].cpu().detach().numpy()\n",
    "        )\n",
    "\n",
    "        predicted_adata = AnnData(\n",
    "            X=predicted_cells,\n",
    "            obs=ctrl_pred.obs.copy(),\n",
    "            var=ctrl_pred.var.copy(),\n",
    "            obsm=ctrl_pred.obsm.copy(),\n",
    "        )\n",
    "        return predicted_adata, delta\n",
    "\n",
    "    def _avg_vector(self, adata):\n",
    "        return np.mean(self.get_latent_representation(adata), axis=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_decoded_expression(\n",
    "        self,\n",
    "        adata: Optional[AnnData] = None,\n",
    "        indices: Optional[Sequence[int]] = None,\n",
    "        batch_size: Optional[int] = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Get decoded expression.\"\"\"\n",
    "        if self.is_trained_ is False:\n",
    "            raise RuntimeError(\"Please train the model first.\")\n",
    "\n",
    "        adata = self._validate_anndata(adata)\n",
    "        scdl = self._make_data_loader(\n",
    "            adata=adata, indices=indices, batch_size=batch_size\n",
    "        )\n",
    "        decoded = []\n",
    "        for tensors in scdl:\n",
    "            _, generative_outputs = self.module(tensors, compute_loss=False)\n",
    "            px = generative_outputs[\"px\"].cpu()\n",
    "            decoded.append(px)\n",
    "\n",
    "        return torch.cat(decoded).numpy()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_removal(self, adata: Optional[AnnData] = None) -> AnnData:\n",
    "        \"\"\"\n",
    "        Removes batch effects.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model. Must have been setup with `batch_key` and `labels_key`,\n",
    "            corresponding to batch and cell type metadata, respectively.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        corrected: `~anndata.AnnData`\n",
    "            AnnData of corrected gene expression in adata.X and corrected latent space in adata.obsm[\"latent\"].\n",
    "            A reference to the original AnnData is in `corrected.raw` if the input adata had no `raw` attribute.\n",
    "        \"\"\"\n",
    "        adata = self._validate_anndata(adata)\n",
    "        latent_all = self.get_latent_representation(adata)\n",
    "        # use keys registered from `setup_anndata()`\n",
    "        cell_label_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.LABELS_KEY\n",
    "        ).original_key\n",
    "        batch_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.BATCH_KEY\n",
    "        ).original_key\n",
    "\n",
    "        adata_latent = AnnData(latent_all)\n",
    "        adata_latent.obs = adata.obs.copy(deep=True)\n",
    "        unique_cell_types = np.unique(adata_latent.obs[cell_label_key])\n",
    "        shared_ct = []\n",
    "        not_shared_ct = []\n",
    "        for cell_type in unique_cell_types:\n",
    "            temp_cell = adata_latent[\n",
    "                adata_latent.obs[cell_label_key] == cell_type\n",
    "            ].copy()\n",
    "            if len(np.unique(temp_cell.obs[batch_key])) < 2:\n",
    "                cell_type_ann = adata_latent[\n",
    "                    adata_latent.obs[cell_label_key] == cell_type\n",
    "                ]\n",
    "                not_shared_ct.append(cell_type_ann)\n",
    "                continue\n",
    "            temp_cell = adata_latent[\n",
    "                adata_latent.obs[cell_label_key] == cell_type\n",
    "            ].copy()\n",
    "            batch_list = {}\n",
    "            batch_ind = {}\n",
    "            max_batch = 0\n",
    "            max_batch_ind = \"\"\n",
    "            batches = np.unique(temp_cell.obs[batch_key])\n",
    "            for i in batches:\n",
    "                temp = temp_cell[temp_cell.obs[batch_key] == i]\n",
    "                temp_ind = temp_cell.obs[batch_key] == i\n",
    "                if max_batch < len(temp):\n",
    "                    max_batch = len(temp)\n",
    "                    max_batch_ind = i\n",
    "                batch_list[i] = temp\n",
    "                batch_ind[i] = temp_ind\n",
    "            max_batch_ann = batch_list[max_batch_ind]\n",
    "            for study in batch_list:\n",
    "                delta = np.average(max_batch_ann.X, axis=0) - np.average(\n",
    "                    batch_list[study].X, axis=0\n",
    "                )\n",
    "                batch_list[study].X = delta + batch_list[study].X\n",
    "                temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "            shared_ct.append(temp_cell)\n",
    "        all_shared_ann = AnnData.concatenate(\n",
    "            *shared_ct, batch_key=\"concat_batch\", index_unique=None\n",
    "        )\n",
    "        if \"concat_batch\" in all_shared_ann.obs.columns:\n",
    "            del all_shared_ann.obs[\"concat_batch\"]\n",
    "        if len(not_shared_ct) < 1:\n",
    "            corrected = AnnData(\n",
    "                self.module.generative(torch.Tensor(all_shared_ann.X))[\"px\"]\n",
    "                .cpu()\n",
    "                .numpy(),\n",
    "                obs=all_shared_ann.obs,\n",
    "            )\n",
    "            corrected.var_names = adata.var_names.tolist()\n",
    "            corrected = corrected[adata.obs_names]\n",
    "            if adata.raw is not None:\n",
    "                adata_raw = AnnData(X=adata.raw.X, var=adata.raw.var)\n",
    "                adata_raw.obs_names = adata.obs_names\n",
    "                corrected.raw = adata_raw\n",
    "            corrected.obsm[\"latent\"] = all_shared_ann.X\n",
    "            corrected.obsm[\"corrected_latent\"] = self.get_latent_representation(\n",
    "                corrected\n",
    "            )\n",
    "            return corrected\n",
    "        else:\n",
    "            all_not_shared_ann = AnnData.concatenate(\n",
    "                *not_shared_ct, batch_key=\"concat_batch\", index_unique=None\n",
    "            )\n",
    "            all_corrected_data = AnnData.concatenate(\n",
    "                all_shared_ann,\n",
    "                all_not_shared_ann,\n",
    "                batch_key=\"concat_batch\",\n",
    "                index_unique=None,\n",
    "            )\n",
    "            if \"concat_batch\" in all_shared_ann.obs.columns:\n",
    "                del all_corrected_data.obs[\"concat_batch\"]\n",
    "            corrected = AnnData(\n",
    "                self.module.generative(torch.Tensor(all_corrected_data.X))[\"px\"]\n",
    "                .cpu()\n",
    "                .numpy(),\n",
    "                obs=all_corrected_data.obs,\n",
    "            )\n",
    "            corrected.var_names = adata.var_names.tolist()\n",
    "            corrected = corrected[adata.obs_names]\n",
    "            if adata.raw is not None:\n",
    "                adata_raw = AnnData(X=adata.raw.X, var=adata.raw.var)\n",
    "                adata_raw.obs_names = adata.obs_names\n",
    "                corrected.raw = adata_raw\n",
    "            corrected.obsm[\"latent\"] = all_corrected_data.X\n",
    "            corrected.obsm[\"corrected_latent\"] = self.get_latent_representation(\n",
    "                corrected\n",
    "            )\n",
    "            return corrected\n",
    "\n",
    "    def reg_mean_plot(\n",
    "        self,\n",
    "        adata,\n",
    "        axis_keys,\n",
    "        labels,\n",
    "        path_to_save=\"./reg_mean.pdf\",\n",
    "        save=True,\n",
    "        gene_list=None,\n",
    "        show=False,\n",
    "        top_100_genes=None,\n",
    "        verbose=False,\n",
    "        legend=True,\n",
    "        title=None,\n",
    "        x_coeff=0.30,\n",
    "        y_coeff=0.8,\n",
    "        fontsize=14,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plots mean matching figure for a set of specific genes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata: `~anndata.AnnData`\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model. Must have been setup with `batch_key` and `labels_key`,\n",
    "            corresponding to batch and cell type metadata, respectively.\n",
    "        axis_keys: dict\n",
    "            Dictionary of `adata.obs` keys that are used by the axes of the plot. Has to be in the following form:\n",
    "             `{\"x\": \"Key for x-axis\", \"y\": \"Key for y-axis\"}`.\n",
    "        labels: dict\n",
    "            Dictionary of axes labels of the form `{\"x\": \"x-axis-name\", \"y\": \"y-axis name\"}`.\n",
    "        path_to_save: basestring\n",
    "            path to save the plot.\n",
    "        save: boolean\n",
    "            Specify if the plot should be saved or not.\n",
    "        gene_list: list\n",
    "            list of gene names to be plotted.\n",
    "        show: bool\n",
    "            if `True`: will show to the plot after saving it.\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import anndata\n",
    "        >>> import scgen\n",
    "        >>> import scanpy as sc\n",
    "        >>> train = sc.read(\"./tests/data/train.h5ad\", backup_url=\"https://goo.gl/33HtVh\")\n",
    "        >>> scgen.SCGEN.setup_anndata(train)\n",
    "        >>> network = scgen.SCGEN(train)\n",
    "        >>> network.train()\n",
    "        >>> unperturbed_data = train[((train.obs[\"cell_type\"] == \"CD4T\") & (train.obs[\"condition\"] == \"control\"))]\n",
    "        >>> pred, delta = network.predict(\n",
    "        >>>     adata=train,\n",
    "        >>>     adata_to_predict=unperturbed_data,\n",
    "        >>>     ctrl_key=\"control\",\n",
    "        >>>     stim_key=\"stimulated\"\n",
    "        >>>)\n",
    "        >>> pred_adata = anndata.AnnData(\n",
    "        >>>     pred,\n",
    "        >>>     obs={\"condition\": [\"pred\"] * len(pred)},\n",
    "        >>>     var={\"var_names\": train.var_names},\n",
    "        >>>)\n",
    "        >>> CD4T = train[train.obs[\"cell_type\"] == \"CD4T\"]\n",
    "        >>> all_adata = CD4T.concatenate(pred_adata)\n",
    "        >>> network.reg_mean_plot(\n",
    "        >>>     all_adata,\n",
    "        >>>     axis_keys={\"x\": \"control\", \"y\": \"pred\", \"y1\": \"stimulated\"},\n",
    "        >>>     gene_list=[\"ISG15\", \"CD3D\"],\n",
    "        >>>     path_to_save=\"tests/reg_mean.pdf\",\n",
    "        >>>     show=False\n",
    "        >>> )\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        sns.set()\n",
    "        sns.set(color_codes=True)\n",
    "\n",
    "        condition_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.BATCH_KEY\n",
    "        ).original_key\n",
    "\n",
    "        diff_genes = top_100_genes\n",
    "        stim = adata[adata.obs[condition_key] == axis_keys[\"y\"]]\n",
    "        ctrl = adata[adata.obs[condition_key] == axis_keys[\"x\"]]\n",
    "        if diff_genes is not None:\n",
    "            if hasattr(diff_genes, \"tolist\"):\n",
    "                diff_genes = diff_genes.tolist()\n",
    "            adata_diff = adata[:, diff_genes]\n",
    "            stim_diff = adata_diff[adata_diff.obs[condition_key] == axis_keys[\"y\"]]\n",
    "            ctrl_diff = adata_diff[adata_diff.obs[condition_key] == axis_keys[\"x\"]]\n",
    "            x_diff = np.asarray(np.mean(ctrl_diff.X, axis=0)).ravel()\n",
    "            y_diff = np.asarray(np.mean(stim_diff.X, axis=0)).ravel()\n",
    "            m, b, r_value_diff, p_value_diff, std_err_diff = stats.linregress(\n",
    "                x_diff, y_diff\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"top_100 DEGs mean: \", r_value_diff**2)\n",
    "        x = np.asarray(np.mean(ctrl.X, axis=0)).ravel()\n",
    "        y = np.asarray(np.mean(stim.X, axis=0)).ravel()\n",
    "        m, b, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        if verbose:\n",
    "            print(\"All genes mean: \", r_value**2)\n",
    "        df = pd.DataFrame({axis_keys[\"x\"]: x, axis_keys[\"y\"]: y})\n",
    "        ax = sns.regplot(x=axis_keys[\"x\"], y=axis_keys[\"y\"], data=df)\n",
    "        ax.tick_params(labelsize=fontsize)\n",
    "        if \"range\" in kwargs:\n",
    "            start, stop, step = kwargs.get(\"range\")\n",
    "            ax.set_xticks(np.arange(start, stop, step))\n",
    "            ax.set_yticks(np.arange(start, stop, step))\n",
    "        ax.set_xlabel(labels[\"x\"], fontsize=fontsize)\n",
    "        ax.set_ylabel(labels[\"y\"], fontsize=fontsize)\n",
    "        if gene_list is not None:\n",
    "            texts = []\n",
    "            for i in gene_list:\n",
    "                j = adata.var_names.tolist().index(i)\n",
    "                x_bar = x[j]\n",
    "                y_bar = y[j]\n",
    "                texts.append(pyplot.text(x_bar, y_bar, i, fontsize=11, color=\"black\"))\n",
    "                pyplot.plot(x_bar, y_bar, \"o\", color=\"red\", markersize=5)\n",
    "                # if \"y1\" in axis_keys.keys():\n",
    "                # y1_bar = y1[j]\n",
    "                # pyplot.text(x_bar, y1_bar, i, fontsize=11, color=\"black\")\n",
    "        if gene_list is not None:\n",
    "            adjust_text(\n",
    "                texts,\n",
    "                x=x,\n",
    "                y=y,\n",
    "                arrowprops=dict(arrowstyle=\"->\", color=\"grey\", lw=0.5),\n",
    "                force_points=(0.0, 0.0),\n",
    "            )\n",
    "        if legend:\n",
    "            pyplot.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "        if title is None:\n",
    "            pyplot.title(\"\", fontsize=fontsize)\n",
    "        else:\n",
    "            pyplot.title(title, fontsize=fontsize)\n",
    "        ax.text(\n",
    "            max(x) - max(x) * x_coeff,\n",
    "            max(y) - y_coeff * max(y),\n",
    "            r\"$\\mathrm{R^2_{\\mathrm{\\mathsf{all\\ genes}}}}$= \" + f\"{r_value ** 2:.2f}\",\n",
    "            fontsize=kwargs.get(\"textsize\", fontsize),\n",
    "        )\n",
    "        if diff_genes is not None:\n",
    "            ax.text(\n",
    "                max(x) - max(x) * x_coeff,\n",
    "                max(y) - (y_coeff + 0.15) * max(y),\n",
    "                r\"$\\mathrm{R^2_{\\mathrm{\\mathsf{top\\ 100\\ DEGs}}}}$= \"\n",
    "                + f\"{r_value_diff ** 2:.2f}\",\n",
    "                fontsize=kwargs.get(\"textsize\", fontsize),\n",
    "            )\n",
    "        if save:\n",
    "            pyplot.savefig(f\"{path_to_save}\", bbox_inches=\"tight\", dpi=100)\n",
    "        if show:\n",
    "            pyplot.show()\n",
    "        pyplot.close()\n",
    "        if diff_genes is not None:\n",
    "            return r_value**2, r_value_diff**2\n",
    "        else:\n",
    "            return r_value**2\n",
    "\n",
    "    def reg_var_plot(\n",
    "        self,\n",
    "        adata,\n",
    "        axis_keys,\n",
    "        labels,\n",
    "        path_to_save=\"./reg_var.pdf\",\n",
    "        save=True,\n",
    "        gene_list=None,\n",
    "        top_100_genes=None,\n",
    "        show=False,\n",
    "        legend=True,\n",
    "        title=None,\n",
    "        verbose=False,\n",
    "        x_coeff=0.30,\n",
    "        y_coeff=0.8,\n",
    "        fontsize=14,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plots variance matching figure for a set of specific genes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata: `~anndata.AnnData`\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model. Must have been setup with `batch_key` and `labels_key`,\n",
    "            corresponding to batch and cell type metadata, respectively.\n",
    "        axis_keys: dict\n",
    "            Dictionary of `adata.obs` keys that are used by the axes of the plot. Has to be in the following form:\n",
    "             `{\"x\": \"Key for x-axis\", \"y\": \"Key for y-axis\"}`.\n",
    "        labels: dict\n",
    "            Dictionary of axes labels of the form `{\"x\": \"x-axis-name\", \"y\": \"y-axis name\"}`.\n",
    "        path_to_save: basestring\n",
    "            path to save the plot.\n",
    "        save: boolean\n",
    "            Specify if the plot should be saved or not.\n",
    "        gene_list: list\n",
    "            list of gene names to be plotted.\n",
    "        show: bool\n",
    "            if `True`: will show to the plot after saving it.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import anndata\n",
    "        >>> import scgen\n",
    "        >>> import scanpy as sc\n",
    "        >>> train = sc.read(\"./tests/data/train.h5ad\", backup_url=\"https://goo.gl/33HtVh\")\n",
    "        >>> scgen.SCGEN.setup_anndata(train)\n",
    "        >>> network = scgen.SCGEN(train)\n",
    "        >>> network.train()\n",
    "        >>> unperturbed_data = train[((train.obs[\"cell_type\"] == \"CD4T\") & (train.obs[\"condition\"] == \"control\"))]\n",
    "        >>> pred, delta = network.predict(\n",
    "        >>>     adata=train,\n",
    "        >>>     adata_to_predict=unperturbed_data,\n",
    "        >>>     ctrl_key=\"control\",\n",
    "        >>>     stim_key=\"stimulated\"\n",
    "        >>>)\n",
    "        >>> pred_adata = anndata.AnnData(\n",
    "        >>>     pred,\n",
    "        >>>     obs={\"condition\": [\"pred\"] * len(pred)},\n",
    "        >>>     var={\"var_names\": train.var_names},\n",
    "        >>>)\n",
    "        >>> CD4T = train[train.obs[\"cell_type\"] == \"CD4T\"]\n",
    "        >>> all_adata = CD4T.concatenate(pred_adata)\n",
    "        >>> network.reg_var_plot(\n",
    "        >>>     all_adata,\n",
    "        >>>     axis_keys={\"x\": \"control\", \"y\": \"pred\", \"y1\": \"stimulated\"},\n",
    "        >>>     gene_list=[\"ISG15\", \"CD3D\"],\n",
    "        >>>     path_to_save=\"tests/reg_var4.pdf\",\n",
    "        >>>     show=False\n",
    "        >>>)\n",
    "        \"\"\"\n",
    "        import seaborn as sns\n",
    "\n",
    "        sns.set()\n",
    "        sns.set(color_codes=True)\n",
    "\n",
    "        condition_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.BATCH_KEY\n",
    "        ).original_key\n",
    "\n",
    "        sc.tl.rank_genes_groups(\n",
    "            adata, groupby=condition_key, n_genes=100, method=\"wilcoxon\"\n",
    "        )\n",
    "        diff_genes = top_100_genes\n",
    "        stim = adata[adata.obs[condition_key] == axis_keys[\"y\"]]\n",
    "        ctrl = adata[adata.obs[condition_key] == axis_keys[\"x\"]]\n",
    "        if diff_genes is not None:\n",
    "            if hasattr(diff_genes, \"tolist\"):\n",
    "                diff_genes = diff_genes.tolist()\n",
    "            adata_diff = adata[:, diff_genes]\n",
    "            stim_diff = adata_diff[adata_diff.obs[condition_key] == axis_keys[\"y\"]]\n",
    "            ctrl_diff = adata_diff[adata_diff.obs[condition_key] == axis_keys[\"x\"]]\n",
    "            x_diff = np.asarray(np.var(ctrl_diff.X, axis=0)).ravel()\n",
    "            y_diff = np.asarray(np.var(stim_diff.X, axis=0)).ravel()\n",
    "            m, b, r_value_diff, p_value_diff, std_err_diff = stats.linregress(\n",
    "                x_diff, y_diff\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"Top 100 DEGs var: \", r_value_diff**2)\n",
    "        if \"y1\" in axis_keys.keys():\n",
    "            real_stim = adata[adata.obs[condition_key] == axis_keys[\"y1\"]]\n",
    "        x = np.asarray(np.var(ctrl.X, axis=0)).ravel()\n",
    "        y = np.asarray(np.var(stim.X, axis=0)).ravel()\n",
    "        m, b, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "        if verbose:\n",
    "            print(\"All genes var: \", r_value**2)\n",
    "        df = pd.DataFrame({axis_keys[\"x\"]: x, axis_keys[\"y\"]: y})\n",
    "        ax = sns.regplot(x=axis_keys[\"x\"], y=axis_keys[\"y\"], data=df)\n",
    "        ax.tick_params(labelsize=fontsize)\n",
    "        if \"range\" in kwargs:\n",
    "            start, stop, step = kwargs.get(\"range\")\n",
    "            ax.set_xticks(np.arange(start, stop, step))\n",
    "            ax.set_yticks(np.arange(start, stop, step))\n",
    "        # _p1 = pyplot.scatter(x, y, marker=\".\", label=f\"{axis_keys['x']}-{axis_keys['y']}\")\n",
    "        # pyplot.plot(x, m * x + b, \"-\", color=\"green\")\n",
    "        ax.set_xlabel(labels[\"x\"], fontsize=fontsize)\n",
    "        ax.set_ylabel(labels[\"y\"], fontsize=fontsize)\n",
    "        if \"y1\" in axis_keys.keys():\n",
    "            y1 = np.asarray(np.var(real_stim.X, axis=0)).ravel()\n",
    "            _ = pyplot.scatter(\n",
    "                x,\n",
    "                y1,\n",
    "                marker=\"*\",\n",
    "                c=\"grey\",\n",
    "                alpha=0.5,\n",
    "                label=f\"{axis_keys['x']}-{axis_keys['y1']}\",\n",
    "            )\n",
    "        if gene_list is not None:\n",
    "            for i in gene_list:\n",
    "                j = adata.var_names.tolist().index(i)\n",
    "                x_bar = x[j]\n",
    "                y_bar = y[j]\n",
    "                pyplot.text(x_bar, y_bar, i, fontsize=11, color=\"black\")\n",
    "                pyplot.plot(x_bar, y_bar, \"o\", color=\"red\", markersize=5)\n",
    "                if \"y1\" in axis_keys.keys():\n",
    "                    y1_bar = y1[j]\n",
    "                    pyplot.text(x_bar, y1_bar, \"*\", color=\"black\", alpha=0.5)\n",
    "        if legend:\n",
    "            pyplot.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "        if title is None:\n",
    "            pyplot.title(\"\", fontsize=12)\n",
    "        else:\n",
    "            pyplot.title(title, fontsize=12)\n",
    "        ax.text(\n",
    "            max(x) - max(x) * x_coeff,\n",
    "            max(y) - y_coeff * max(y),\n",
    "            r\"$\\mathrm{R^2_{\\mathrm{\\mathsf{all\\ genes}}}}$= \" + f\"{r_value ** 2:.2f}\",\n",
    "            fontsize=kwargs.get(\"textsize\", fontsize),\n",
    "        )\n",
    "        if diff_genes is not None:\n",
    "            ax.text(\n",
    "                max(x) - max(x) * x_coeff,\n",
    "                max(y) - (y_coeff + 0.15) * max(y),\n",
    "                r\"$\\mathrm{R^2_{\\mathrm{\\mathsf{top\\ 100\\ DEGs}}}}$= \"\n",
    "                + f\"{r_value_diff ** 2:.2f}\",\n",
    "                fontsize=kwargs.get(\"textsize\", fontsize),\n",
    "            )\n",
    "\n",
    "        if save:\n",
    "            pyplot.savefig(f\"{path_to_save}\", bbox_inches=\"tight\", dpi=100)\n",
    "        if show:\n",
    "            pyplot.show()\n",
    "        pyplot.close()\n",
    "        if diff_genes is not None:\n",
    "            return r_value**2, r_value_diff**2\n",
    "        else:\n",
    "            return r_value**2\n",
    "\n",
    "    def binary_classifier(\n",
    "        self,\n",
    "        adata,\n",
    "        delta,\n",
    "        ctrl_key,\n",
    "        stim_key,\n",
    "        path_to_save,\n",
    "        save=True,\n",
    "        fontsize=14,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Latent space classifier.\n",
    "\n",
    "        Builds a linear classifier based on the dot product between\n",
    "        the difference vector and the latent representation of each\n",
    "        cell and plots the dot product results between delta and latent\n",
    "        representation.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata: `~anndata.AnnData`\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model. Must have been setup with `batch_key` and `labels_key`,\n",
    "            corresponding to batch and cell type metadata, respectively.\n",
    "        delta: float\n",
    "            Difference between stimulated and control cells in latent space\n",
    "        ctrl_key: basestring\n",
    "            key for `control` part of the `data` found in `condition_key`.\n",
    "        stim_key: basestring\n",
    "            key for `stimulated` part of the `data` found in `condition_key`.\n",
    "        path_to_save: basestring\n",
    "            path to save the plot.\n",
    "        save: boolean\n",
    "            Specify if the plot should be saved or not.\n",
    "        fontsize: integer\n",
    "            Set the font size of the plot.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import anndata\n",
    "        >>> import scgen\n",
    "        >>> import scanpy as sc\n",
    "        >>> train = sc.read(\"./tests/data/train.h5ad\", backup_url=\"https://goo.gl/33HtVh\")\n",
    "        >>> scgen.SCGEN.setup_anndata(train)\n",
    "        >>> network = scgen.SCGEN(train)\n",
    "        >>> network.train()\n",
    "        >>> unperturbed_data = train[((train.obs[\"cell_type\"] == \"CD4T\") & (train.obs[\"condition\"] == \"control\"))]\n",
    "        >>> pred, delta = network.predict(\n",
    "        >>>     adata=train,\n",
    "        >>>     adata_to_predict=unperturbed_data,\n",
    "        >>>     ctrl_key=\"control\",\n",
    "        >>>     stim_key=\"stimulated\"\n",
    "        >>>)\n",
    "        >>> network.binary_classifier(\n",
    "        >>>     network,\n",
    "        >>>     train,\n",
    "        >>>     delta,\n",
    "        >>>     ctrl_key=\"control\",\n",
    "        >>>     stim_key=\"stimulated\",\n",
    "        >>>     path_to_save=\"tests/binary_classifier.pdf\"\n",
    "        >>>     )\n",
    "        \"\"\"\n",
    "        # matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "        pyplot.close(\"all\")\n",
    "        adata = self._validate_anndata(adata)\n",
    "        condition_key = self.adata_manager.get_state_registry(\n",
    "            REGISTRY_KEYS.BATCH_KEY\n",
    "        ).original_key\n",
    "        cd = adata[adata.obs[condition_key] == ctrl_key, :]\n",
    "        stim = adata[adata.obs[condition_key] == stim_key, :]\n",
    "        all_latent_cd = self.get_latent_representation(cd.X)\n",
    "        all_latent_stim = self.get_latent_representation(stim.X)\n",
    "        dot_cd = np.zeros(len(all_latent_cd))\n",
    "        dot_sal = np.zeros(len(all_latent_stim))\n",
    "        for ind, vec in enumerate(all_latent_cd):\n",
    "            dot_cd[ind] = np.dot(delta, vec)\n",
    "        for ind, vec in enumerate(all_latent_stim):\n",
    "            dot_sal[ind] = np.dot(delta, vec)\n",
    "        pyplot.hist(\n",
    "            dot_cd,\n",
    "            label=ctrl_key,\n",
    "            bins=50,\n",
    "        )\n",
    "        pyplot.hist(dot_sal, label=stim_key, bins=50)\n",
    "        # pyplot.legend(loc=1, prop={'size': 7})\n",
    "        pyplot.axvline(0, color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
    "        pyplot.title(\"  \", fontsize=fontsize)\n",
    "        pyplot.xlabel(\"  \", fontsize=fontsize)\n",
    "        pyplot.ylabel(\"  \", fontsize=fontsize)\n",
    "        pyplot.xticks(fontsize=fontsize)\n",
    "        pyplot.yticks(fontsize=fontsize)\n",
    "        ax = pyplot.gca()\n",
    "        ax.grid(False)\n",
    "        if save:\n",
    "            pyplot.savefig(f\"{path_to_save}\", bbox_inches=\"tight\", dpi=100)\n",
    "        pyplot.show()\n",
    "\n",
    "    @classmethod\n",
    "    @setup_anndata_dsp.dedent\n",
    "    def setup_anndata(\n",
    "        cls,\n",
    "        adata: AnnData,\n",
    "        batch_key: Optional[str] = None,\n",
    "        labels_key: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        %(summary)s.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        %(param_batch_key)s\n",
    "        %(param_labels_key)s\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        scGen expects the expression data to come from `adata.X`\n",
    "        \"\"\"\n",
    "        setup_method_args = cls._get_setup_method_args(**locals())\n",
    "        anndata_fields = [\n",
    "            LayerField(REGISTRY_KEYS.X_KEY, None, is_count_data=False),\n",
    "            CategoricalObsField(REGISTRY_KEYS.BATCH_KEY, batch_key),\n",
    "            CategoricalObsField(REGISTRY_KEYS.LABELS_KEY, labels_key),\n",
    "        ]\n",
    "        adata_manager = AnnDataManager(\n",
    "            fields=anndata_fields, setup_method_args=setup_method_args\n",
    "        )\n",
    "        adata_manager.register_fields(adata, **kwargs)\n",
    "        cls.register_manager(adata_manager)\n",
    "        \n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi.module.base import BaseModuleClass, LossOutput, auto_move_data\n",
    "from scvi.nn import Encoder\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import kl_divergence as kl\n",
    "\n",
    "class SCGENVAE(BaseModuleClass):\n",
    "    \"\"\"\n",
    "    Variational auto-encoder model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input\n",
    "        Number of input genes\n",
    "    n_hidden\n",
    "        Number of nodes per hidden layer\n",
    "    n_latent\n",
    "        Dimensionality of the latent space\n",
    "    n_layers\n",
    "        Number of hidden layers used for encoder and decoder NNs\n",
    "    dropout_rate\n",
    "        Dropout rate for neural networks\n",
    "    use_layer_norm\n",
    "        Whether to use layer norm in layers\n",
    "    kl_weight\n",
    "        Weight for kl divergence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_hidden: int = 800,\n",
    "        n_latent: int = 10,\n",
    "        n_layers: int = 2,\n",
    "        dropout_rate: float = 0.1,\n",
    "        log_variational: bool = False,\n",
    "        latent_distribution: str = \"normal\",\n",
    "        use_batch_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"both\",\n",
    "        use_layer_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"none\",\n",
    "        kl_weight: float = 0.00005,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_latent = n_latent\n",
    "        self.log_variational = log_variational\n",
    "        self.latent_distribution = \"normal\"\n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        use_batch_norm_encoder = use_batch_norm == \"encoder\" or use_batch_norm == \"both\"\n",
    "        use_layer_norm_encoder = use_layer_norm == \"encoder\" or use_layer_norm == \"both\"\n",
    "\n",
    "        self.z_encoder = Encoder(\n",
    "            n_input,\n",
    "            n_latent,\n",
    "            n_layers=n_layers,\n",
    "            n_hidden=n_hidden,\n",
    "            dropout_rate=dropout_rate,\n",
    "            distribution=latent_distribution,\n",
    "            use_batch_norm=use_batch_norm_encoder,\n",
    "            use_layer_norm=use_layer_norm_encoder,\n",
    "            activation_fn=torch.nn.LeakyReLU,\n",
    "        )\n",
    "\n",
    "        n_input_decoder = n_latent\n",
    "        self.decoder = DecoderSCGEN(\n",
    "            n_input_decoder,\n",
    "            n_input,\n",
    "            n_layers=n_layers,\n",
    "            n_hidden=n_hidden,\n",
    "            activation_fn=torch.nn.LeakyReLU,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "\n",
    "    def _get_inference_input(self, tensors):\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "        input_dict = dict(\n",
    "            x=x,\n",
    "        )\n",
    "        return input_dict\n",
    "\n",
    "    def _get_generative_input(self, tensors, inference_outputs):\n",
    "        z = inference_outputs[\"z\"]\n",
    "        input_dict = {\n",
    "            \"z\": z,\n",
    "        }\n",
    "        return input_dict\n",
    "\n",
    "    @auto_move_data\n",
    "    def inference(self, x):\n",
    "        \"\"\"\n",
    "        High level inference method.\n",
    "\n",
    "        Runs the inference (encoder) model.\n",
    "        \"\"\"\n",
    "        qz_m, qz_v, z = self.z_encoder(x)\n",
    "\n",
    "        outputs = dict(z=z, qz_m=qz_m, qz_v=qz_v)\n",
    "        return outputs\n",
    "\n",
    "    @auto_move_data\n",
    "    def generative(self, z):\n",
    "        \"\"\"Runs the generative model.\"\"\"\n",
    "        px = self.decoder(z)\n",
    "\n",
    "        return dict(px=px)\n",
    "\n",
    "    def loss(\n",
    "        self,\n",
    "        tensors,\n",
    "        inference_outputs,\n",
    "        generative_outputs,\n",
    "    ):\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "        qz_m = inference_outputs[\"qz_m\"]\n",
    "        qz_v = inference_outputs[\"qz_v\"]\n",
    "        p = generative_outputs[\"px\"]\n",
    "\n",
    "        kld = kl(\n",
    "            Normal(qz_m, torch.sqrt(qz_v)),\n",
    "            Normal(0, 1),\n",
    "        ).sum(dim=1)\n",
    "        rl = self.get_reconstruction_loss(p, x)\n",
    "        loss = (0.5 * rl + 0.5 * (kld * self.kl_weight)).mean()\n",
    "        return LossOutput(loss=loss, reconstruction_loss=rl, kl_local=kld)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        tensors,\n",
    "        n_samples=1,\n",
    "    ) -> np.ndarray:\n",
    "        r\"\"\"\n",
    "        Generate observation samples from the posterior predictive distribution.\n",
    "\n",
    "        The posterior predictive distribution is written as :math:`p(\\hat{x} \\mid x)`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensors\n",
    "            Tensors dict\n",
    "        n_samples\n",
    "            Number of required samples for each cell\n",
    "        library_size\n",
    "            Library size to scale scamples to\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_new : :py:class:`torch.Tensor`\n",
    "            tensor with shape (n_cells, n_genes, n_samples)\n",
    "        \"\"\"\n",
    "        inference_kwargs = dict(n_samples=n_samples)\n",
    "        (\n",
    "            inference_outputs,\n",
    "            generative_outputs,\n",
    "        ) = self.forward(\n",
    "            tensors,\n",
    "            inference_kwargs=inference_kwargs,\n",
    "            compute_loss=False,\n",
    "        )\n",
    "        px = Normal(generative_outputs[\"px\"], 1).sample()\n",
    "        return px.cpu().numpy()\n",
    "\n",
    "    def get_reconstruction_loss(self, x, px) -> torch.Tensor:\n",
    "        loss = ((x - px) ** 2).sum(dim=1)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f85615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████| 2/2 [00:27<00:00, 13.99s/it, v_num=1, train_loss_step=232, train_loss_epoch=165]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████████████████| 2/2 [00:27<00:00, 13.94s/it, v_num=1, train_loss_step=232, train_loss_epoch=165]\n",
      "\u001b[34mINFO    \u001b[0m Received view of anndata, making copy.                                                                    \n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n",
      "\u001b[34mINFO    \u001b[0m Received view of anndata, making copy.                                                                    \n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n",
      "\u001b[34mINFO    \u001b[0m Received view of anndata, making copy.                                                                    \n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import scanpy as sc\n",
    "\n",
    "\n",
    "import pertpy as pt\n",
    "adata = pt.dt.kang_2018()\n",
    "\n",
    "\n",
    "CUSTOM_ALGORITHM = CUSTOM_ALGORITHM\n",
    "# train = sc.read(\"./tests/data/train_kang.h5ad\",\n",
    "#                 backup_url='https://drive.google.com/uc?id=1r87vhoLLq6PXAYdmyyd89zG90eJOFYLk').copy()\n",
    "\n",
    "# train = train.copy()\n",
    "# train_new = train[~((train.obs[\"cell_type\"] == \"CD4T\") &\n",
    "#                     (train.obs[\"condition\"] == \"stimulated\"))]\n",
    "\n",
    "# SCGEN.setup_anndata(train_new, batch_key=\"condition\", labels_key=\"cell_type\")\n",
    "# model = SCGEN(train_new)\n",
    "\n",
    "\n",
    "# model.train(\n",
    "#     max_epochs=100,\n",
    "#     batch_size=32,\n",
    "#     early_stopping=True,\n",
    "#     early_stopping_patience=25\n",
    "# )\n",
    "\n",
    "# pred, delta = model.predict(\n",
    "#     ctrl_key='control',\n",
    "#     stim_key='stimulated',\n",
    "#     celltype_to_predict='CD4T'\n",
    "# )\n",
    "\n",
    "adata = pt.dt.kang_2018()\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata)\n",
    "\n",
    "adata.obs.rename({\"label\": \"condition\"}, axis=1, inplace=True)\n",
    "adata.obs[\"condition\"].replace({\"ctrl\": \"control\", \"stim\": \"stimulated\"}, inplace=True)\n",
    "\n",
    "adata.obs.cell_type.value_counts()\n",
    "\n",
    "adata_t = adata[\n",
    "    ~(\n",
    "        (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "        & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "cd4t_stim = adata[\n",
    "    (\n",
    "        (adata.obs[\"cell_type\"] == \"CD4 T cells\")\n",
    "        & (adata.obs[\"condition\"] == \"stimulated\")\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "CUSTOM_ALGORITHM.setup_anndata(adata_t, batch_key=\"condition\", labels_key=\"cell_type\")\n",
    "\n",
    "model = CUSTOM_ALGORITHM(adata_t, n_hidden=800, n_latent=100, n_layers=2)\n",
    "\n",
    "model.train(\n",
    "    max_epochs=2, batch_size=32, early_stopping=True, early_stopping_patience=25\n",
    ")\n",
    "\n",
    "adata_t.obsm[\"scgen\"] = model.get_latent_representation()\n",
    "\n",
    "pred, delta = model.predict(\n",
    "    ctrl_key=\"control\", stim_key=\"stimulated\", celltype_to_predict=\"CD4 T cells\"\n",
    ")\n",
    "\n",
    "# we annotate the predicted cells to distinguish them later from ground truth cells.\n",
    "pred.obs[\"condition\"] = \"predicted stimulated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df31d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'condition'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/anndata/_core/anndata.py:1108\u001b[0m, in \u001b[0;36mAnnData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnData\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a sliced view of the object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     oidx, vidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AnnData(\u001b[38;5;28mself\u001b[39m, oidx\u001b[38;5;241m=\u001b[39moidx, vidx\u001b[38;5;241m=\u001b[39mvidx, asview\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/anndata/_core/anndata.py:1089\u001b[0m, in \u001b[0;36mAnnData._normalize_indices\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize_indices\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: Optional[Index]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mslice\u001b[39m]:\n\u001b[0;32m-> 1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_normalize_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/anndata/_core/index.py:32\u001b[0m, in \u001b[0;36m_normalize_indices\u001b[0;34m(index, names0, names1)\u001b[0m\n\u001b[1;32m     30\u001b[0m         index \u001b[38;5;241m=\u001b[39m index[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     31\u001b[0m ax0, ax1 \u001b[38;5;241m=\u001b[39m unpack_index(index)\n\u001b[0;32m---> 32\u001b[0m ax0 \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m _normalize_index(ax1, names1)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax0, ax1\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/anndata/_core/index.py:72\u001b[0m, in \u001b[0;36m_normalize_index\u001b[0;34m(indexer, index)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# int\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, (Sequence, np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mIndex, spmatrix, np\u001b[38;5;241m.\u001b[39mmatrix)):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     75\u001b[0m         (indexer\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (indexer\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m, index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     77\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/shit/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'condition'"
     ]
    }
   ],
   "source": [
    "pred['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f3ef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 24673 × 15706\n",
       "    obs: 'nCount_RNA', 'nFeature_RNA', 'tsne1', 'tsne2', 'condition', 'cluster', 'cell_type', 'replicate', 'nCount_SCT', 'nFeature_SCT', 'integrated_snn_res.0.4', 'seurat_clusters'\n",
       "    var: 'name', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg'\n",
       "    obsm: 'X_pca', 'X_umap'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata\n",
    "\n",
    "\n",
    "\n",
    "#make a module and have it just print and no setup required and faster and more accurate and does multi-modal stuff and better options (no one cares about hidden layers and batch size pretty sure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
